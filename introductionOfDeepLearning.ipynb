{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP -  Introduction to Pytorch\n",
    "\n",
    "\n",
    "## Tensors, Back-propagation, Hand-written digit recognition,  Language modeling\n",
    "*************************************************************\n",
    "\n",
    "**Recommended Reading:**\n",
    "\n",
    "http://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0000e+00 -1.5846e+29\n",
      "-8.2054e+18  3.6902e+19\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "-3.961408124995789e+28\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.FloatTensor(2, 2)\n",
    "print(a)\n",
    "print(a.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### are Numpy arrays inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   0.00000000e+00]\n",
      " [  1.28334229e-20  -3.69024602e+19]]\n"
     ]
    }
   ],
   "source": [
    "a = a.numpy()\n",
    "a [0, 1] = 0\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(torch.ones(2, 2))\n",
    "print(x)\n",
    "print(x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=torch.LongTensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.LongTensor with no dimension]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=Variable(torch.ones(1,1))\n",
    "z=Variable(torch.ones(1,1))\n",
    "y==z\n",
    "t= Variable(torch.zeros(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.ByteTensor of size 1x1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y==z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.ByteTensor of size 1x1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y-z==t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Criterion(x,y):\n",
    "    return 1 if x-y is t else 0\n",
    "Criterion(y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### are Tensors inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with automatic differentiation !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x10e54f400>\n",
      "<MulBackward0 object at 0x10e54fa58>\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad=True\n",
    "\n",
    "y = x + 2\n",
    "print(y.grad_fn)\n",
    "\n",
    "z = y * y * 3\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-4.5000 -4.5000\n",
      "-4.5000 -4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "\n",
    "error = (10 - z).mean()\n",
    "error.backward()\n",
    "\n",
    "#print(error.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-propagation: example\n",
    "\n",
    "On calcule les gradients $\\frac{\\partial L(y - h(x))}{\\partial w}$ et $\\frac{\\partial L(y - h(x))}{\\partial b}$, avec:\n",
    " - $h(x) = \\sigma(w*x + b)$\n",
    " - $\\sigma$ est la fonction logistique (sigmoid)\n",
    " - $L(y, \\hat{y}) = (y - \\hat{y})^2$ (erreur quadratique)\n",
    " - $y = 0.2$\n",
    " - $x = 1.5$\n",
    " - $b = -2$\n",
    " - $w = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9241418242454529\n",
      "0.1522950828075409\n",
      "0.101530060172081\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([1.5]))\n",
    "y = Variable(torch.Tensor([0.2]))\n",
    "b = Variable(torch.Tensor([-2.0]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([3.0]), requires_grad=True)\n",
    "h = torch.sigmoid(w * x + b)\n",
    "error = (y - h)**2\n",
    "error.backward()\n",
    "\n",
    "print(h.data[0])\n",
    "print(w.grad.data[0])\n",
    "print(b.grad.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5244\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On minimize $L(y - h(x))$ pas à pas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 h=0.92414 w=2.96954 b=-2.02031 error=0.52438\n",
      "Epoch 2 h=0.91938 w=2.93755 b=-2.04163 error=0.51751\n",
      "Epoch 3 h=0.91409 w=2.90391 b=-2.06406 error=0.50993\n",
      "Epoch 4 h=0.90820 w=2.86848 b=-2.08768 error=0.50154\n",
      "Epoch 5 h=0.90159 w=2.83113 b=-2.11258 error=0.49223\n",
      "Epoch 6 h=0.89417 w=2.79172 b=-2.13886 error=0.48188\n",
      "Epoch 7 h=0.88582 w=2.75010 b=-2.16660 error=0.47035\n",
      "Epoch 8 h=0.87637 w=2.70613 b=-2.19591 error=0.45748\n",
      "Epoch 9 h=0.86568 w=2.65968 b=-2.22688 error=0.44313\n",
      "Epoch 10 h=0.85354 w=2.61067 b=-2.25956 error=0.42712\n",
      "Epoch 11 h=0.83976 w=2.55901 b=-2.29399 error=0.40929\n",
      "Epoch 12 h=0.82412 w=2.50474 b=-2.33018 error=0.38953\n",
      "Epoch 13 h=0.80642 w=2.44794 b=-2.36804 error=0.36775\n",
      "Epoch 14 h=0.78648 w=2.38884 b=-2.40744 error=0.34396\n",
      "Epoch 15 h=0.76420 w=2.32784 b=-2.44810 error=0.31832\n",
      "Epoch 16 h=0.73956 w=2.26549 b=-2.48968 error=0.29112\n",
      "Epoch 17 h=0.71270 w=2.20250 b=-2.53167 error=0.26287\n",
      "Epoch 18 h=0.68397 w=2.13973 b=-2.57351 error=0.23423\n",
      "Epoch 19 h=0.65387 w=2.07810 b=-2.61460 error=0.20600\n",
      "Epoch 20 h=0.62306 w=2.01848 b=-2.65434 error=0.17898\n",
      "Epoch 21 h=0.59228 w=1.96165 b=-2.69224 error=0.15388\n",
      "Epoch 22 h=0.56223 w=1.90815 b=-2.72790 error=0.13121\n",
      "Epoch 23 h=0.53353 w=1.85835 b=-2.76110 error=0.11124\n",
      "Epoch 24 h=0.50661 w=1.81237 b=-2.79176 error=0.09401\n",
      "Epoch 25 h=0.48171 w=1.77017 b=-2.81989 error=0.07936\n",
      "Epoch 26 h=0.45893 w=1.73159 b=-2.84561 error=0.06705\n",
      "Epoch 27 h=0.43826 w=1.69639 b=-2.86907 error=0.05677\n",
      "Epoch 28 h=0.41958 w=1.66431 b=-2.89046 error=0.04822\n",
      "Epoch 29 h=0.40276 w=1.63505 b=-2.90997 error=0.04111\n",
      "Epoch 30 h=0.38760 w=1.60833 b=-2.92778 error=0.03519\n",
      "Epoch 31 h=0.37395 w=1.58389 b=-2.94407 error=0.03026\n",
      "Epoch 32 h=0.36164 w=1.56150 b=-2.95900 error=0.02613\n",
      "Epoch 33 h=0.35052 w=1.54094 b=-2.97271 error=0.02266\n",
      "Epoch 34 h=0.34045 w=1.52202 b=-2.98532 error=0.01973\n",
      "Epoch 35 h=0.33130 w=1.50457 b=-2.99696 error=0.01724\n",
      "Epoch 36 h=0.32298 w=1.48843 b=-3.00771 error=0.01512\n",
      "Epoch 37 h=0.31538 w=1.47348 b=-3.01768 error=0.01331\n",
      "Epoch 38 h=0.30843 w=1.45961 b=-3.02693 error=0.01176\n",
      "Epoch 39 h=0.30206 w=1.44670 b=-3.03554 error=0.01042\n",
      "Epoch 40 h=0.29619 w=1.43466 b=-3.04356 error=0.00925\n",
      "Epoch 41 h=0.29079 w=1.42343 b=-3.05105 error=0.00824\n",
      "Epoch 42 h=0.28579 w=1.41292 b=-3.05805 error=0.00736\n",
      "Epoch 43 h=0.28117 w=1.40308 b=-3.06461 error=0.00659\n",
      "Epoch 44 h=0.27688 w=1.39384 b=-3.07077 error=0.00591\n",
      "Epoch 45 h=0.27289 w=1.38517 b=-3.07656 error=0.00531\n",
      "Epoch 46 h=0.26918 w=1.37700 b=-3.08200 error=0.00479\n",
      "Epoch 47 h=0.26571 w=1.36931 b=-3.08713 error=0.00432\n",
      "Epoch 48 h=0.26247 w=1.36205 b=-3.09196 error=0.00390\n",
      "Epoch 49 h=0.25944 w=1.35520 b=-3.09653 error=0.00353\n",
      "Epoch 50 h=0.25660 w=1.34872 b=-3.10085 error=0.00320\n",
      "Epoch 51 h=0.25393 w=1.34259 b=-3.10494 error=0.00291\n",
      "Epoch 52 h=0.25142 w=1.33679 b=-3.10881 error=0.00264\n",
      "Epoch 53 h=0.24906 w=1.33128 b=-3.11248 error=0.00241\n",
      "Epoch 54 h=0.24684 w=1.32606 b=-3.11596 error=0.00219\n",
      "Epoch 55 h=0.24474 w=1.32110 b=-3.11927 error=0.00200\n",
      "Epoch 56 h=0.24276 w=1.31638 b=-3.12241 error=0.00183\n",
      "Epoch 57 h=0.24088 w=1.31189 b=-3.12540 error=0.00167\n",
      "Epoch 58 h=0.23911 w=1.30762 b=-3.12825 error=0.00153\n",
      "Epoch 59 h=0.23743 w=1.30356 b=-3.13096 error=0.00140\n",
      "Epoch 60 h=0.23584 w=1.29968 b=-3.13354 error=0.00128\n",
      "Epoch 61 h=0.23433 w=1.29599 b=-3.13601 error=0.00118\n",
      "Epoch 62 h=0.23290 w=1.29246 b=-3.13836 error=0.00108\n",
      "Epoch 63 h=0.23153 w=1.28909 b=-3.14060 error=0.00099\n",
      "Epoch 64 h=0.23024 w=1.28588 b=-3.14275 error=0.00091\n",
      "Epoch 65 h=0.22901 w=1.28281 b=-3.14480 error=0.00084\n",
      "Epoch 66 h=0.22783 w=1.27987 b=-3.14675 error=0.00077\n",
      "Epoch 67 h=0.22672 w=1.27706 b=-3.14863 error=0.00071\n",
      "Epoch 68 h=0.22565 w=1.27437 b=-3.15042 error=0.00066\n",
      "Epoch 69 h=0.22463 w=1.27179 b=-3.15214 error=0.00061\n",
      "Epoch 70 h=0.22366 w=1.26933 b=-3.15378 error=0.00056\n",
      "Epoch 71 h=0.22274 w=1.26697 b=-3.15535 error=0.00052\n",
      "Epoch 72 h=0.22185 w=1.26470 b=-3.15686 error=0.00048\n",
      "Epoch 73 h=0.22101 w=1.26253 b=-3.15831 error=0.00044\n",
      "Epoch 74 h=0.22020 w=1.26045 b=-3.15970 error=0.00041\n",
      "Epoch 75 h=0.21943 w=1.25846 b=-3.16103 error=0.00038\n",
      "Epoch 76 h=0.21869 w=1.25654 b=-3.16231 error=0.00035\n",
      "Epoch 77 h=0.21798 w=1.25470 b=-3.16353 error=0.00032\n",
      "Epoch 78 h=0.21730 w=1.25294 b=-3.16471 error=0.00030\n",
      "Epoch 79 h=0.21665 w=1.25124 b=-3.16584 error=0.00028\n",
      "Epoch 80 h=0.21603 w=1.24961 b=-3.16692 error=0.00026\n",
      "Epoch 81 h=0.21543 w=1.24805 b=-3.16797 error=0.00024\n",
      "Epoch 82 h=0.21486 w=1.24654 b=-3.16897 error=0.00022\n",
      "Epoch 83 h=0.21431 w=1.24510 b=-3.16993 error=0.00020\n",
      "Epoch 84 h=0.21378 w=1.24371 b=-3.17086 error=0.00019\n",
      "Epoch 85 h=0.21328 w=1.24237 b=-3.17175 error=0.00018\n",
      "Epoch 86 h=0.21279 w=1.24109 b=-3.17261 error=0.00016\n",
      "Epoch 87 h=0.21232 w=1.23985 b=-3.17343 error=0.00015\n",
      "Epoch 88 h=0.21188 w=1.23866 b=-3.17423 error=0.00014\n",
      "Epoch 89 h=0.21145 w=1.23752 b=-3.17499 error=0.00013\n",
      "Epoch 90 h=0.21103 w=1.23641 b=-3.17572 error=0.00012\n",
      "Epoch 91 h=0.21064 w=1.23535 b=-3.17643 error=0.00011\n",
      "Epoch 92 h=0.21025 w=1.23433 b=-3.17711 error=0.00011\n",
      "Epoch 93 h=0.20989 w=1.23335 b=-3.17777 error=0.00010\n",
      "Epoch 94 h=0.20953 w=1.23240 b=-3.17840 error=0.00009\n",
      "Epoch 95 h=0.20919 w=1.23149 b=-3.17901 error=0.00008\n",
      "Epoch 96 h=0.20887 w=1.23061 b=-3.17959 error=0.00008\n",
      "Epoch 97 h=0.20855 w=1.22976 b=-3.18016 error=0.00007\n",
      "Epoch 98 h=0.20825 w=1.22895 b=-3.18070 error=0.00007\n",
      "Epoch 99 h=0.20796 w=1.22816 b=-3.18123 error=0.00006\n",
      "Epoch 100 h=0.20768 w=1.22740 b=-3.18173 error=0.00006\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([1.5]))\n",
    "y = Variable(torch.Tensor([0.2]))\n",
    "b = Variable(torch.Tensor([-2.0]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([3.0]), requires_grad=True)\n",
    "\n",
    "alpha = 0.2\n",
    "for i in range(100):\n",
    "    h = torch.sigmoid(w * x + b)\n",
    "    error = (y - h)**2\n",
    "    error.backward()\n",
    "    \n",
    "    w.data.sub_(alpha * w.grad.data)\n",
    "    w.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "    b.data.sub_(alpha * b.grad.data)\n",
    "    b.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "    print('Epoch {} h={:.05f} w={:.05f} b={:.05f} error={:.05f}'.format(i+1, h.data[0], w.data[0], b.data[0], error.data[0]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayez différentes valeurs pour le paramètre alpha: 0.01, 0.1, 1, 10, 100. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 h=0.92414 w=2.99848 b=-2.00102 error=0.52438\n",
      "Epoch 2 h=0.92391 w=2.99695 b=-2.00203 error=0.52405\n",
      "Epoch 3 h=0.92368 w=2.99542 b=-2.00305 error=0.52371\n",
      "Epoch 4 h=0.92344 w=2.99389 b=-2.00408 error=0.52337\n",
      "Epoch 5 h=0.92321 w=2.99235 b=-2.00510 error=0.52303\n",
      "Epoch 6 h=0.92297 w=2.99081 b=-2.00613 error=0.52269\n",
      "Epoch 7 h=0.92273 w=2.98926 b=-2.00716 error=0.52234\n",
      "Epoch 8 h=0.92249 w=2.98771 b=-2.00819 error=0.52200\n",
      "Epoch 9 h=0.92225 w=2.98616 b=-2.00923 error=0.52165\n",
      "Epoch 10 h=0.92201 w=2.98460 b=-2.01027 error=0.52130\n",
      "Epoch 11 h=0.92177 w=2.98304 b=-2.01131 error=0.52095\n",
      "Epoch 12 h=0.92152 w=2.98147 b=-2.01235 error=0.52060\n",
      "Epoch 13 h=0.92128 w=2.97990 b=-2.01340 error=0.52024\n",
      "Epoch 14 h=0.92103 w=2.97833 b=-2.01445 error=0.51989\n",
      "Epoch 15 h=0.92078 w=2.97675 b=-2.01550 error=0.51953\n",
      "Epoch 16 h=0.92053 w=2.97517 b=-2.01655 error=0.51917\n",
      "Epoch 17 h=0.92028 w=2.97359 b=-2.01761 error=0.51881\n",
      "Epoch 18 h=0.92003 w=2.97200 b=-2.01867 error=0.51844\n",
      "Epoch 19 h=0.91978 w=2.97040 b=-2.01973 error=0.51808\n",
      "Epoch 20 h=0.91952 w=2.96881 b=-2.02080 error=0.51771\n",
      "Epoch 21 h=0.91927 w=2.96720 b=-2.02186 error=0.51734\n",
      "Epoch 22 h=0.91901 w=2.96560 b=-2.02293 error=0.51697\n",
      "Epoch 23 h=0.91875 w=2.96399 b=-2.02401 error=0.51660\n",
      "Epoch 24 h=0.91849 w=2.96237 b=-2.02508 error=0.51622\n",
      "Epoch 25 h=0.91823 w=2.96076 b=-2.02616 error=0.51585\n",
      "Epoch 26 h=0.91796 w=2.95914 b=-2.02724 error=0.51547\n",
      "Epoch 27 h=0.91770 w=2.95751 b=-2.02833 error=0.51509\n",
      "Epoch 28 h=0.91743 w=2.95588 b=-2.02941 error=0.51471\n",
      "Epoch 29 h=0.91716 w=2.95424 b=-2.03050 error=0.51432\n",
      "Epoch 30 h=0.91689 w=2.95261 b=-2.03160 error=0.51394\n",
      "Epoch 31 h=0.91662 w=2.95096 b=-2.03269 error=0.51355\n",
      "Epoch 32 h=0.91635 w=2.94931 b=-2.03379 error=0.51316\n",
      "Epoch 33 h=0.91608 w=2.94766 b=-2.03489 error=0.51276\n",
      "Epoch 34 h=0.91580 w=2.94601 b=-2.03599 error=0.51237\n",
      "Epoch 35 h=0.91552 w=2.94435 b=-2.03710 error=0.51197\n",
      "Epoch 36 h=0.91524 w=2.94268 b=-2.03821 error=0.51157\n",
      "Epoch 37 h=0.91496 w=2.94101 b=-2.03932 error=0.51117\n",
      "Epoch 38 h=0.91468 w=2.93934 b=-2.04044 error=0.51077\n",
      "Epoch 39 h=0.91440 w=2.93766 b=-2.04156 error=0.51037\n",
      "Epoch 40 h=0.91411 w=2.93598 b=-2.04268 error=0.50996\n",
      "Epoch 41 h=0.91383 w=2.93429 b=-2.04380 error=0.50955\n",
      "Epoch 42 h=0.91354 w=2.93260 b=-2.04493 error=0.50914\n",
      "Epoch 43 h=0.91325 w=2.93091 b=-2.04606 error=0.50873\n",
      "Epoch 44 h=0.91296 w=2.92921 b=-2.04719 error=0.50831\n",
      "Epoch 45 h=0.91267 w=2.92751 b=-2.04833 error=0.50789\n",
      "Epoch 46 h=0.91237 w=2.92580 b=-2.04947 error=0.50747\n",
      "Epoch 47 h=0.91207 w=2.92408 b=-2.05061 error=0.50705\n",
      "Epoch 48 h=0.91178 w=2.92237 b=-2.05176 error=0.50662\n",
      "Epoch 49 h=0.91148 w=2.92064 b=-2.05290 error=0.50620\n",
      "Epoch 50 h=0.91117 w=2.91892 b=-2.05405 error=0.50577\n",
      "Epoch 51 h=0.91087 w=2.91719 b=-2.05521 error=0.50534\n",
      "Epoch 52 h=0.91057 w=2.91545 b=-2.05637 error=0.50490\n",
      "Epoch 53 h=0.91026 w=2.91371 b=-2.05753 error=0.50447\n",
      "Epoch 54 h=0.90995 w=2.91196 b=-2.05869 error=0.50403\n",
      "Epoch 55 h=0.90964 w=2.91021 b=-2.05986 error=0.50359\n",
      "Epoch 56 h=0.90933 w=2.90846 b=-2.06103 error=0.50315\n",
      "Epoch 57 h=0.90901 w=2.90670 b=-2.06220 error=0.50270\n",
      "Epoch 58 h=0.90870 w=2.90494 b=-2.06338 error=0.50225\n",
      "Epoch 59 h=0.90838 w=2.90317 b=-2.06455 error=0.50180\n",
      "Epoch 60 h=0.90806 w=2.90139 b=-2.06574 error=0.50135\n",
      "Epoch 61 h=0.90774 w=2.89962 b=-2.06692 error=0.50090\n",
      "Epoch 62 h=0.90742 w=2.89783 b=-2.06811 error=0.50044\n",
      "Epoch 63 h=0.90709 w=2.89605 b=-2.06930 error=0.49998\n",
      "Epoch 64 h=0.90677 w=2.89425 b=-2.07050 error=0.49952\n",
      "Epoch 65 h=0.90644 w=2.89246 b=-2.07170 error=0.49905\n",
      "Epoch 66 h=0.90611 w=2.89065 b=-2.07290 error=0.49859\n",
      "Epoch 67 h=0.90577 w=2.88885 b=-2.07410 error=0.49812\n",
      "Epoch 68 h=0.90544 w=2.88703 b=-2.07531 error=0.49764\n",
      "Epoch 69 h=0.90510 w=2.88522 b=-2.07652 error=0.49717\n",
      "Epoch 70 h=0.90476 w=2.88340 b=-2.07774 error=0.49669\n",
      "Epoch 71 h=0.90442 w=2.88157 b=-2.07895 error=0.49621\n",
      "Epoch 72 h=0.90408 w=2.87974 b=-2.08017 error=0.49573\n",
      "Epoch 73 h=0.90373 w=2.87790 b=-2.08140 error=0.49524\n",
      "Epoch 74 h=0.90339 w=2.87606 b=-2.08263 error=0.49475\n",
      "Epoch 75 h=0.90304 w=2.87421 b=-2.08386 error=0.49426\n",
      "Epoch 76 h=0.90269 w=2.87236 b=-2.08509 error=0.49377\n",
      "Epoch 77 h=0.90234 w=2.87050 b=-2.08633 error=0.49328\n",
      "Epoch 78 h=0.90198 w=2.86864 b=-2.08757 error=0.49278\n",
      "Epoch 79 h=0.90162 w=2.86677 b=-2.08882 error=0.49228\n",
      "Epoch 80 h=0.90126 w=2.86490 b=-2.09006 error=0.49177\n",
      "Epoch 81 h=0.90090 w=2.86303 b=-2.09132 error=0.49126\n",
      "Epoch 82 h=0.90054 w=2.86114 b=-2.09257 error=0.49075\n",
      "Epoch 83 h=0.90017 w=2.85926 b=-2.09383 error=0.49024\n",
      "Epoch 84 h=0.89980 w=2.85736 b=-2.09509 error=0.48973\n",
      "Epoch 85 h=0.89943 w=2.85546 b=-2.09636 error=0.48921\n",
      "Epoch 86 h=0.89906 w=2.85356 b=-2.09763 error=0.48869\n",
      "Epoch 87 h=0.89869 w=2.85165 b=-2.09890 error=0.48816\n",
      "Epoch 88 h=0.89831 w=2.84974 b=-2.10017 error=0.48764\n",
      "Epoch 89 h=0.89793 w=2.84782 b=-2.10145 error=0.48711\n",
      "Epoch 90 h=0.89755 w=2.84590 b=-2.10274 error=0.48657\n",
      "Epoch 91 h=0.89716 w=2.84397 b=-2.10402 error=0.48604\n",
      "Epoch 92 h=0.89678 w=2.84203 b=-2.10531 error=0.48550\n",
      "Epoch 93 h=0.89639 w=2.84009 b=-2.10661 error=0.48496\n",
      "Epoch 94 h=0.89600 w=2.83815 b=-2.10790 error=0.48441\n",
      "Epoch 95 h=0.89560 w=2.83619 b=-2.10920 error=0.48387\n",
      "Epoch 96 h=0.89521 w=2.83424 b=-2.11051 error=0.48332\n",
      "Epoch 97 h=0.89481 w=2.83228 b=-2.11182 error=0.48276\n",
      "Epoch 98 h=0.89441 w=2.83031 b=-2.11313 error=0.48220\n",
      "Epoch 99 h=0.89401 w=2.82834 b=-2.11444 error=0.48164\n",
      "Epoch 100 h=0.89360 w=2.82636 b=-2.11576 error=0.48108\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([1.5]))\n",
    "y = Variable(torch.Tensor([0.2]))\n",
    "b = Variable(torch.Tensor([-2.0]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([3.0]), requires_grad=True)\n",
    "\n",
    "alpha = 0.01\n",
    "for i in range(100):\n",
    "    h = torch.sigmoid(w * x + b)\n",
    "    error = (y - h)**2\n",
    "    error.backward()\n",
    "    \n",
    "    w.data.sub_(alpha * w.grad.data)\n",
    "    w.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "    b.data.sub_(alpha * b.grad.data)\n",
    "    b.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "    print('Epoch {} h={:.05f} w={:.05f} b={:.05f} error={:.05f}'.format(i+1, h.data[0], w.data[0], b.data[0], error.data[0]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 h=0.92414 w=2.98477 b=-2.01015 error=0.52438\n",
      "Epoch 2 h=0.92180 w=2.96916 b=-2.02056 error=0.52099\n",
      "Epoch 3 h=0.91932 w=2.95316 b=-2.03123 error=0.51743\n",
      "Epoch 4 h=0.91671 w=2.93674 b=-2.04217 error=0.51368\n",
      "Epoch 5 h=0.91396 w=2.91990 b=-2.05340 error=0.50973\n",
      "Epoch 6 h=0.91104 w=2.90261 b=-2.06493 error=0.50558\n",
      "Epoch 7 h=0.90796 w=2.88486 b=-2.07676 error=0.50121\n",
      "Epoch 8 h=0.90470 w=2.86663 b=-2.08891 error=0.49660\n",
      "Epoch 9 h=0.90124 w=2.84791 b=-2.10140 error=0.49173\n",
      "Epoch 10 h=0.89757 w=2.82867 b=-2.11422 error=0.48660\n",
      "Epoch 11 h=0.89367 w=2.80889 b=-2.12741 error=0.48118\n",
      "Epoch 12 h=0.88953 w=2.78856 b=-2.14096 error=0.47545\n",
      "Epoch 13 h=0.88513 w=2.76766 b=-2.15489 error=0.46940\n",
      "Epoch 14 h=0.88044 w=2.74618 b=-2.16922 error=0.46300\n",
      "Epoch 15 h=0.87545 w=2.72408 b=-2.18395 error=0.45624\n",
      "Epoch 16 h=0.87014 w=2.70136 b=-2.19909 error=0.44908\n",
      "Epoch 17 h=0.86447 w=2.67801 b=-2.21466 error=0.44153\n",
      "Epoch 18 h=0.85844 w=2.65401 b=-2.23066 error=0.43354\n",
      "Epoch 19 h=0.85200 w=2.62934 b=-2.24711 error=0.42510\n",
      "Epoch 20 h=0.84513 w=2.60401 b=-2.26399 error=0.41619\n",
      "Epoch 21 h=0.83781 w=2.57801 b=-2.28133 error=0.40680\n",
      "Epoch 22 h=0.83001 w=2.55134 b=-2.29911 error=0.39691\n",
      "Epoch 23 h=0.82170 w=2.52402 b=-2.31732 error=0.38651\n",
      "Epoch 24 h=0.81286 w=2.49605 b=-2.33597 error=0.37560\n",
      "Epoch 25 h=0.80347 w=2.46746 b=-2.35503 error=0.36417\n",
      "Epoch 26 h=0.79350 w=2.43829 b=-2.37448 error=0.35224\n",
      "Epoch 27 h=0.78295 w=2.40857 b=-2.39429 error=0.33983\n",
      "Epoch 28 h=0.77181 w=2.37835 b=-2.41443 error=0.32697\n",
      "Epoch 29 h=0.76008 w=2.34771 b=-2.43486 error=0.31369\n",
      "Epoch 30 h=0.74776 w=2.31672 b=-2.45552 error=0.30004\n",
      "Epoch 31 h=0.73489 w=2.28545 b=-2.47636 error=0.28610\n",
      "Epoch 32 h=0.72148 w=2.25402 b=-2.49732 error=0.27194\n",
      "Epoch 33 h=0.70759 w=2.22251 b=-2.51833 error=0.25765\n",
      "Epoch 34 h=0.69327 w=2.19104 b=-2.53930 error=0.24331\n",
      "Epoch 35 h=0.67858 w=2.15973 b=-2.56018 error=0.22904\n",
      "Epoch 36 h=0.66361 w=2.12868 b=-2.58088 error=0.21493\n",
      "Epoch 37 h=0.64843 w=2.09801 b=-2.60133 error=0.20109\n",
      "Epoch 38 h=0.63314 w=2.06783 b=-2.62145 error=0.18761\n",
      "Epoch 39 h=0.61782 w=2.03823 b=-2.64118 error=0.17457\n",
      "Epoch 40 h=0.60257 w=2.00931 b=-2.66046 error=0.16206\n",
      "Epoch 41 h=0.58747 w=1.98114 b=-2.67924 error=0.15013\n",
      "Epoch 42 h=0.57260 w=1.95379 b=-2.69748 error=0.13883\n",
      "Epoch 43 h=0.55804 w=1.92729 b=-2.71514 error=0.12819\n",
      "Epoch 44 h=0.54384 w=1.90171 b=-2.73220 error=0.11822\n",
      "Epoch 45 h=0.53005 w=1.87704 b=-2.74864 error=0.10894\n",
      "Epoch 46 h=0.51672 w=1.85331 b=-2.76446 error=0.10031\n",
      "Epoch 47 h=0.50388 w=1.83052 b=-2.77965 error=0.09234\n",
      "Epoch 48 h=0.49153 w=1.80866 b=-2.79422 error=0.08499\n",
      "Epoch 49 h=0.47970 w=1.78772 b=-2.80819 error=0.07823\n",
      "Epoch 50 h=0.46839 w=1.76767 b=-2.82155 error=0.07203\n",
      "Epoch 51 h=0.45759 w=1.74849 b=-2.83434 error=0.06635\n",
      "Epoch 52 h=0.44730 w=1.73015 b=-2.84657 error=0.06116\n",
      "Epoch 53 h=0.43749 w=1.71262 b=-2.85826 error=0.05640\n",
      "Epoch 54 h=0.42817 w=1.69586 b=-2.86943 error=0.05206\n",
      "Epoch 55 h=0.41930 w=1.67984 b=-2.88011 error=0.04809\n",
      "Epoch 56 h=0.41087 w=1.66453 b=-2.89032 error=0.04447\n",
      "Epoch 57 h=0.40287 w=1.64988 b=-2.90008 error=0.04116\n",
      "Epoch 58 h=0.39526 w=1.63588 b=-2.90941 error=0.03813\n",
      "Epoch 59 h=0.38803 w=1.62249 b=-2.91834 error=0.03536\n",
      "Epoch 60 h=0.38116 w=1.60967 b=-2.92689 error=0.03282\n",
      "Epoch 61 h=0.37463 w=1.59739 b=-2.93507 error=0.03050\n",
      "Epoch 62 h=0.36842 w=1.58564 b=-2.94291 error=0.02837\n",
      "Epoch 63 h=0.36252 w=1.57437 b=-2.95042 error=0.02641\n",
      "Epoch 64 h=0.35689 w=1.56357 b=-2.95762 error=0.02462\n",
      "Epoch 65 h=0.35154 w=1.55320 b=-2.96453 error=0.02296\n",
      "Epoch 66 h=0.34644 w=1.54326 b=-2.97116 error=0.02144\n",
      "Epoch 67 h=0.34158 w=1.53370 b=-2.97753 error=0.02004\n",
      "Epoch 68 h=0.33694 w=1.52453 b=-2.98365 error=0.01875\n",
      "Epoch 69 h=0.33251 w=1.51570 b=-2.98953 error=0.01756\n",
      "Epoch 70 h=0.32828 w=1.50722 b=-2.99519 error=0.01646\n",
      "Epoch 71 h=0.32424 w=1.49905 b=-3.00063 error=0.01543\n",
      "Epoch 72 h=0.32037 w=1.49119 b=-3.00588 error=0.01449\n",
      "Epoch 73 h=0.31667 w=1.48361 b=-3.01093 error=0.01361\n",
      "Epoch 74 h=0.31313 w=1.47631 b=-3.01579 error=0.01280\n",
      "Epoch 75 h=0.30974 w=1.46927 b=-3.02049 error=0.01204\n",
      "Epoch 76 h=0.30649 w=1.46248 b=-3.02501 error=0.01134\n",
      "Epoch 77 h=0.30337 w=1.45593 b=-3.02938 error=0.01069\n",
      "Epoch 78 h=0.30038 w=1.44960 b=-3.03360 error=0.01008\n",
      "Epoch 79 h=0.29751 w=1.44349 b=-3.03768 error=0.00951\n",
      "Epoch 80 h=0.29475 w=1.43758 b=-3.04162 error=0.00898\n",
      "Epoch 81 h=0.29209 w=1.43187 b=-3.04542 error=0.00848\n",
      "Epoch 82 h=0.28954 w=1.42634 b=-3.04911 error=0.00802\n",
      "Epoch 83 h=0.28708 w=1.42099 b=-3.05267 error=0.00758\n",
      "Epoch 84 h=0.28472 w=1.41582 b=-3.05612 error=0.00718\n",
      "Epoch 85 h=0.28244 w=1.41081 b=-3.05946 error=0.00680\n",
      "Epoch 86 h=0.28024 w=1.40595 b=-3.06270 error=0.00644\n",
      "Epoch 87 h=0.27813 w=1.40124 b=-3.06584 error=0.00610\n",
      "Epoch 88 h=0.27608 w=1.39668 b=-3.06888 error=0.00579\n",
      "Epoch 89 h=0.27411 w=1.39226 b=-3.07183 error=0.00549\n",
      "Epoch 90 h=0.27221 w=1.38797 b=-3.07469 error=0.00521\n",
      "Epoch 91 h=0.27037 w=1.38380 b=-3.07747 error=0.00495\n",
      "Epoch 92 h=0.26859 w=1.37976 b=-3.08016 error=0.00471\n",
      "Epoch 93 h=0.26688 w=1.37583 b=-3.08278 error=0.00447\n",
      "Epoch 94 h=0.26522 w=1.37202 b=-3.08532 error=0.00425\n",
      "Epoch 95 h=0.26361 w=1.36832 b=-3.08779 error=0.00405\n",
      "Epoch 96 h=0.26206 w=1.36472 b=-3.09019 error=0.00385\n",
      "Epoch 97 h=0.26055 w=1.36122 b=-3.09252 error=0.00367\n",
      "Epoch 98 h=0.25909 w=1.35781 b=-3.09479 error=0.00349\n",
      "Epoch 99 h=0.25768 w=1.35450 b=-3.09700 error=0.00333\n",
      "Epoch 100 h=0.25631 w=1.35128 b=-3.09914 error=0.00317\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([1.5]))\n",
    "y = Variable(torch.Tensor([0.2]))\n",
    "b = Variable(torch.Tensor([-2.0]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([3.0]), requires_grad=True)\n",
    "\n",
    "alpha = 0.1\n",
    "for i in range(100):\n",
    "    h = torch.sigmoid(w * x + b)\n",
    "    error = (y - h)**2\n",
    "    error.backward()\n",
    "    \n",
    "    w.data.sub_(alpha * w.grad.data)\n",
    "    w.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "    b.data.sub_(alpha * b.grad.data)\n",
    "    b.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "    print('Epoch {} h={:.05f} w={:.05f} b={:.05f} error={:.05f}'.format(i+1, h.data[0], w.data[0], b.data[0], error.data[0]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand le paramètre alpha est trop grand, les suites w,b ne convergent pas, ou en ce cas, converge à un minimum local.\n",
    "Quand le paramètre est trop petit, la convergence est très lentement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A vous de jouer !\n",
    "\n",
    "Voici un jeu de données synthetique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "X = np.concatenate((\n",
    "    np.random.random(\n",
    "        size=(5000, 2)) - 0.5,\n",
    "    np.random.multivariate_normal(\n",
    "        size=(2500, ),\n",
    "        mean=(-.25, -.25),\n",
    "        cov=((0.005, 0), (0, 0.005))),\n",
    "    np.random.multivariate_normal(\n",
    "        size=(2500, ),\n",
    "        mean=(0.25, 0.25),\n",
    "        cov=((0.005, 0), (0, 0.005))),\n",
    "))\n",
    "#Donc, X_ est de dimension 10000x2????\n",
    "\n",
    "Y = np.concatenate((\n",
    "    np.zeros(shape=(5000, 1)),\n",
    "    np.ones(shape=(5000, 1)),\n",
    "))\n",
    "\n",
    "#Y_ de dimension 10000x1\n",
    "\n",
    "X = np.asarray(X, dtype='float32')#bien X_ thanh 1 mang so thuc,Y_ pareil\n",
    "Y = np.asarray(Y, dtype='float32')\n",
    "\n",
    "# shuffle data points\n",
    "perm = np.random.permutation(X.shape[0])\n",
    "X = X[perm]\n",
    "Y = Y[perm]\n",
    "\n",
    "# numpy arrays -> torch tensors\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "Y = torch.from_numpy(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée deux jeux séparés: train / test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA60AAAHiCAYAAAADNCpPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cc8ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# train / test split\n",
    "n_train = 100\n",
    "n_test = 100\n",
    "\n",
    "X_train = X[:n_train]\n",
    "Y_train = Y[:n_train]\n",
    "\n",
    "X_test = X[n_train:(n_train + n_test)]\n",
    "Y_test = Y[n_train:(n_train + n_test)]\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8), squeeze=False)\n",
    "axes[0, 0].set_title('train')\n",
    "axes[0, 0].scatter(\n",
    "    X_train[:, 0].numpy(),\n",
    "    X_train[:, 1].numpy(),\n",
    "    c=Y_train[:, 0].numpy(),\n",
    "    cmap=cm_bright,\n",
    "    edgecolors='k')\n",
    "axes[0, 1].set_title('test')\n",
    "axes[0, 1].scatter(\n",
    "    X_test[:, 0].numpy(),\n",
    "    X_test[:, 1].numpy(),\n",
    "    c=Y_test[:, 0].numpy(),\n",
    "    cmap=cm_bright,\n",
    "    edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentez un réseau de neurones sans couche cachée, qui prends en entrée $\\mathbf{x} \\in \\mathbb{R}^2$ et produit une seule sortie $\\mathbf{y} \\in [0, 1]$ (sigmoid).\n",
    "\n",
    "Multiplication de matrics: torch.matmul\n",
    "\n",
    "Interdiction d'utiliser les modules haut niveau de pytorch ! (optim, nn etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001\ttrain loss=7.021829\ttest loss=67.705444\t0/1 error=0.420\n",
      "Epoch 002\ttrain loss=6.870937\ttest loss=70.073250\t0/1 error=0.620\n",
      "Epoch 003\ttrain loss=6.844877\ttest loss=66.558731\t0/1 error=0.290\n",
      "Epoch 004\ttrain loss=6.899327\ttest loss=67.863380\t0/1 error=0.370\n",
      "Epoch 005\ttrain loss=6.846813\ttest loss=66.623093\t0/1 error=0.400\n",
      "Epoch 006\ttrain loss=6.869139\ttest loss=66.710007\t0/1 error=0.320\n",
      "Epoch 007\ttrain loss=6.934757\ttest loss=68.696220\t0/1 error=0.590\n",
      "Epoch 008\ttrain loss=6.886077\ttest loss=67.781403\t0/1 error=0.380\n",
      "Epoch 009\ttrain loss=6.808216\ttest loss=66.499252\t0/1 error=0.280\n",
      "Epoch 010\ttrain loss=6.928420\ttest loss=67.248566\t0/1 error=0.400\n",
      "Epoch 011\ttrain loss=6.911923\ttest loss=71.929886\t0/1 error=0.620\n",
      "Epoch 012\ttrain loss=6.902493\ttest loss=68.767815\t0/1 error=0.590\n",
      "Epoch 013\ttrain loss=6.917811\ttest loss=68.455383\t0/1 error=0.520\n",
      "Epoch 014\ttrain loss=6.763779\ttest loss=66.788750\t0/1 error=0.310\n",
      "Epoch 015\ttrain loss=6.852124\ttest loss=67.330719\t0/1 error=0.390\n",
      "Epoch 016\ttrain loss=6.780756\ttest loss=66.350006\t0/1 error=0.370\n",
      "Epoch 017\ttrain loss=6.771703\ttest loss=68.419708\t0/1 error=0.370\n",
      "Epoch 018\ttrain loss=6.869476\ttest loss=68.985260\t0/1 error=0.590\n",
      "Epoch 019\ttrain loss=6.926737\ttest loss=67.318024\t0/1 error=0.380\n",
      "Epoch 020\ttrain loss=6.821434\ttest loss=67.105164\t0/1 error=0.360\n",
      "Epoch 021\ttrain loss=6.775761\ttest loss=66.368820\t0/1 error=0.340\n",
      "Epoch 022\ttrain loss=6.900240\ttest loss=66.567696\t0/1 error=0.290\n",
      "Epoch 023\ttrain loss=6.919960\ttest loss=67.314377\t0/1 error=0.400\n",
      "Epoch 024\ttrain loss=6.875399\ttest loss=66.724106\t0/1 error=0.390\n",
      "Epoch 025\ttrain loss=6.857705\ttest loss=74.604889\t0/1 error=0.590\n",
      "Epoch 026\ttrain loss=6.963870\ttest loss=68.159172\t0/1 error=0.410\n",
      "Epoch 027\ttrain loss=6.970530\ttest loss=73.348625\t0/1 error=0.560\n",
      "Epoch 028\ttrain loss=6.778565\ttest loss=66.895447\t0/1 error=0.420\n",
      "Epoch 029\ttrain loss=6.896006\ttest loss=66.672005\t0/1 error=0.350\n",
      "Epoch 030\ttrain loss=6.789122\ttest loss=66.638878\t0/1 error=0.360\n",
      "Epoch 031\ttrain loss=6.947156\ttest loss=67.177124\t0/1 error=0.430\n",
      "Epoch 032\ttrain loss=6.833668\ttest loss=69.122917\t0/1 error=0.500\n",
      "Epoch 033\ttrain loss=6.916751\ttest loss=68.153824\t0/1 error=0.400\n",
      "Epoch 034\ttrain loss=6.840048\ttest loss=67.663612\t0/1 error=0.400\n",
      "Epoch 035\ttrain loss=6.720771\ttest loss=69.031647\t0/1 error=0.390\n",
      "Epoch 036\ttrain loss=6.921611\ttest loss=66.633156\t0/1 error=0.340\n",
      "Epoch 037\ttrain loss=6.958264\ttest loss=69.645233\t0/1 error=0.560\n",
      "Epoch 038\ttrain loss=6.808752\ttest loss=73.030098\t0/1 error=0.610\n",
      "Epoch 039\ttrain loss=6.774561\ttest loss=66.519135\t0/1 error=0.270\n",
      "Epoch 040\ttrain loss=6.844664\ttest loss=66.575920\t0/1 error=0.320\n",
      "Epoch 041\ttrain loss=6.825365\ttest loss=66.932617\t0/1 error=0.340\n",
      "Epoch 042\ttrain loss=6.738721\ttest loss=67.882080\t0/1 error=0.460\n",
      "Epoch 043\ttrain loss=6.715051\ttest loss=69.455261\t0/1 error=0.580\n",
      "Epoch 044\ttrain loss=6.852546\ttest loss=66.605827\t0/1 error=0.280\n",
      "Epoch 045\ttrain loss=6.858891\ttest loss=66.649971\t0/1 error=0.300\n",
      "Epoch 046\ttrain loss=6.917485\ttest loss=70.624519\t0/1 error=0.600\n",
      "Epoch 047\ttrain loss=6.817914\ttest loss=66.695129\t0/1 error=0.310\n",
      "Epoch 048\ttrain loss=6.869118\ttest loss=67.418747\t0/1 error=0.290\n",
      "Epoch 049\ttrain loss=6.988381\ttest loss=70.610771\t0/1 error=0.630\n",
      "Epoch 050\ttrain loss=6.794972\ttest loss=68.251862\t0/1 error=0.400\n",
      "Epoch 051\ttrain loss=6.754360\ttest loss=66.384544\t0/1 error=0.360\n",
      "Epoch 052\ttrain loss=6.980732\ttest loss=69.444778\t0/1 error=0.590\n",
      "Epoch 053\ttrain loss=6.962292\ttest loss=68.284538\t0/1 error=0.420\n",
      "Epoch 054\ttrain loss=6.890068\ttest loss=66.860535\t0/1 error=0.330\n",
      "Epoch 055\ttrain loss=6.835597\ttest loss=74.048836\t0/1 error=0.610\n",
      "Epoch 056\ttrain loss=6.922078\ttest loss=67.428566\t0/1 error=0.290\n",
      "Epoch 057\ttrain loss=6.961697\ttest loss=69.051544\t0/1 error=0.600\n",
      "Epoch 058\ttrain loss=6.822055\ttest loss=66.604538\t0/1 error=0.310\n",
      "Epoch 059\ttrain loss=6.842465\ttest loss=67.996399\t0/1 error=0.490\n",
      "Epoch 060\ttrain loss=6.830879\ttest loss=68.088524\t0/1 error=0.500\n",
      "Epoch 061\ttrain loss=6.925123\ttest loss=66.756317\t0/1 error=0.320\n",
      "Epoch 062\ttrain loss=6.871927\ttest loss=68.731010\t0/1 error=0.470\n",
      "Epoch 063\ttrain loss=6.817562\ttest loss=66.662231\t0/1 error=0.300\n",
      "Epoch 064\ttrain loss=6.849583\ttest loss=67.131760\t0/1 error=0.400\n",
      "Epoch 065\ttrain loss=6.861387\ttest loss=67.081413\t0/1 error=0.310\n",
      "Epoch 066\ttrain loss=6.878109\ttest loss=66.956970\t0/1 error=0.420\n",
      "Epoch 067\ttrain loss=6.875900\ttest loss=66.523453\t0/1 error=0.420\n",
      "Epoch 068\ttrain loss=6.906299\ttest loss=66.718979\t0/1 error=0.350\n",
      "Epoch 069\ttrain loss=6.892342\ttest loss=67.214043\t0/1 error=0.410\n",
      "Epoch 070\ttrain loss=6.875756\ttest loss=67.787292\t0/1 error=0.380\n",
      "Epoch 071\ttrain loss=6.827201\ttest loss=67.139198\t0/1 error=0.420\n",
      "Epoch 072\ttrain loss=6.928907\ttest loss=67.011490\t0/1 error=0.320\n",
      "Epoch 073\ttrain loss=6.910131\ttest loss=71.354446\t0/1 error=0.620\n",
      "Epoch 074\ttrain loss=6.899915\ttest loss=67.215164\t0/1 error=0.370\n",
      "Epoch 075\ttrain loss=6.862512\ttest loss=66.659058\t0/1 error=0.280\n",
      "Epoch 076\ttrain loss=6.900593\ttest loss=66.900307\t0/1 error=0.340\n",
      "Epoch 077\ttrain loss=6.888565\ttest loss=68.910164\t0/1 error=0.600\n",
      "Epoch 078\ttrain loss=6.880112\ttest loss=72.845734\t0/1 error=0.610\n",
      "Epoch 079\ttrain loss=6.914097\ttest loss=67.785042\t0/1 error=0.400\n",
      "Epoch 080\ttrain loss=6.939583\ttest loss=67.049240\t0/1 error=0.280\n",
      "Epoch 081\ttrain loss=6.799189\ttest loss=67.776276\t0/1 error=0.410\n",
      "Epoch 082\ttrain loss=6.748860\ttest loss=68.365601\t0/1 error=0.460\n",
      "Epoch 083\ttrain loss=6.857358\ttest loss=71.424179\t0/1 error=0.630\n",
      "Epoch 084\ttrain loss=6.850404\ttest loss=66.817299\t0/1 error=0.380\n",
      "Epoch 085\ttrain loss=6.843551\ttest loss=66.583969\t0/1 error=0.340\n",
      "Epoch 086\ttrain loss=6.971854\ttest loss=67.222412\t0/1 error=0.270\n",
      "Epoch 087\ttrain loss=6.817512\ttest loss=69.770935\t0/1 error=0.590\n",
      "Epoch 088\ttrain loss=6.982753\ttest loss=69.539604\t0/1 error=0.630\n",
      "Epoch 089\ttrain loss=6.792174\ttest loss=67.390182\t0/1 error=0.240\n",
      "Epoch 090\ttrain loss=6.972238\ttest loss=66.754105\t0/1 error=0.350\n",
      "Epoch 091\ttrain loss=6.888163\ttest loss=66.577805\t0/1 error=0.390\n",
      "Epoch 092\ttrain loss=6.896099\ttest loss=67.244408\t0/1 error=0.240\n",
      "Epoch 093\ttrain loss=6.823567\ttest loss=66.460548\t0/1 error=0.310\n",
      "Epoch 094\ttrain loss=6.794362\ttest loss=69.107399\t0/1 error=0.570\n",
      "Epoch 095\ttrain loss=6.779286\ttest loss=67.179398\t0/1 error=0.240\n",
      "Epoch 096\ttrain loss=7.061811\ttest loss=69.127235\t0/1 error=0.490\n",
      "Epoch 097\ttrain loss=6.840374\ttest loss=66.614960\t0/1 error=0.330\n",
      "Epoch 098\ttrain loss=6.914855\ttest loss=66.894485\t0/1 error=0.280\n",
      "Epoch 099\ttrain loss=6.806679\ttest loss=68.388214\t0/1 error=0.470\n",
      "Epoch 100\ttrain loss=6.946599\ttest loss=66.614883\t0/1 error=0.300\n",
      "Epoch 101\ttrain loss=6.897396\ttest loss=66.806442\t0/1 error=0.350\n",
      "Epoch 102\ttrain loss=6.821100\ttest loss=67.062141\t0/1 error=0.420\n",
      "Epoch 103\ttrain loss=6.883858\ttest loss=68.783318\t0/1 error=0.570\n",
      "Epoch 104\ttrain loss=6.739229\ttest loss=71.430054\t0/1 error=0.610\n",
      "Epoch 105\ttrain loss=6.855108\ttest loss=71.055626\t0/1 error=0.650\n",
      "Epoch 106\ttrain loss=6.921710\ttest loss=70.487671\t0/1 error=0.570\n",
      "Epoch 107\ttrain loss=6.717192\ttest loss=66.468079\t0/1 error=0.390\n",
      "Epoch 108\ttrain loss=6.887442\ttest loss=68.949791\t0/1 error=0.590\n",
      "Epoch 109\ttrain loss=6.864026\ttest loss=70.064552\t0/1 error=0.570\n",
      "Epoch 110\ttrain loss=6.827942\ttest loss=69.789894\t0/1 error=0.520\n",
      "Epoch 111\ttrain loss=6.675978\ttest loss=67.805504\t0/1 error=0.400\n",
      "Epoch 112\ttrain loss=6.784095\ttest loss=67.760643\t0/1 error=0.460\n",
      "Epoch 113\ttrain loss=6.789426\ttest loss=66.414986\t0/1 error=0.320\n",
      "Epoch 114\ttrain loss=6.759725\ttest loss=66.397896\t0/1 error=0.290\n",
      "Epoch 115\ttrain loss=6.956247\ttest loss=67.063644\t0/1 error=0.350\n",
      "Epoch 116\ttrain loss=6.856797\ttest loss=68.900795\t0/1 error=0.590\n",
      "Epoch 117\ttrain loss=6.927816\ttest loss=71.823143\t0/1 error=0.640\n",
      "Epoch 118\ttrain loss=6.889980\ttest loss=68.383072\t0/1 error=0.530\n",
      "Epoch 119\ttrain loss=6.783833\ttest loss=67.064987\t0/1 error=0.420\n",
      "Epoch 120\ttrain loss=6.869223\ttest loss=68.743637\t0/1 error=0.500\n",
      "Epoch 121\ttrain loss=6.907475\ttest loss=66.706230\t0/1 error=0.400\n",
      "Epoch 122\ttrain loss=6.921684\ttest loss=69.195786\t0/1 error=0.440\n",
      "Epoch 123\ttrain loss=6.775065\ttest loss=66.680046\t0/1 error=0.370\n",
      "Epoch 124\ttrain loss=6.894891\ttest loss=66.498711\t0/1 error=0.330\n",
      "Epoch 125\ttrain loss=6.707578\ttest loss=72.090248\t0/1 error=0.660\n",
      "Epoch 126\ttrain loss=6.818488\ttest loss=66.537315\t0/1 error=0.310\n",
      "Epoch 127\ttrain loss=6.769679\ttest loss=66.421623\t0/1 error=0.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128\ttrain loss=6.786220\ttest loss=68.494308\t0/1 error=0.470\n",
      "Epoch 129\ttrain loss=6.773308\ttest loss=67.730904\t0/1 error=0.450\n",
      "Epoch 130\ttrain loss=6.759100\ttest loss=66.907120\t0/1 error=0.340\n",
      "Epoch 131\ttrain loss=6.767057\ttest loss=66.709831\t0/1 error=0.280\n",
      "Epoch 132\ttrain loss=6.921315\ttest loss=66.762352\t0/1 error=0.310\n",
      "Epoch 133\ttrain loss=6.792761\ttest loss=66.443726\t0/1 error=0.400\n",
      "Epoch 134\ttrain loss=6.745230\ttest loss=70.024887\t0/1 error=0.590\n",
      "Epoch 135\ttrain loss=6.945704\ttest loss=67.908577\t0/1 error=0.330\n",
      "Epoch 136\ttrain loss=6.865392\ttest loss=67.437424\t0/1 error=0.380\n",
      "Epoch 137\ttrain loss=6.898041\ttest loss=67.289543\t0/1 error=0.310\n",
      "Epoch 138\ttrain loss=6.916434\ttest loss=67.007141\t0/1 error=0.310\n",
      "Epoch 139\ttrain loss=6.829764\ttest loss=67.400383\t0/1 error=0.370\n",
      "Epoch 140\ttrain loss=6.881287\ttest loss=66.549759\t0/1 error=0.310\n",
      "Epoch 141\ttrain loss=6.837719\ttest loss=66.798553\t0/1 error=0.310\n",
      "Epoch 142\ttrain loss=6.868121\ttest loss=69.350899\t0/1 error=0.550\n",
      "Epoch 143\ttrain loss=6.881171\ttest loss=66.760811\t0/1 error=0.280\n",
      "Epoch 144\ttrain loss=6.840860\ttest loss=68.471573\t0/1 error=0.550\n",
      "Epoch 145\ttrain loss=6.667777\ttest loss=66.584007\t0/1 error=0.310\n",
      "Epoch 146\ttrain loss=6.820316\ttest loss=66.478874\t0/1 error=0.390\n",
      "Epoch 147\ttrain loss=6.897169\ttest loss=68.208694\t0/1 error=0.450\n",
      "Epoch 148\ttrain loss=6.746265\ttest loss=67.678619\t0/1 error=0.390\n",
      "Epoch 149\ttrain loss=6.882080\ttest loss=68.829903\t0/1 error=0.460\n",
      "Epoch 150\ttrain loss=6.849030\ttest loss=66.902229\t0/1 error=0.420\n",
      "Epoch 151\ttrain loss=6.785029\ttest loss=67.343590\t0/1 error=0.400\n",
      "Epoch 152\ttrain loss=6.871946\ttest loss=70.368149\t0/1 error=0.660\n",
      "Epoch 153\ttrain loss=6.854662\ttest loss=66.586235\t0/1 error=0.310\n",
      "Epoch 154\ttrain loss=6.692965\ttest loss=72.929550\t0/1 error=0.630\n",
      "Epoch 155\ttrain loss=6.923868\ttest loss=68.770416\t0/1 error=0.460\n",
      "Epoch 156\ttrain loss=6.915184\ttest loss=67.174965\t0/1 error=0.230\n",
      "Epoch 157\ttrain loss=6.774154\ttest loss=66.428795\t0/1 error=0.330\n",
      "Epoch 158\ttrain loss=6.800441\ttest loss=71.554939\t0/1 error=0.610\n",
      "Epoch 159\ttrain loss=6.949393\ttest loss=66.723495\t0/1 error=0.320\n",
      "Epoch 160\ttrain loss=6.884842\ttest loss=68.007103\t0/1 error=0.480\n",
      "Epoch 161\ttrain loss=6.742761\ttest loss=68.821602\t0/1 error=0.530\n",
      "Epoch 162\ttrain loss=6.816732\ttest loss=67.001625\t0/1 error=0.260\n",
      "Epoch 163\ttrain loss=6.827316\ttest loss=67.168701\t0/1 error=0.350\n",
      "Epoch 164\ttrain loss=6.914105\ttest loss=67.030472\t0/1 error=0.420\n",
      "Epoch 165\ttrain loss=6.786171\ttest loss=66.529358\t0/1 error=0.400\n",
      "Epoch 166\ttrain loss=6.901689\ttest loss=66.574509\t0/1 error=0.350\n",
      "Epoch 167\ttrain loss=6.811748\ttest loss=66.646240\t0/1 error=0.310\n",
      "Epoch 168\ttrain loss=6.741468\ttest loss=67.161385\t0/1 error=0.320\n",
      "Epoch 169\ttrain loss=7.009988\ttest loss=67.423958\t0/1 error=0.400\n",
      "Epoch 170\ttrain loss=6.792569\ttest loss=67.112381\t0/1 error=0.410\n",
      "Epoch 171\ttrain loss=6.845237\ttest loss=69.636818\t0/1 error=0.490\n",
      "Epoch 172\ttrain loss=6.909447\ttest loss=67.552795\t0/1 error=0.410\n",
      "Epoch 173\ttrain loss=6.859117\ttest loss=67.584900\t0/1 error=0.390\n",
      "Epoch 174\ttrain loss=6.884658\ttest loss=69.416916\t0/1 error=0.590\n",
      "Epoch 175\ttrain loss=6.817345\ttest loss=73.328430\t0/1 error=0.620\n",
      "Epoch 176\ttrain loss=6.830017\ttest loss=68.208572\t0/1 error=0.460\n",
      "Epoch 177\ttrain loss=6.830796\ttest loss=72.238083\t0/1 error=0.620\n",
      "Epoch 178\ttrain loss=6.853818\ttest loss=67.231522\t0/1 error=0.310\n",
      "Epoch 179\ttrain loss=6.833146\ttest loss=67.794365\t0/1 error=0.380\n",
      "Epoch 180\ttrain loss=6.958511\ttest loss=67.919998\t0/1 error=0.380\n",
      "Epoch 181\ttrain loss=6.896924\ttest loss=67.209915\t0/1 error=0.310\n",
      "Epoch 182\ttrain loss=6.780626\ttest loss=67.550674\t0/1 error=0.390\n",
      "Epoch 183\ttrain loss=6.895132\ttest loss=66.943428\t0/1 error=0.340\n",
      "Epoch 184\ttrain loss=6.926828\ttest loss=69.711212\t0/1 error=0.640\n",
      "Epoch 185\ttrain loss=6.846381\ttest loss=66.553116\t0/1 error=0.330\n",
      "Epoch 186\ttrain loss=6.879937\ttest loss=67.891273\t0/1 error=0.410\n",
      "Epoch 187\ttrain loss=6.832488\ttest loss=67.095207\t0/1 error=0.340\n",
      "Epoch 188\ttrain loss=6.935145\ttest loss=67.567009\t0/1 error=0.390\n",
      "Epoch 189\ttrain loss=6.902808\ttest loss=66.980453\t0/1 error=0.320\n",
      "Epoch 190\ttrain loss=6.993684\ttest loss=67.696724\t0/1 error=0.410\n",
      "Epoch 191\ttrain loss=6.831796\ttest loss=66.867477\t0/1 error=0.430\n",
      "Epoch 192\ttrain loss=6.827015\ttest loss=66.700287\t0/1 error=0.310\n",
      "Epoch 193\ttrain loss=6.806701\ttest loss=66.425369\t0/1 error=0.360\n",
      "Epoch 194\ttrain loss=6.807135\ttest loss=67.224968\t0/1 error=0.390\n",
      "Epoch 195\ttrain loss=6.824096\ttest loss=66.438721\t0/1 error=0.350\n",
      "Epoch 196\ttrain loss=6.935866\ttest loss=67.038956\t0/1 error=0.250\n",
      "Epoch 197\ttrain loss=6.823339\ttest loss=67.653503\t0/1 error=0.380\n",
      "Epoch 198\ttrain loss=6.975794\ttest loss=66.996330\t0/1 error=0.400\n",
      "Epoch 199\ttrain loss=6.860226\ttest loss=68.979645\t0/1 error=0.600\n",
      "Epoch 200\ttrain loss=6.814789\ttest loss=69.955170\t0/1 error=0.660\n",
      "Epoch 201\ttrain loss=6.890007\ttest loss=70.508827\t0/1 error=0.650\n",
      "Epoch 202\ttrain loss=6.872352\ttest loss=67.428009\t0/1 error=0.410\n",
      "Epoch 203\ttrain loss=6.793306\ttest loss=66.466850\t0/1 error=0.280\n",
      "Epoch 204\ttrain loss=6.840011\ttest loss=69.382095\t0/1 error=0.590\n",
      "Epoch 205\ttrain loss=6.958671\ttest loss=70.847206\t0/1 error=0.600\n",
      "Epoch 206\ttrain loss=6.802761\ttest loss=67.500778\t0/1 error=0.310\n",
      "Epoch 207\ttrain loss=6.800558\ttest loss=66.511711\t0/1 error=0.310\n",
      "Epoch 208\ttrain loss=6.882239\ttest loss=67.102173\t0/1 error=0.270\n",
      "Epoch 209\ttrain loss=6.866315\ttest loss=67.400711\t0/1 error=0.390\n",
      "Epoch 210\ttrain loss=6.862476\ttest loss=70.562347\t0/1 error=0.600\n",
      "Epoch 211\ttrain loss=6.843799\ttest loss=66.506584\t0/1 error=0.380\n",
      "Epoch 212\ttrain loss=6.785179\ttest loss=66.901215\t0/1 error=0.420\n",
      "Epoch 213\ttrain loss=6.798639\ttest loss=66.568985\t0/1 error=0.300\n",
      "Epoch 214\ttrain loss=6.984517\ttest loss=69.395882\t0/1 error=0.590\n",
      "Epoch 215\ttrain loss=6.828778\ttest loss=67.587593\t0/1 error=0.380\n",
      "Epoch 216\ttrain loss=7.009250\ttest loss=67.987068\t0/1 error=0.340\n",
      "Epoch 217\ttrain loss=6.757864\ttest loss=67.442123\t0/1 error=0.370\n",
      "Epoch 218\ttrain loss=6.884539\ttest loss=66.697884\t0/1 error=0.320\n",
      "Epoch 219\ttrain loss=6.863975\ttest loss=67.575272\t0/1 error=0.380\n",
      "Epoch 220\ttrain loss=6.785730\ttest loss=69.317009\t0/1 error=0.590\n",
      "Epoch 221\ttrain loss=6.892611\ttest loss=66.588631\t0/1 error=0.280\n",
      "Epoch 222\ttrain loss=6.808217\ttest loss=68.271858\t0/1 error=0.400\n",
      "Epoch 223\ttrain loss=6.819149\ttest loss=67.822762\t0/1 error=0.470\n",
      "Epoch 224\ttrain loss=6.855550\ttest loss=67.044388\t0/1 error=0.350\n",
      "Epoch 225\ttrain loss=6.799619\ttest loss=68.398178\t0/1 error=0.410\n",
      "Epoch 226\ttrain loss=6.883154\ttest loss=67.704849\t0/1 error=0.380\n",
      "Epoch 227\ttrain loss=6.871109\ttest loss=67.206451\t0/1 error=0.410\n",
      "Epoch 228\ttrain loss=6.893445\ttest loss=67.430771\t0/1 error=0.400\n",
      "Epoch 229\ttrain loss=6.967822\ttest loss=68.710945\t0/1 error=0.590\n",
      "Epoch 230\ttrain loss=6.999155\ttest loss=67.017769\t0/1 error=0.350\n",
      "Epoch 231\ttrain loss=6.884480\ttest loss=67.312904\t0/1 error=0.410\n",
      "Epoch 232\ttrain loss=6.808904\ttest loss=67.482437\t0/1 error=0.380\n",
      "Epoch 233\ttrain loss=6.904540\ttest loss=66.972763\t0/1 error=0.340\n",
      "Epoch 234\ttrain loss=6.928517\ttest loss=66.639023\t0/1 error=0.360\n",
      "Epoch 235\ttrain loss=6.914902\ttest loss=69.600807\t0/1 error=0.600\n",
      "Epoch 236\ttrain loss=6.870948\ttest loss=70.652512\t0/1 error=0.650\n",
      "Epoch 237\ttrain loss=6.922260\ttest loss=68.480728\t0/1 error=0.450\n",
      "Epoch 238\ttrain loss=6.842753\ttest loss=71.330452\t0/1 error=0.600\n",
      "Epoch 239\ttrain loss=6.793404\ttest loss=68.202774\t0/1 error=0.420\n",
      "Epoch 240\ttrain loss=6.949012\ttest loss=70.167038\t0/1 error=0.650\n",
      "Epoch 241\ttrain loss=6.891897\ttest loss=66.708252\t0/1 error=0.320\n",
      "Epoch 242\ttrain loss=6.839020\ttest loss=67.425987\t0/1 error=0.380\n",
      "Epoch 243\ttrain loss=6.794940\ttest loss=66.440109\t0/1 error=0.280\n",
      "Epoch 244\ttrain loss=6.789492\ttest loss=67.094749\t0/1 error=0.400\n",
      "Epoch 245\ttrain loss=6.841017\ttest loss=66.857368\t0/1 error=0.370\n",
      "Epoch 246\ttrain loss=6.865593\ttest loss=69.468163\t0/1 error=0.620\n",
      "Epoch 247\ttrain loss=6.887883\ttest loss=67.252296\t0/1 error=0.320\n",
      "Epoch 248\ttrain loss=6.819059\ttest loss=66.500908\t0/1 error=0.430\n",
      "Epoch 249\ttrain loss=6.960272\ttest loss=66.947784\t0/1 error=0.350\n",
      "Epoch 250\ttrain loss=6.905744\ttest loss=67.654991\t0/1 error=0.390\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_in = 2\n",
    "params = []\n",
    "\n",
    "n_out = 1\n",
    "W = Variable(torch.normal(torch.zeros(n_in, n_out), np.sqrt(2/(n_in + n_out))), requires_grad=True)\n",
    "b = Variable(torch.zeros(n_out), requires_grad=True)\n",
    "\n",
    "def forward(X):\n",
    "    H  = torch.sigmoid(torch.mm(X,W)  + b)\n",
    "    \n",
    "    return H #O day H kha nang la ham sigmoid theo X, nhung con thieu W va b. Chac dung o tren\n",
    "\n",
    "# Dung la ham sigmoid.\n",
    "\n",
    "def L(H, Y, eps=1e-08):\n",
    "    loss = sum(-Y * torch.log(H + eps) - (1 - Y) * torch.log(1 - H + eps))  # log-likelikood\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "n_epochs = 250\n",
    "epoch_n_batches = 100\n",
    "train_batch_size = 10\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(n_epochs):\n",
    "\n",
    "    train_loss = 0.\n",
    "\n",
    "    for j in range(epoch_n_batches):\n",
    "\n",
    "        # Prepare next mini-batch\n",
    "        mb_idxs = torch.multinomial(torch.ones(n_train), train_batch_size, replacement=True)\n",
    "        #mb_idxs pour choisir aléatoirement train_batch_size éléments dans l'intervalle 0, n_train\n",
    "        #afin de choisir aléatoirement un petit échantillon pour mini path\n",
    "        X_mb = Variable(X_train[mb_idxs])\n",
    "        Y_mb = Variable(Y_train[mb_idxs])\n",
    "\n",
    "        # Forward pass\n",
    "        Y_prob_mb = forward(X_mb)\n",
    "        \n",
    "        loss = L(Y_prob_mb,Y_mb)\n",
    "        loss.backward()\n",
    "        W.data.sub_(alpha * W.grad.data)\n",
    "        W.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "        b.data.sub_(alpha * b.grad.data)\n",
    "        b.grad.data.zero_()  # must reset to 0 before next pass\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "\n",
    "    train_loss /= epoch_n_batches\n",
    "\n",
    "    # Forward pass\n",
    "    Y_test_prob = forward(Variable(X_test)).data\n",
    "    test_loss = L(Y_test_prob, Y_test).mean()\n",
    "    \n",
    "    # Compute expected 0/1 error\n",
    "    Y_test_pred = (Y_test_prob > 0.5).type(torch.FloatTensor)\n",
    "    test_err = torch.abs(Y_test - Y_test_pred).mean()\n",
    "\n",
    "    print('Epoch {:03d}\\ttrain loss={:.06f}\\ttest loss={:.06f}\\t0/1 error={:.03f}'.format(\n",
    "        i + 1, train_loss, test_loss, test_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisez la distribution apprise par votre modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAAHiCAYAAADVkfAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNwMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e52cac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_size = (100, 100)\n",
    "x1, x2 = np.meshgrid(np.linspace(X_[:, 0].min()-0.1, X_[:, 0].max()+0.1, map_size[0]),\n",
    "                     np.linspace(X_[:, 1].min()-0.1, X_[:, 1].max()+0.1, map_size[1]))\n",
    "X_map = torch.from_numpy(np.asarray(np.c_[x1.ravel(), x2.ravel()], dtype='float32'))\n",
    "\n",
    "Y_prob_map = forward(Variable(X_map)).data\n",
    "\n",
    "Y_train_pred = (forward(Variable(X_train)).data > 0.5).type(torch.FloatTensor)\n",
    "train_err = torch.abs(Y_train - Y_train_pred).mean()\n",
    "\n",
    "Y_test_pred = (forward(Variable(X_test)).data > 0.5).type(torch.FloatTensor)\n",
    "test_err = torch.abs(Y_test - Y_test_pred).mean()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8), squeeze=False)\n",
    "axes[0, 0].set_title('train accuracy={:.03f}'.format(1 - train_err))\n",
    "axes[0, 0].contourf(\n",
    "    x1,\n",
    "    x2,\n",
    "    Y_prob_map.numpy().reshape(map_size),\n",
    "    cmap=cm, vmin=0, vmax=1,\n",
    "    alpha=.8)\n",
    "axes[0, 0].scatter(\n",
    "    X_train[:, 0].numpy(),\n",
    "    X_train[:, 1].numpy(),\n",
    "    c=Y_train[:, 0].numpy(),\n",
    "    cmap=cm_bright,\n",
    "    edgecolors='k')\n",
    "axes[0, 1].set_title('test accuracy={:.03f}'.format(1 - test_err))\n",
    "axes[0, 1].contourf(\n",
    "    x1,\n",
    "    x2,\n",
    "    Y_prob_map.numpy().reshape(map_size),\n",
    "    cmap=cm, vmin=0, vmax=1,\n",
    "    alpha=.8)\n",
    "axes[0, 1].scatter(\n",
    "    X_test[:, 0].numpy(),\n",
    "    X_test[:, 1].numpy(),\n",
    "    c=Y_test[:, 0].numpy(),\n",
    "    cmap=cm_bright,\n",
    "    edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutez une couche cachée de taille 10 à votre réseau de neurones, avec la fonction d'activation relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: améliorez votre réseau de neurones: plus de neurones cachés, deuxième couche cachée etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001\ttrain loss=7.085681\ttest loss=68.080780\t0/1 error=0.440\n",
      "Epoch 002\ttrain loss=7.137445\ttest loss=75.204773\t0/1 error=0.560\n",
      "Epoch 003\ttrain loss=6.998565\ttest loss=67.134903\t0/1 error=0.350\n",
      "Epoch 004\ttrain loss=7.018527\ttest loss=66.529030\t0/1 error=0.360\n",
      "Epoch 005\ttrain loss=6.964293\ttest loss=67.172211\t0/1 error=0.390\n",
      "Epoch 006\ttrain loss=6.901138\ttest loss=65.989502\t0/1 error=0.330\n",
      "Epoch 007\ttrain loss=6.840745\ttest loss=65.277061\t0/1 error=0.310\n",
      "Epoch 008\ttrain loss=6.706254\ttest loss=63.840275\t0/1 error=0.270\n",
      "Epoch 009\ttrain loss=6.446760\ttest loss=62.939594\t0/1 error=0.280\n",
      "Epoch 010\ttrain loss=6.412170\ttest loss=61.825527\t0/1 error=0.300\n",
      "Epoch 011\ttrain loss=6.165340\ttest loss=60.461178\t0/1 error=0.310\n",
      "Epoch 012\ttrain loss=6.128836\ttest loss=59.994129\t0/1 error=0.300\n",
      "Epoch 013\ttrain loss=5.925023\ttest loss=58.121315\t0/1 error=0.290\n",
      "Epoch 014\ttrain loss=5.590721\ttest loss=57.194092\t0/1 error=0.240\n",
      "Epoch 015\ttrain loss=5.654968\ttest loss=56.444901\t0/1 error=0.250\n",
      "Epoch 016\ttrain loss=5.233187\ttest loss=53.386166\t0/1 error=0.210\n",
      "Epoch 017\ttrain loss=4.955485\ttest loss=54.070652\t0/1 error=0.210\n",
      "Epoch 018\ttrain loss=4.854710\ttest loss=50.349411\t0/1 error=0.210\n",
      "Epoch 019\ttrain loss=4.688287\ttest loss=47.304554\t0/1 error=0.200\n",
      "Epoch 020\ttrain loss=4.433404\ttest loss=48.510483\t0/1 error=0.240\n",
      "Epoch 021\ttrain loss=4.054372\ttest loss=46.602386\t0/1 error=0.170\n",
      "Epoch 022\ttrain loss=4.101647\ttest loss=43.613899\t0/1 error=0.120\n",
      "Epoch 023\ttrain loss=3.916133\ttest loss=44.127689\t0/1 error=0.160\n",
      "Epoch 024\ttrain loss=3.786625\ttest loss=42.785625\t0/1 error=0.130\n",
      "Epoch 025\ttrain loss=3.626241\ttest loss=41.143288\t0/1 error=0.130\n",
      "Epoch 026\ttrain loss=3.684497\ttest loss=50.287109\t0/1 error=0.300\n",
      "Epoch 027\ttrain loss=3.666865\ttest loss=46.665367\t0/1 error=0.270\n",
      "Epoch 028\ttrain loss=3.119296\ttest loss=38.508617\t0/1 error=0.110\n",
      "Epoch 029\ttrain loss=3.303741\ttest loss=37.830326\t0/1 error=0.120\n",
      "Epoch 030\ttrain loss=3.212145\ttest loss=37.899220\t0/1 error=0.140\n",
      "Epoch 031\ttrain loss=3.425065\ttest loss=38.376911\t0/1 error=0.130\n",
      "Epoch 032\ttrain loss=3.178300\ttest loss=42.687939\t0/1 error=0.190\n",
      "Epoch 033\ttrain loss=2.921209\ttest loss=38.197914\t0/1 error=0.140\n",
      "Epoch 034\ttrain loss=3.261557\ttest loss=37.450554\t0/1 error=0.130\n",
      "Epoch 035\ttrain loss=2.933810\ttest loss=35.955650\t0/1 error=0.110\n",
      "Epoch 036\ttrain loss=3.074989\ttest loss=35.691326\t0/1 error=0.110\n",
      "Epoch 037\ttrain loss=3.109267\ttest loss=34.423717\t0/1 error=0.100\n",
      "Epoch 038\ttrain loss=2.707490\ttest loss=39.061729\t0/1 error=0.170\n",
      "Epoch 039\ttrain loss=2.988354\ttest loss=33.708321\t0/1 error=0.100\n",
      "Epoch 040\ttrain loss=2.805356\ttest loss=33.577236\t0/1 error=0.100\n",
      "Epoch 041\ttrain loss=2.813868\ttest loss=33.332287\t0/1 error=0.120\n",
      "Epoch 042\ttrain loss=2.841118\ttest loss=34.287460\t0/1 error=0.130\n",
      "Epoch 043\ttrain loss=2.600669\ttest loss=35.483402\t0/1 error=0.130\n",
      "Epoch 044\ttrain loss=2.479676\ttest loss=32.548065\t0/1 error=0.110\n",
      "Epoch 045\ttrain loss=2.600593\ttest loss=35.179726\t0/1 error=0.160\n",
      "Epoch 046\ttrain loss=2.608807\ttest loss=33.935078\t0/1 error=0.130\n",
      "Epoch 047\ttrain loss=2.612130\ttest loss=32.573887\t0/1 error=0.100\n",
      "Epoch 048\ttrain loss=2.465393\ttest loss=33.224155\t0/1 error=0.130\n",
      "Epoch 049\ttrain loss=2.717784\ttest loss=32.096947\t0/1 error=0.120\n",
      "Epoch 050\ttrain loss=2.393871\ttest loss=38.537548\t0/1 error=0.190\n",
      "Epoch 051\ttrain loss=2.492487\ttest loss=32.799084\t0/1 error=0.120\n",
      "Epoch 052\ttrain loss=2.462944\ttest loss=37.271759\t0/1 error=0.150\n",
      "Epoch 053\ttrain loss=2.288134\ttest loss=32.517044\t0/1 error=0.130\n",
      "Epoch 054\ttrain loss=2.576499\ttest loss=31.305826\t0/1 error=0.100\n",
      "Epoch 055\ttrain loss=2.466114\ttest loss=35.159603\t0/1 error=0.130\n",
      "Epoch 056\ttrain loss=2.296550\ttest loss=33.859276\t0/1 error=0.140\n",
      "Epoch 057\ttrain loss=2.266104\ttest loss=32.647015\t0/1 error=0.140\n",
      "Epoch 058\ttrain loss=2.385939\ttest loss=31.469830\t0/1 error=0.120\n",
      "Epoch 059\ttrain loss=2.438268\ttest loss=34.684578\t0/1 error=0.130\n",
      "Epoch 060\ttrain loss=2.271963\ttest loss=32.104309\t0/1 error=0.140\n",
      "Epoch 061\ttrain loss=2.354070\ttest loss=34.614769\t0/1 error=0.160\n",
      "Epoch 062\ttrain loss=2.392628\ttest loss=32.040085\t0/1 error=0.140\n",
      "Epoch 063\ttrain loss=2.405381\ttest loss=31.693220\t0/1 error=0.120\n",
      "Epoch 064\ttrain loss=2.090236\ttest loss=33.082897\t0/1 error=0.120\n",
      "Epoch 065\ttrain loss=2.175863\ttest loss=31.430801\t0/1 error=0.130\n",
      "Epoch 066\ttrain loss=2.275632\ttest loss=34.638233\t0/1 error=0.140\n",
      "Epoch 067\ttrain loss=2.351685\ttest loss=31.606052\t0/1 error=0.120\n",
      "Epoch 068\ttrain loss=2.164833\ttest loss=31.605406\t0/1 error=0.120\n",
      "Epoch 069\ttrain loss=2.115911\ttest loss=32.159695\t0/1 error=0.150\n",
      "Epoch 070\ttrain loss=2.284249\ttest loss=31.769770\t0/1 error=0.140\n",
      "Epoch 071\ttrain loss=2.372975\ttest loss=33.005329\t0/1 error=0.140\n",
      "Epoch 072\ttrain loss=2.562936\ttest loss=33.431023\t0/1 error=0.140\n",
      "Epoch 073\ttrain loss=2.178168\ttest loss=33.021629\t0/1 error=0.140\n",
      "Epoch 074\ttrain loss=2.337553\ttest loss=31.767553\t0/1 error=0.140\n",
      "Epoch 075\ttrain loss=2.431290\ttest loss=33.092609\t0/1 error=0.130\n",
      "Epoch 076\ttrain loss=2.220653\ttest loss=32.309830\t0/1 error=0.130\n",
      "Epoch 077\ttrain loss=2.163099\ttest loss=32.969505\t0/1 error=0.120\n",
      "Epoch 078\ttrain loss=2.124918\ttest loss=32.551594\t0/1 error=0.130\n",
      "Epoch 079\ttrain loss=2.427629\ttest loss=32.565842\t0/1 error=0.120\n",
      "Epoch 080\ttrain loss=2.376845\ttest loss=31.185160\t0/1 error=0.120\n",
      "Epoch 081\ttrain loss=2.330431\ttest loss=32.184998\t0/1 error=0.140\n",
      "Epoch 082\ttrain loss=2.195760\ttest loss=33.488758\t0/1 error=0.140\n",
      "Epoch 083\ttrain loss=2.158884\ttest loss=32.585041\t0/1 error=0.150\n",
      "Epoch 084\ttrain loss=2.257397\ttest loss=32.341637\t0/1 error=0.150\n",
      "Epoch 085\ttrain loss=2.186044\ttest loss=31.963928\t0/1 error=0.140\n",
      "Epoch 086\ttrain loss=2.117438\ttest loss=32.786030\t0/1 error=0.120\n",
      "Epoch 087\ttrain loss=1.965919\ttest loss=34.911339\t0/1 error=0.150\n",
      "Epoch 088\ttrain loss=2.236749\ttest loss=31.395370\t0/1 error=0.120\n",
      "Epoch 089\ttrain loss=2.213865\ttest loss=32.635624\t0/1 error=0.140\n",
      "Epoch 090\ttrain loss=2.037306\ttest loss=33.514294\t0/1 error=0.140\n",
      "Epoch 091\ttrain loss=2.009368\ttest loss=31.708422\t0/1 error=0.120\n",
      "Epoch 092\ttrain loss=2.022914\ttest loss=34.776024\t0/1 error=0.150\n",
      "Epoch 093\ttrain loss=1.946679\ttest loss=32.967480\t0/1 error=0.140\n",
      "Epoch 094\ttrain loss=1.971026\ttest loss=39.341640\t0/1 error=0.230\n",
      "Epoch 095\ttrain loss=2.042609\ttest loss=33.042973\t0/1 error=0.140\n",
      "Epoch 096\ttrain loss=2.108453\ttest loss=31.178350\t0/1 error=0.120\n",
      "Epoch 097\ttrain loss=2.115069\ttest loss=32.206249\t0/1 error=0.140\n",
      "Epoch 098\ttrain loss=2.049934\ttest loss=34.231884\t0/1 error=0.150\n",
      "Epoch 099\ttrain loss=1.907626\ttest loss=31.561956\t0/1 error=0.120\n",
      "Epoch 100\ttrain loss=2.166793\ttest loss=31.314491\t0/1 error=0.120\n",
      "Epoch 101\ttrain loss=2.066768\ttest loss=33.944157\t0/1 error=0.140\n",
      "Epoch 102\ttrain loss=2.051119\ttest loss=31.636309\t0/1 error=0.120\n",
      "Epoch 103\ttrain loss=1.959319\ttest loss=33.884697\t0/1 error=0.140\n",
      "Epoch 104\ttrain loss=1.837155\ttest loss=33.572712\t0/1 error=0.130\n",
      "Epoch 105\ttrain loss=2.033673\ttest loss=42.955338\t0/1 error=0.270\n",
      "Epoch 106\ttrain loss=1.954504\ttest loss=32.090904\t0/1 error=0.140\n",
      "Epoch 107\ttrain loss=1.890917\ttest loss=31.932798\t0/1 error=0.120\n",
      "Epoch 108\ttrain loss=2.080917\ttest loss=31.935492\t0/1 error=0.120\n",
      "Epoch 109\ttrain loss=2.057025\ttest loss=32.720116\t0/1 error=0.130\n",
      "Epoch 110\ttrain loss=2.017919\ttest loss=37.871235\t0/1 error=0.150\n",
      "Epoch 111\ttrain loss=2.048204\ttest loss=33.624119\t0/1 error=0.140\n",
      "Epoch 112\ttrain loss=2.194538\ttest loss=34.871300\t0/1 error=0.140\n",
      "Epoch 113\ttrain loss=1.968080\ttest loss=31.956656\t0/1 error=0.120\n",
      "Epoch 114\ttrain loss=1.786901\ttest loss=32.099640\t0/1 error=0.140\n",
      "Epoch 115\ttrain loss=2.015653\ttest loss=32.809807\t0/1 error=0.140\n",
      "Epoch 116\ttrain loss=2.032730\ttest loss=32.971203\t0/1 error=0.130\n",
      "Epoch 117\ttrain loss=2.226603\ttest loss=34.267540\t0/1 error=0.130\n",
      "Epoch 118\ttrain loss=2.012224\ttest loss=32.009651\t0/1 error=0.130\n",
      "Epoch 119\ttrain loss=1.873203\ttest loss=31.606890\t0/1 error=0.130\n",
      "Epoch 120\ttrain loss=2.101573\ttest loss=32.294422\t0/1 error=0.130\n",
      "Epoch 121\ttrain loss=2.032770\ttest loss=31.428770\t0/1 error=0.120\n",
      "Epoch 122\ttrain loss=1.862590\ttest loss=33.993706\t0/1 error=0.130\n",
      "Epoch 123\ttrain loss=2.180063\ttest loss=34.649841\t0/1 error=0.120\n",
      "Epoch 124\ttrain loss=1.907865\ttest loss=33.104664\t0/1 error=0.130\n",
      "Epoch 125\ttrain loss=1.932622\ttest loss=32.998135\t0/1 error=0.130\n",
      "Epoch 126\ttrain loss=2.144092\ttest loss=31.598909\t0/1 error=0.130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127\ttrain loss=1.864976\ttest loss=33.121292\t0/1 error=0.130\n",
      "Epoch 128\ttrain loss=1.863639\ttest loss=32.304848\t0/1 error=0.120\n",
      "Epoch 129\ttrain loss=1.857699\ttest loss=32.017838\t0/1 error=0.120\n",
      "Epoch 130\ttrain loss=2.126406\ttest loss=32.624653\t0/1 error=0.130\n",
      "Epoch 131\ttrain loss=1.941092\ttest loss=31.630001\t0/1 error=0.120\n",
      "Epoch 132\ttrain loss=1.868650\ttest loss=33.390587\t0/1 error=0.130\n",
      "Epoch 133\ttrain loss=1.893374\ttest loss=32.694763\t0/1 error=0.130\n",
      "Epoch 134\ttrain loss=1.872073\ttest loss=32.453651\t0/1 error=0.120\n",
      "Epoch 135\ttrain loss=2.081007\ttest loss=33.486637\t0/1 error=0.130\n",
      "Epoch 136\ttrain loss=2.020648\ttest loss=34.606762\t0/1 error=0.130\n",
      "Epoch 137\ttrain loss=1.935870\ttest loss=32.476795\t0/1 error=0.120\n",
      "Epoch 138\ttrain loss=1.972053\ttest loss=33.123211\t0/1 error=0.120\n",
      "Epoch 139\ttrain loss=1.913655\ttest loss=32.530151\t0/1 error=0.140\n",
      "Epoch 140\ttrain loss=1.984174\ttest loss=35.121758\t0/1 error=0.130\n",
      "Epoch 141\ttrain loss=1.928642\ttest loss=32.228767\t0/1 error=0.130\n",
      "Epoch 142\ttrain loss=1.967365\ttest loss=35.594158\t0/1 error=0.140\n",
      "Epoch 143\ttrain loss=1.868804\ttest loss=32.097767\t0/1 error=0.120\n",
      "Epoch 144\ttrain loss=1.934020\ttest loss=32.928986\t0/1 error=0.120\n",
      "Epoch 145\ttrain loss=1.796724\ttest loss=31.170732\t0/1 error=0.130\n",
      "Epoch 146\ttrain loss=1.598737\ttest loss=35.426727\t0/1 error=0.130\n",
      "Epoch 147\ttrain loss=1.721337\ttest loss=33.061985\t0/1 error=0.140\n",
      "Epoch 148\ttrain loss=1.629491\ttest loss=32.061672\t0/1 error=0.140\n",
      "Epoch 149\ttrain loss=1.940748\ttest loss=32.305702\t0/1 error=0.110\n",
      "Epoch 150\ttrain loss=1.689670\ttest loss=31.545612\t0/1 error=0.120\n",
      "Epoch 151\ttrain loss=2.024677\ttest loss=33.107628\t0/1 error=0.120\n",
      "Epoch 152\ttrain loss=1.760640\ttest loss=31.826035\t0/1 error=0.110\n",
      "Epoch 153\ttrain loss=1.756381\ttest loss=32.327087\t0/1 error=0.120\n",
      "Epoch 154\ttrain loss=1.780958\ttest loss=32.425095\t0/1 error=0.110\n",
      "Epoch 155\ttrain loss=1.549756\ttest loss=32.481171\t0/1 error=0.130\n",
      "Epoch 156\ttrain loss=1.998792\ttest loss=33.603325\t0/1 error=0.120\n",
      "Epoch 157\ttrain loss=1.705829\ttest loss=34.382027\t0/1 error=0.130\n",
      "Epoch 158\ttrain loss=1.819077\ttest loss=34.801968\t0/1 error=0.110\n",
      "Epoch 159\ttrain loss=1.861116\ttest loss=32.876728\t0/1 error=0.110\n",
      "Epoch 160\ttrain loss=1.936874\ttest loss=33.581234\t0/1 error=0.110\n",
      "Epoch 161\ttrain loss=1.697994\ttest loss=36.434353\t0/1 error=0.160\n",
      "Epoch 162\ttrain loss=1.778600\ttest loss=33.747242\t0/1 error=0.120\n",
      "Epoch 163\ttrain loss=1.957545\ttest loss=34.882732\t0/1 error=0.110\n",
      "Epoch 164\ttrain loss=2.093587\ttest loss=33.304523\t0/1 error=0.130\n",
      "Epoch 165\ttrain loss=1.696593\ttest loss=32.009624\t0/1 error=0.110\n",
      "Epoch 166\ttrain loss=1.717532\ttest loss=33.593357\t0/1 error=0.130\n",
      "Epoch 167\ttrain loss=1.674213\ttest loss=32.294273\t0/1 error=0.110\n",
      "Epoch 168\ttrain loss=1.709385\ttest loss=35.285816\t0/1 error=0.150\n",
      "Epoch 169\ttrain loss=1.752017\ttest loss=32.949512\t0/1 error=0.120\n",
      "Epoch 170\ttrain loss=1.762336\ttest loss=35.251377\t0/1 error=0.140\n",
      "Epoch 171\ttrain loss=1.827237\ttest loss=34.281090\t0/1 error=0.120\n",
      "Epoch 172\ttrain loss=1.806981\ttest loss=33.606445\t0/1 error=0.120\n",
      "Epoch 173\ttrain loss=1.886971\ttest loss=36.521133\t0/1 error=0.140\n",
      "Epoch 174\ttrain loss=1.781003\ttest loss=32.644730\t0/1 error=0.120\n",
      "Epoch 175\ttrain loss=1.588217\ttest loss=34.568008\t0/1 error=0.160\n",
      "Epoch 176\ttrain loss=1.973704\ttest loss=35.478004\t0/1 error=0.140\n",
      "Epoch 177\ttrain loss=1.705598\ttest loss=37.310024\t0/1 error=0.160\n",
      "Epoch 178\ttrain loss=1.779112\ttest loss=35.092617\t0/1 error=0.130\n",
      "Epoch 179\ttrain loss=1.875484\ttest loss=35.548809\t0/1 error=0.140\n",
      "Epoch 180\ttrain loss=1.666028\ttest loss=34.029179\t0/1 error=0.120\n",
      "Epoch 181\ttrain loss=1.957743\ttest loss=45.252392\t0/1 error=0.240\n",
      "Epoch 182\ttrain loss=1.690562\ttest loss=38.308964\t0/1 error=0.170\n",
      "Epoch 183\ttrain loss=1.629129\ttest loss=36.318920\t0/1 error=0.130\n",
      "Epoch 184\ttrain loss=1.891480\ttest loss=39.701096\t0/1 error=0.170\n",
      "Epoch 185\ttrain loss=1.643917\ttest loss=36.783051\t0/1 error=0.110\n",
      "Epoch 186\ttrain loss=1.502263\ttest loss=36.812099\t0/1 error=0.120\n",
      "Epoch 187\ttrain loss=1.680930\ttest loss=33.800461\t0/1 error=0.110\n",
      "Epoch 188\ttrain loss=1.606538\ttest loss=35.260933\t0/1 error=0.130\n",
      "Epoch 189\ttrain loss=1.795546\ttest loss=38.730080\t0/1 error=0.150\n",
      "Epoch 190\ttrain loss=1.749306\ttest loss=37.773193\t0/1 error=0.130\n",
      "Epoch 191\ttrain loss=1.738136\ttest loss=36.263783\t0/1 error=0.130\n",
      "Epoch 192\ttrain loss=1.764483\ttest loss=35.694202\t0/1 error=0.120\n",
      "Epoch 193\ttrain loss=1.612992\ttest loss=34.876682\t0/1 error=0.140\n",
      "Epoch 194\ttrain loss=1.574313\ttest loss=35.977089\t0/1 error=0.110\n",
      "Epoch 195\ttrain loss=1.812809\ttest loss=36.780937\t0/1 error=0.110\n",
      "Epoch 196\ttrain loss=1.618746\ttest loss=37.096794\t0/1 error=0.130\n",
      "Epoch 197\ttrain loss=1.671123\ttest loss=34.188404\t0/1 error=0.130\n",
      "Epoch 198\ttrain loss=1.813387\ttest loss=39.516853\t0/1 error=0.150\n",
      "Epoch 199\ttrain loss=1.748187\ttest loss=38.650833\t0/1 error=0.170\n",
      "Epoch 200\ttrain loss=1.594490\ttest loss=38.099052\t0/1 error=0.150\n",
      "Epoch 201\ttrain loss=1.648754\ttest loss=37.235809\t0/1 error=0.120\n",
      "Epoch 202\ttrain loss=1.773698\ttest loss=35.275513\t0/1 error=0.110\n",
      "Epoch 203\ttrain loss=1.758655\ttest loss=35.995060\t0/1 error=0.110\n",
      "Epoch 204\ttrain loss=1.737830\ttest loss=35.974018\t0/1 error=0.140\n",
      "Epoch 205\ttrain loss=1.729684\ttest loss=38.265087\t0/1 error=0.170\n",
      "Epoch 206\ttrain loss=1.525309\ttest loss=38.768177\t0/1 error=0.130\n",
      "Epoch 207\ttrain loss=1.836856\ttest loss=38.370014\t0/1 error=0.100\n",
      "Epoch 208\ttrain loss=1.733271\ttest loss=38.076382\t0/1 error=0.130\n",
      "Epoch 209\ttrain loss=1.682351\ttest loss=36.641479\t0/1 error=0.160\n",
      "Epoch 210\ttrain loss=1.758710\ttest loss=35.780479\t0/1 error=0.130\n",
      "Epoch 211\ttrain loss=1.538864\ttest loss=36.399124\t0/1 error=0.120\n",
      "Epoch 212\ttrain loss=1.695015\ttest loss=35.942844\t0/1 error=0.130\n",
      "Epoch 213\ttrain loss=1.397127\ttest loss=35.098110\t0/1 error=0.120\n",
      "Epoch 214\ttrain loss=1.793764\ttest loss=37.745918\t0/1 error=0.120\n",
      "Epoch 215\ttrain loss=1.492231\ttest loss=37.715019\t0/1 error=0.120\n",
      "Epoch 216\ttrain loss=1.811894\ttest loss=44.450073\t0/1 error=0.200\n",
      "Epoch 217\ttrain loss=1.661967\ttest loss=36.120358\t0/1 error=0.130\n",
      "Epoch 218\ttrain loss=1.676866\ttest loss=38.121944\t0/1 error=0.170\n",
      "Epoch 219\ttrain loss=1.690432\ttest loss=37.481960\t0/1 error=0.170\n",
      "Epoch 220\ttrain loss=1.722937\ttest loss=38.011292\t0/1 error=0.120\n",
      "Epoch 221\ttrain loss=1.726157\ttest loss=38.073528\t0/1 error=0.130\n",
      "Epoch 222\ttrain loss=1.536529\ttest loss=35.018131\t0/1 error=0.130\n",
      "Epoch 223\ttrain loss=1.767526\ttest loss=37.096710\t0/1 error=0.100\n",
      "Epoch 224\ttrain loss=1.765844\ttest loss=37.673847\t0/1 error=0.140\n",
      "Epoch 225\ttrain loss=1.570175\ttest loss=37.440811\t0/1 error=0.100\n",
      "Epoch 226\ttrain loss=1.589394\ttest loss=35.673538\t0/1 error=0.120\n",
      "Epoch 227\ttrain loss=1.598072\ttest loss=38.506424\t0/1 error=0.150\n",
      "Epoch 228\ttrain loss=1.688324\ttest loss=36.738319\t0/1 error=0.130\n",
      "Epoch 229\ttrain loss=1.700123\ttest loss=40.536835\t0/1 error=0.160\n",
      "Epoch 230\ttrain loss=1.678950\ttest loss=36.448967\t0/1 error=0.120\n",
      "Epoch 231\ttrain loss=1.514955\ttest loss=35.842567\t0/1 error=0.120\n",
      "Epoch 232\ttrain loss=1.562902\ttest loss=36.167908\t0/1 error=0.130\n",
      "Epoch 233\ttrain loss=1.598061\ttest loss=38.744305\t0/1 error=0.100\n",
      "Epoch 234\ttrain loss=1.512457\ttest loss=35.211216\t0/1 error=0.150\n",
      "Epoch 235\ttrain loss=1.606807\ttest loss=36.314251\t0/1 error=0.150\n",
      "Epoch 236\ttrain loss=1.575958\ttest loss=36.492580\t0/1 error=0.150\n",
      "Epoch 237\ttrain loss=1.653173\ttest loss=36.931324\t0/1 error=0.150\n",
      "Epoch 238\ttrain loss=1.431357\ttest loss=42.187107\t0/1 error=0.180\n",
      "Epoch 239\ttrain loss=1.622215\ttest loss=37.346043\t0/1 error=0.160\n",
      "Epoch 240\ttrain loss=1.567708\ttest loss=41.798565\t0/1 error=0.160\n",
      "Epoch 241\ttrain loss=1.493147\ttest loss=36.351864\t0/1 error=0.130\n",
      "Epoch 242\ttrain loss=1.534553\ttest loss=38.963989\t0/1 error=0.140\n",
      "Epoch 243\ttrain loss=1.606627\ttest loss=36.813309\t0/1 error=0.150\n",
      "Epoch 244\ttrain loss=1.563578\ttest loss=37.052711\t0/1 error=0.120\n",
      "Epoch 245\ttrain loss=1.528507\ttest loss=35.984264\t0/1 error=0.110\n",
      "Epoch 246\ttrain loss=1.520515\ttest loss=40.201080\t0/1 error=0.100\n",
      "Epoch 247\ttrain loss=1.595269\ttest loss=38.091225\t0/1 error=0.100\n",
      "Epoch 248\ttrain loss=1.500702\ttest loss=38.296799\t0/1 error=0.170\n",
      "Epoch 249\ttrain loss=1.566846\ttest loss=36.857883\t0/1 error=0.120\n",
      "Epoch 250\ttrain loss=1.512127\ttest loss=38.945881\t0/1 error=0.140\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_in = 2\n",
    "n_c1=10\n",
    "params = []\n",
    "\n",
    "n_out = 1\n",
    "W1 = Variable(torch.normal(torch.zeros(n_in, n_c1), np.sqrt(2/(n_in + n_c1))), requires_grad=True)\n",
    "b1 = Variable(torch.zeros(n_c1), requires_grad=True)\n",
    "W2 = Variable(torch.normal(torch.zeros(n_c1, n_out), np.sqrt(2/(n_c1 + n_out))), requires_grad=True)\n",
    "b2 = Variable(torch.zeros(n_out), requires_grad=True)\n",
    "\n",
    "def forward(X):\n",
    "    H1 = torch.sigmoid( torch.mm(X, W1)+b1)\n",
    "    H2 = torch.sigmoid(torch.mm(H1, W2) + b2)\n",
    "    \n",
    "    return H2 \n",
    "\n",
    "def L(H, Y, eps=1e-08):\n",
    "    loss = sum(-Y * torch.log(H + eps) - (1 - Y) * torch.log(1 - H + eps))  # log-likelikood\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "n_epochs = 250\n",
    "epoch_n_batches = 100\n",
    "train_batch_size = 10\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(n_epochs):\n",
    "\n",
    "    train_loss = 0.\n",
    "\n",
    "    for j in range(epoch_n_batches):\n",
    "\n",
    "        # Prepare next mini-batch\n",
    "        mb_idxs = torch.multinomial(torch.ones(n_train), train_batch_size, replacement=True)\n",
    "        X_mb = Variable(X_train[mb_idxs])\n",
    "        Y_mb = Variable(Y_train[mb_idxs])\n",
    "\n",
    "        # Forward pass\n",
    "        Y_prob_mb = forward(X_mb)\n",
    "        \n",
    "        loss = L(Y_prob_mb,Y_mb)\n",
    "        # loss la ham sum cua y_ilogf(x_i)+(1-y_i)log(1-f(x_i)) vay no la sum cua ham L(H,y_i)\n",
    "\n",
    "        # Backward pass# \n",
    "        loss.backward()\n",
    "        # Parameter update (gradient descent)\n",
    "        W1.data.sub_(alpha * W1.grad.data)\n",
    "        W1.grad.data.zero_()  # must reset to 0 before next pass\n",
    "        W2.data.sub_(alpha * W2.grad.data)\n",
    "        W2.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "        b1.data.sub_(alpha * b1.grad.data)\n",
    "        b1.grad.data.zero_()  # must reset to 0 before next pass\n",
    "\n",
    "        b2.data.sub_(alpha * b2.grad.data)\n",
    "        b2.grad.data.zero_()  # must reset to 0 before next pass\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "\n",
    "    train_loss /= epoch_n_batches\n",
    "\n",
    "    # Forward pass\n",
    "    Y_test_prob = forward(Variable(X_test)).data\n",
    "    test_loss = L(Y_test_prob, Y_test).mean()\n",
    "    \n",
    "    # Compute expected 0/1 error\n",
    "    Y_test_pred = (Y_test_prob > 0.5).type(torch.FloatTensor)\n",
    "    test_err = torch.abs(Y_test - Y_test_pred).mean()\n",
    "\n",
    "    print('Epoch {:03d}\\ttrain loss={:.06f}\\ttest loss={:.06f}\\t0/1 error={:.03f}'.format(\n",
    "        i + 1, train_loss, test_loss, test_err))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001\ttrain loss=7.165280\ttest loss=71.115273\t0/1 error=0.560\n",
      "Epoch 002\ttrain loss=7.077521\ttest loss=68.944969\t0/1 error=0.440\n",
      "Epoch 003\ttrain loss=7.036386\ttest loss=73.795151\t0/1 error=0.560\n",
      "Epoch 004\ttrain loss=7.071702\ttest loss=69.782578\t0/1 error=0.560\n",
      "Epoch 005\ttrain loss=7.001674\ttest loss=70.338058\t0/1 error=0.560\n",
      "Epoch 006\ttrain loss=7.006515\ttest loss=68.816467\t0/1 error=0.440\n",
      "Epoch 007\ttrain loss=7.037956\ttest loss=69.403511\t0/1 error=0.570\n",
      "Epoch 008\ttrain loss=7.009235\ttest loss=72.605057\t0/1 error=0.560\n",
      "Epoch 009\ttrain loss=6.997608\ttest loss=68.534538\t0/1 error=0.440\n",
      "Epoch 010\ttrain loss=7.008840\ttest loss=68.850983\t0/1 error=0.500\n",
      "Epoch 011\ttrain loss=6.978603\ttest loss=69.111938\t0/1 error=0.330\n",
      "Epoch 012\ttrain loss=7.022204\ttest loss=70.101578\t0/1 error=0.560\n",
      "Epoch 013\ttrain loss=6.978000\ttest loss=68.487267\t0/1 error=0.440\n",
      "Epoch 014\ttrain loss=6.948717\ttest loss=68.334755\t0/1 error=0.510\n",
      "Epoch 015\ttrain loss=6.945141\ttest loss=71.111855\t0/1 error=0.560\n",
      "Epoch 016\ttrain loss=6.889438\ttest loss=67.882179\t0/1 error=0.440\n",
      "Epoch 017\ttrain loss=6.897964\ttest loss=69.268257\t0/1 error=0.350\n",
      "Epoch 018\ttrain loss=6.951516\ttest loss=69.044151\t0/1 error=0.360\n",
      "Epoch 019\ttrain loss=6.941771\ttest loss=67.867973\t0/1 error=0.370\n",
      "Epoch 020\ttrain loss=6.902690\ttest loss=67.401566\t0/1 error=0.440\n",
      "Epoch 021\ttrain loss=6.821217\ttest loss=66.736404\t0/1 error=0.460\n",
      "Epoch 022\ttrain loss=6.914502\ttest loss=66.648689\t0/1 error=0.490\n",
      "Epoch 023\ttrain loss=6.853091\ttest loss=67.475426\t0/1 error=0.340\n",
      "Epoch 024\ttrain loss=6.761739\ttest loss=66.391006\t0/1 error=0.430\n",
      "Epoch 025\ttrain loss=6.766061\ttest loss=70.606590\t0/1 error=0.500\n",
      "Epoch 026\ttrain loss=6.817576\ttest loss=66.446487\t0/1 error=0.400\n",
      "Epoch 027\ttrain loss=6.666433\ttest loss=68.045319\t0/1 error=0.340\n",
      "Epoch 028\ttrain loss=6.421425\ttest loss=66.463333\t0/1 error=0.370\n",
      "Epoch 029\ttrain loss=6.541942\ttest loss=67.094978\t0/1 error=0.340\n",
      "Epoch 030\ttrain loss=6.396563\ttest loss=67.245979\t0/1 error=0.340\n",
      "Epoch 031\ttrain loss=6.516867\ttest loss=68.914352\t0/1 error=0.440\n",
      "Epoch 032\ttrain loss=6.254174\ttest loss=65.256660\t0/1 error=0.350\n",
      "Epoch 033\ttrain loss=6.314813\ttest loss=63.749119\t0/1 error=0.340\n",
      "Epoch 034\ttrain loss=6.035673\ttest loss=59.746056\t0/1 error=0.360\n",
      "Epoch 035\ttrain loss=5.494291\ttest loss=55.233589\t0/1 error=0.270\n",
      "Epoch 036\ttrain loss=4.933167\ttest loss=52.242561\t0/1 error=0.250\n",
      "Epoch 037\ttrain loss=4.453567\ttest loss=52.973576\t0/1 error=0.270\n",
      "Epoch 038\ttrain loss=4.247681\ttest loss=49.183208\t0/1 error=0.210\n",
      "Epoch 039\ttrain loss=4.363705\ttest loss=52.554192\t0/1 error=0.270\n",
      "Epoch 040\ttrain loss=4.029894\ttest loss=51.062515\t0/1 error=0.230\n",
      "Epoch 041\ttrain loss=4.081508\ttest loss=48.462875\t0/1 error=0.210\n",
      "Epoch 042\ttrain loss=4.006590\ttest loss=48.162083\t0/1 error=0.210\n",
      "Epoch 043\ttrain loss=3.873845\ttest loss=48.571861\t0/1 error=0.240\n",
      "Epoch 044\ttrain loss=3.962716\ttest loss=47.766521\t0/1 error=0.210\n",
      "Epoch 045\ttrain loss=4.063493\ttest loss=49.134056\t0/1 error=0.230\n",
      "Epoch 046\ttrain loss=4.019068\ttest loss=47.849586\t0/1 error=0.220\n",
      "Epoch 047\ttrain loss=3.650271\ttest loss=48.816612\t0/1 error=0.210\n",
      "Epoch 048\ttrain loss=4.052587\ttest loss=48.398922\t0/1 error=0.220\n",
      "Epoch 049\ttrain loss=4.182268\ttest loss=45.980984\t0/1 error=0.190\n",
      "Epoch 050\ttrain loss=3.760673\ttest loss=45.398270\t0/1 error=0.190\n",
      "Epoch 051\ttrain loss=3.907570\ttest loss=46.173504\t0/1 error=0.190\n",
      "Epoch 052\ttrain loss=3.764656\ttest loss=46.553776\t0/1 error=0.190\n",
      "Epoch 053\ttrain loss=3.920862\ttest loss=52.926083\t0/1 error=0.240\n",
      "Epoch 054\ttrain loss=3.839649\ttest loss=46.093822\t0/1 error=0.200\n",
      "Epoch 055\ttrain loss=3.876436\ttest loss=50.926113\t0/1 error=0.250\n",
      "Epoch 056\ttrain loss=3.507748\ttest loss=47.389320\t0/1 error=0.220\n",
      "Epoch 057\ttrain loss=3.508898\ttest loss=45.592041\t0/1 error=0.200\n",
      "Epoch 058\ttrain loss=3.622319\ttest loss=47.201870\t0/1 error=0.210\n",
      "Epoch 059\ttrain loss=3.834614\ttest loss=43.791073\t0/1 error=0.190\n",
      "Epoch 060\ttrain loss=3.585874\ttest loss=49.011444\t0/1 error=0.200\n",
      "Epoch 061\ttrain loss=3.591833\ttest loss=50.409775\t0/1 error=0.220\n",
      "Epoch 062\ttrain loss=3.525660\ttest loss=47.215828\t0/1 error=0.200\n",
      "Epoch 063\ttrain loss=3.631540\ttest loss=49.089497\t0/1 error=0.200\n",
      "Epoch 064\ttrain loss=2.993241\ttest loss=51.786442\t0/1 error=0.210\n",
      "Epoch 065\ttrain loss=3.270065\ttest loss=45.374485\t0/1 error=0.190\n",
      "Epoch 066\ttrain loss=3.628204\ttest loss=43.800709\t0/1 error=0.210\n",
      "Epoch 067\ttrain loss=3.337042\ttest loss=47.922497\t0/1 error=0.240\n",
      "Epoch 068\ttrain loss=3.224520\ttest loss=41.714828\t0/1 error=0.170\n",
      "Epoch 069\ttrain loss=2.997955\ttest loss=42.218544\t0/1 error=0.180\n",
      "Epoch 070\ttrain loss=3.343640\ttest loss=40.197861\t0/1 error=0.150\n",
      "Epoch 071\ttrain loss=3.134398\ttest loss=42.043324\t0/1 error=0.180\n",
      "Epoch 072\ttrain loss=3.301350\ttest loss=41.020790\t0/1 error=0.190\n",
      "Epoch 073\ttrain loss=3.028988\ttest loss=40.974434\t0/1 error=0.200\n",
      "Epoch 074\ttrain loss=3.314394\ttest loss=35.888870\t0/1 error=0.140\n",
      "Epoch 075\ttrain loss=3.198661\ttest loss=56.348602\t0/1 error=0.270\n",
      "Epoch 076\ttrain loss=2.980913\ttest loss=34.563778\t0/1 error=0.120\n",
      "Epoch 077\ttrain loss=3.080044\ttest loss=49.567558\t0/1 error=0.240\n",
      "Epoch 078\ttrain loss=2.771340\ttest loss=37.962296\t0/1 error=0.170\n",
      "Epoch 079\ttrain loss=2.767617\ttest loss=36.457954\t0/1 error=0.170\n",
      "Epoch 080\ttrain loss=2.688616\ttest loss=39.426010\t0/1 error=0.190\n",
      "Epoch 081\ttrain loss=2.702109\ttest loss=32.161053\t0/1 error=0.130\n",
      "Epoch 082\ttrain loss=2.540836\ttest loss=33.431351\t0/1 error=0.170\n",
      "Epoch 083\ttrain loss=2.820991\ttest loss=31.038040\t0/1 error=0.140\n",
      "Epoch 084\ttrain loss=2.517919\ttest loss=31.589518\t0/1 error=0.120\n",
      "Epoch 085\ttrain loss=2.531821\ttest loss=32.790287\t0/1 error=0.160\n",
      "Epoch 086\ttrain loss=2.267117\ttest loss=32.105225\t0/1 error=0.130\n",
      "Epoch 087\ttrain loss=2.259612\ttest loss=29.698765\t0/1 error=0.120\n",
      "Epoch 088\ttrain loss=2.446144\ttest loss=29.821115\t0/1 error=0.130\n",
      "Epoch 089\ttrain loss=2.193351\ttest loss=34.642788\t0/1 error=0.140\n",
      "Epoch 090\ttrain loss=2.344873\ttest loss=32.633640\t0/1 error=0.150\n",
      "Epoch 091\ttrain loss=2.063438\ttest loss=35.739128\t0/1 error=0.150\n",
      "Epoch 092\ttrain loss=2.400432\ttest loss=30.524675\t0/1 error=0.140\n",
      "Epoch 093\ttrain loss=1.824292\ttest loss=29.951447\t0/1 error=0.120\n",
      "Epoch 094\ttrain loss=2.087023\ttest loss=34.028236\t0/1 error=0.160\n",
      "Epoch 095\ttrain loss=1.994797\ttest loss=35.236748\t0/1 error=0.140\n",
      "Epoch 096\ttrain loss=2.100295\ttest loss=30.927336\t0/1 error=0.130\n",
      "Epoch 097\ttrain loss=2.222320\ttest loss=30.686167\t0/1 error=0.140\n",
      "Epoch 098\ttrain loss=1.915487\ttest loss=30.458893\t0/1 error=0.130\n",
      "Epoch 099\ttrain loss=2.167338\ttest loss=30.800114\t0/1 error=0.100\n",
      "Epoch 100\ttrain loss=1.883923\ttest loss=31.190891\t0/1 error=0.110\n",
      "Epoch 101\ttrain loss=1.907329\ttest loss=30.152208\t0/1 error=0.120\n",
      "Epoch 102\ttrain loss=2.094107\ttest loss=36.319218\t0/1 error=0.160\n",
      "Epoch 103\ttrain loss=1.800395\ttest loss=31.869623\t0/1 error=0.130\n",
      "Epoch 104\ttrain loss=1.775855\ttest loss=35.575489\t0/1 error=0.160\n",
      "Epoch 105\ttrain loss=1.720646\ttest loss=32.779537\t0/1 error=0.090\n",
      "Epoch 106\ttrain loss=1.596949\ttest loss=32.817852\t0/1 error=0.100\n",
      "Epoch 107\ttrain loss=1.875015\ttest loss=32.693993\t0/1 error=0.130\n",
      "Epoch 108\ttrain loss=1.918599\ttest loss=41.536041\t0/1 error=0.200\n",
      "Epoch 109\ttrain loss=1.871307\ttest loss=34.385468\t0/1 error=0.130\n",
      "Epoch 110\ttrain loss=1.790259\ttest loss=32.350689\t0/1 error=0.120\n",
      "Epoch 111\ttrain loss=1.743328\ttest loss=34.705067\t0/1 error=0.160\n",
      "Epoch 112\ttrain loss=1.786861\ttest loss=34.955750\t0/1 error=0.130\n",
      "Epoch 113\ttrain loss=1.757205\ttest loss=36.105431\t0/1 error=0.100\n",
      "Epoch 114\ttrain loss=1.598619\ttest loss=41.192951\t0/1 error=0.170\n",
      "Epoch 115\ttrain loss=1.755360\ttest loss=32.361221\t0/1 error=0.110\n",
      "Epoch 116\ttrain loss=1.740980\ttest loss=32.808304\t0/1 error=0.110\n",
      "Epoch 117\ttrain loss=1.891948\ttest loss=33.456638\t0/1 error=0.100\n",
      "Epoch 118\ttrain loss=1.575771\ttest loss=33.249779\t0/1 error=0.130\n",
      "Epoch 119\ttrain loss=1.508931\ttest loss=35.159225\t0/1 error=0.090\n",
      "Epoch 120\ttrain loss=1.736052\ttest loss=36.996006\t0/1 error=0.090\n",
      "Epoch 121\ttrain loss=1.746663\ttest loss=34.540451\t0/1 error=0.110\n",
      "Epoch 122\ttrain loss=1.721507\ttest loss=37.872883\t0/1 error=0.100\n",
      "Epoch 123\ttrain loss=1.639279\ttest loss=34.507637\t0/1 error=0.100\n",
      "Epoch 124\ttrain loss=1.599400\ttest loss=35.665623\t0/1 error=0.100\n",
      "Epoch 125\ttrain loss=1.616608\ttest loss=37.556973\t0/1 error=0.180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126\ttrain loss=1.542956\ttest loss=35.897312\t0/1 error=0.110\n",
      "Epoch 127\ttrain loss=1.607775\ttest loss=36.150711\t0/1 error=0.100\n",
      "Epoch 128\ttrain loss=1.444830\ttest loss=34.638954\t0/1 error=0.110\n",
      "Epoch 129\ttrain loss=1.538648\ttest loss=34.481358\t0/1 error=0.120\n",
      "Epoch 130\ttrain loss=1.591230\ttest loss=40.353527\t0/1 error=0.200\n",
      "Epoch 131\ttrain loss=1.500449\ttest loss=36.445984\t0/1 error=0.150\n",
      "Epoch 132\ttrain loss=1.430295\ttest loss=39.328136\t0/1 error=0.140\n",
      "Epoch 133\ttrain loss=1.351036\ttest loss=36.705730\t0/1 error=0.150\n",
      "Epoch 134\ttrain loss=1.435288\ttest loss=38.326534\t0/1 error=0.120\n",
      "Epoch 135\ttrain loss=1.559616\ttest loss=36.303810\t0/1 error=0.140\n",
      "Epoch 136\ttrain loss=1.444457\ttest loss=35.911396\t0/1 error=0.110\n",
      "Epoch 137\ttrain loss=1.510888\ttest loss=34.348396\t0/1 error=0.090\n",
      "Epoch 138\ttrain loss=1.525154\ttest loss=39.250286\t0/1 error=0.200\n",
      "Epoch 139\ttrain loss=1.571530\ttest loss=37.106792\t0/1 error=0.100\n",
      "Epoch 140\ttrain loss=1.528247\ttest loss=37.628849\t0/1 error=0.120\n",
      "Epoch 141\ttrain loss=1.415586\ttest loss=35.163757\t0/1 error=0.150\n",
      "Epoch 142\ttrain loss=1.437768\ttest loss=38.641563\t0/1 error=0.110\n",
      "Epoch 143\ttrain loss=1.492578\ttest loss=36.183842\t0/1 error=0.110\n",
      "Epoch 144\ttrain loss=1.320892\ttest loss=37.483219\t0/1 error=0.110\n",
      "Epoch 145\ttrain loss=1.343238\ttest loss=37.949127\t0/1 error=0.130\n",
      "Epoch 146\ttrain loss=1.271160\ttest loss=35.875648\t0/1 error=0.150\n",
      "Epoch 147\ttrain loss=1.194246\ttest loss=36.285908\t0/1 error=0.090\n",
      "Epoch 148\ttrain loss=1.161466\ttest loss=35.740997\t0/1 error=0.090\n",
      "Epoch 149\ttrain loss=1.513628\ttest loss=36.184158\t0/1 error=0.090\n",
      "Epoch 150\ttrain loss=1.252798\ttest loss=38.629951\t0/1 error=0.170\n",
      "Epoch 151\ttrain loss=1.533101\ttest loss=37.013103\t0/1 error=0.100\n",
      "Epoch 152\ttrain loss=1.294392\ttest loss=35.383419\t0/1 error=0.130\n",
      "Epoch 153\ttrain loss=1.327387\ttest loss=40.931568\t0/1 error=0.110\n",
      "Epoch 154\ttrain loss=1.356510\ttest loss=42.420517\t0/1 error=0.130\n",
      "Epoch 155\ttrain loss=1.105839\ttest loss=38.945362\t0/1 error=0.150\n",
      "Epoch 156\ttrain loss=1.435764\ttest loss=38.832878\t0/1 error=0.220\n",
      "Epoch 157\ttrain loss=1.124073\ttest loss=35.580952\t0/1 error=0.100\n",
      "Epoch 158\ttrain loss=1.227117\ttest loss=36.934776\t0/1 error=0.090\n",
      "Epoch 159\ttrain loss=1.438983\ttest loss=37.264271\t0/1 error=0.110\n",
      "Epoch 160\ttrain loss=1.281219\ttest loss=39.986126\t0/1 error=0.110\n",
      "Epoch 161\ttrain loss=1.209962\ttest loss=40.225311\t0/1 error=0.110\n",
      "Epoch 162\ttrain loss=1.314334\ttest loss=38.853615\t0/1 error=0.120\n",
      "Epoch 163\ttrain loss=1.460679\ttest loss=39.566757\t0/1 error=0.100\n",
      "Epoch 164\ttrain loss=1.331881\ttest loss=38.888264\t0/1 error=0.140\n",
      "Epoch 165\ttrain loss=1.318706\ttest loss=36.993088\t0/1 error=0.150\n",
      "Epoch 166\ttrain loss=1.141820\ttest loss=42.174427\t0/1 error=0.140\n",
      "Epoch 167\ttrain loss=1.169912\ttest loss=41.690105\t0/1 error=0.150\n",
      "Epoch 168\ttrain loss=1.205344\ttest loss=37.274364\t0/1 error=0.090\n",
      "Epoch 169\ttrain loss=1.264952\ttest loss=38.431145\t0/1 error=0.100\n",
      "Epoch 170\ttrain loss=1.300979\ttest loss=39.558197\t0/1 error=0.150\n",
      "Epoch 171\ttrain loss=1.325634\ttest loss=39.755127\t0/1 error=0.150\n",
      "Epoch 172\ttrain loss=1.271400\ttest loss=36.824123\t0/1 error=0.130\n",
      "Epoch 173\ttrain loss=1.346126\ttest loss=42.632782\t0/1 error=0.110\n",
      "Epoch 174\ttrain loss=1.268785\ttest loss=39.971867\t0/1 error=0.130\n",
      "Epoch 175\ttrain loss=1.154543\ttest loss=43.077915\t0/1 error=0.160\n",
      "Epoch 176\ttrain loss=1.464099\ttest loss=39.958603\t0/1 error=0.140\n",
      "Epoch 177\ttrain loss=1.219512\ttest loss=35.970192\t0/1 error=0.100\n",
      "Epoch 178\ttrain loss=1.174917\ttest loss=41.170643\t0/1 error=0.130\n",
      "Epoch 179\ttrain loss=1.198183\ttest loss=39.375965\t0/1 error=0.100\n",
      "Epoch 180\ttrain loss=1.217967\ttest loss=41.903320\t0/1 error=0.110\n",
      "Epoch 181\ttrain loss=1.489273\ttest loss=39.557472\t0/1 error=0.110\n",
      "Epoch 182\ttrain loss=1.220902\ttest loss=40.936974\t0/1 error=0.160\n",
      "Epoch 183\ttrain loss=1.166733\ttest loss=39.781181\t0/1 error=0.100\n",
      "Epoch 184\ttrain loss=1.287508\ttest loss=41.568779\t0/1 error=0.100\n",
      "Epoch 185\ttrain loss=1.186746\ttest loss=40.316963\t0/1 error=0.100\n",
      "Epoch 186\ttrain loss=1.031600\ttest loss=39.639488\t0/1 error=0.110\n",
      "Epoch 187\ttrain loss=1.316820\ttest loss=39.527462\t0/1 error=0.100\n",
      "Epoch 188\ttrain loss=1.185022\ttest loss=39.227325\t0/1 error=0.100\n",
      "Epoch 189\ttrain loss=1.276347\ttest loss=42.490322\t0/1 error=0.200\n",
      "Epoch 190\ttrain loss=1.252150\ttest loss=38.044010\t0/1 error=0.100\n",
      "Epoch 191\ttrain loss=1.234699\ttest loss=41.296696\t0/1 error=0.100\n",
      "Epoch 192\ttrain loss=1.260662\ttest loss=40.847160\t0/1 error=0.110\n",
      "Epoch 193\ttrain loss=1.234999\ttest loss=40.336102\t0/1 error=0.100\n",
      "Epoch 194\ttrain loss=1.136633\ttest loss=37.841610\t0/1 error=0.100\n",
      "Epoch 195\ttrain loss=1.462785\ttest loss=36.519264\t0/1 error=0.100\n",
      "Epoch 196\ttrain loss=1.093060\ttest loss=39.742508\t0/1 error=0.120\n",
      "Epoch 197\ttrain loss=1.223269\ttest loss=39.810238\t0/1 error=0.160\n",
      "Epoch 198\ttrain loss=1.297236\ttest loss=39.564999\t0/1 error=0.120\n",
      "Epoch 199\ttrain loss=1.275659\ttest loss=39.790333\t0/1 error=0.140\n",
      "Epoch 200\ttrain loss=1.131721\ttest loss=41.471321\t0/1 error=0.140\n",
      "Epoch 201\ttrain loss=1.206766\ttest loss=42.432980\t0/1 error=0.130\n",
      "Epoch 202\ttrain loss=1.279238\ttest loss=41.812954\t0/1 error=0.100\n",
      "Epoch 203\ttrain loss=1.269830\ttest loss=40.291348\t0/1 error=0.110\n",
      "Epoch 204\ttrain loss=1.246905\ttest loss=38.941639\t0/1 error=0.130\n",
      "Epoch 205\ttrain loss=1.247819\ttest loss=41.966862\t0/1 error=0.130\n",
      "Epoch 206\ttrain loss=1.140302\ttest loss=40.137516\t0/1 error=0.100\n",
      "Epoch 207\ttrain loss=1.328068\ttest loss=42.008469\t0/1 error=0.160\n",
      "Epoch 208\ttrain loss=1.319613\ttest loss=41.758881\t0/1 error=0.160\n",
      "Epoch 209\ttrain loss=1.223350\ttest loss=39.608128\t0/1 error=0.100\n",
      "Epoch 210\ttrain loss=1.256943\ttest loss=41.057724\t0/1 error=0.100\n",
      "Epoch 211\ttrain loss=1.150212\ttest loss=37.557240\t0/1 error=0.140\n",
      "Epoch 212\ttrain loss=1.089329\ttest loss=42.650974\t0/1 error=0.120\n",
      "Epoch 213\ttrain loss=1.116171\ttest loss=41.717907\t0/1 error=0.100\n",
      "Epoch 214\ttrain loss=1.325329\ttest loss=43.596397\t0/1 error=0.170\n",
      "Epoch 215\ttrain loss=1.041004\ttest loss=41.794449\t0/1 error=0.140\n",
      "Epoch 216\ttrain loss=1.354231\ttest loss=40.576229\t0/1 error=0.100\n",
      "Epoch 217\ttrain loss=1.311769\ttest loss=41.748840\t0/1 error=0.200\n",
      "Epoch 218\ttrain loss=1.275016\ttest loss=40.234577\t0/1 error=0.150\n",
      "Epoch 219\ttrain loss=1.236424\ttest loss=40.544128\t0/1 error=0.100\n",
      "Epoch 220\ttrain loss=1.230161\ttest loss=41.415100\t0/1 error=0.130\n",
      "Epoch 221\ttrain loss=1.343496\ttest loss=44.334919\t0/1 error=0.160\n",
      "Epoch 222\ttrain loss=1.097785\ttest loss=48.355522\t0/1 error=0.200\n",
      "Epoch 223\ttrain loss=1.317976\ttest loss=39.990768\t0/1 error=0.100\n",
      "Epoch 224\ttrain loss=1.230283\ttest loss=44.317360\t0/1 error=0.100\n",
      "Epoch 225\ttrain loss=1.223946\ttest loss=43.602558\t0/1 error=0.160\n",
      "Epoch 226\ttrain loss=1.130270\ttest loss=44.824245\t0/1 error=0.160\n",
      "Epoch 227\ttrain loss=1.292569\ttest loss=41.489693\t0/1 error=0.090\n",
      "Epoch 228\ttrain loss=1.289953\ttest loss=39.787815\t0/1 error=0.100\n",
      "Epoch 229\ttrain loss=1.290955\ttest loss=43.253391\t0/1 error=0.110\n",
      "Epoch 230\ttrain loss=1.313390\ttest loss=40.112919\t0/1 error=0.200\n",
      "Epoch 231\ttrain loss=1.136875\ttest loss=43.288559\t0/1 error=0.100\n",
      "Epoch 232\ttrain loss=1.101581\ttest loss=42.836277\t0/1 error=0.100\n",
      "Epoch 233\ttrain loss=1.293738\ttest loss=47.395435\t0/1 error=0.140\n",
      "Epoch 234\ttrain loss=1.230446\ttest loss=41.303360\t0/1 error=0.140\n",
      "Epoch 235\ttrain loss=1.260787\ttest loss=42.709209\t0/1 error=0.160\n",
      "Epoch 236\ttrain loss=1.212929\ttest loss=42.037247\t0/1 error=0.110\n",
      "Epoch 237\ttrain loss=1.250019\ttest loss=42.365162\t0/1 error=0.100\n",
      "Epoch 238\ttrain loss=1.184202\ttest loss=42.705776\t0/1 error=0.160\n",
      "Epoch 239\ttrain loss=1.207331\ttest loss=43.284431\t0/1 error=0.150\n",
      "Epoch 240\ttrain loss=1.176681\ttest loss=44.487659\t0/1 error=0.160\n",
      "Epoch 241\ttrain loss=1.043187\ttest loss=41.861576\t0/1 error=0.090\n",
      "Epoch 242\ttrain loss=1.176296\ttest loss=43.238632\t0/1 error=0.170\n",
      "Epoch 243\ttrain loss=1.029102\ttest loss=41.852154\t0/1 error=0.090\n",
      "Epoch 244\ttrain loss=1.204427\ttest loss=41.523499\t0/1 error=0.090\n",
      "Epoch 245\ttrain loss=1.264917\ttest loss=41.754116\t0/1 error=0.160\n",
      "Epoch 246\ttrain loss=1.127189\ttest loss=41.489090\t0/1 error=0.090\n",
      "Epoch 247\ttrain loss=1.277369\ttest loss=39.880737\t0/1 error=0.100\n",
      "Epoch 248\ttrain loss=1.099665\ttest loss=46.128536\t0/1 error=0.130\n",
      "Epoch 249\ttrain loss=1.080902\ttest loss=42.623028\t0/1 error=0.100\n",
      "Epoch 250\ttrain loss=1.134295\ttest loss=45.271294\t0/1 error=0.170\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_in = 2\n",
    "n_c1=10\n",
    "n_c2=10\n",
    "params = []\n",
    "\n",
    "n_out = 1\n",
    "W1 = Variable(torch.normal(torch.zeros(n_in, n_c1), np.sqrt(2/(n_in + n_c1))), requires_grad=True)\n",
    "b1 = Variable(torch.zeros(n_c1), requires_grad=True)\n",
    "W2 = Variable(torch.normal(torch.zeros(n_c1, n_c2), np.sqrt(2/(n_c1 + n_c2))), requires_grad=True)\n",
    "b2 = Variable(torch.zeros(n_c2), requires_grad=True)\n",
    "W3 = Variable(torch.normal(torch.zeros(n_c2, n_out), np.sqrt(2/(n_c2 + n_out))), requires_grad=True)\n",
    "b3 = Variable(torch.zeros(n_out), requires_grad=True)\n",
    "\n",
    "\n",
    "def forward(X):\n",
    "    H1 = torch.sigmoid( torch.mm(X, W1)+b1)\n",
    "    H2 = torch.sigmoid(torch.mm(H1, W2) + b2)\n",
    "    H3 = torch.sigmoid(torch.mm(H2, W3) + b3)\n",
    "    return H3 \n",
    "\n",
    "def L(H, Y, eps=1e-08):\n",
    "    loss = sum (-Y * torch.log(H + eps) - (1 - Y) * torch.log(1 - H + eps))  # log-likelikood\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "n_epochs = 250\n",
    "epoch_n_batches = 100\n",
    "train_batch_size = 10\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(n_epochs):\n",
    "\n",
    "    train_loss = 0.\n",
    "\n",
    "    for j in range(epoch_n_batches):\n",
    "\n",
    "        # Prepare next mini-batch\n",
    "        mb_idxs = torch.multinomial(torch.ones(n_train), train_batch_size, replacement=True)\n",
    "        X_mb = Variable(X_train[mb_idxs])\n",
    "        Y_mb = Variable(Y_train[mb_idxs])\n",
    "\n",
    "        # Forward pass\n",
    "        Y_prob_mb = forward(X_mb)\n",
    "        \n",
    "        loss = L(Y_prob_mb,Y_mb)\n",
    "        loss.backward()\n",
    "        W1.data.sub_(alpha * W1.grad.data)\n",
    "        W1.grad.data.zero_()  # must reset to 0 before next pass\n",
    "        W2.data.sub_(alpha * W2.grad.data)\n",
    "        W2.grad.data.zero_()  # must reset to 0 before next pass\n",
    "        W3.data.sub_(alpha * W3.grad.data)\n",
    "        W3.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "        b1.data.sub_(alpha * b1.grad.data)\n",
    "        b1.grad.data.zero_()  # must reset to 0 before next pass\n",
    "\n",
    "        b2.data.sub_(alpha * b2.grad.data)\n",
    "        b2.grad.data.zero_()  # must reset to 0 before next pass\n",
    "        b3.data.sub_(alpha * b3.grad.data)\n",
    "        b3.grad.data.zero_()  # must reset to 0 before next pass\n",
    "        train_loss += loss.data[0]\n",
    "\n",
    "    train_loss /= epoch_n_batches\n",
    "\n",
    "    # Forward pass\n",
    "    Y_test_prob = forward(Variable(X_test)).data\n",
    "    test_loss = L(Y_test_prob, Y_test).mean()\n",
    "    \n",
    "    # Compute expected 0/1 error\n",
    "    Y_test_pred = (Y_test_prob > 0.5).type(torch.FloatTensor)\n",
    "    test_err = torch.abs(Y_test - Y_test_pred).mean()\n",
    "\n",
    "    print('Epoch {:03d}\\ttrain loss={:.06f}\\ttest loss={:.06f}\\t0/1 error={:.03f}'.format(\n",
    "        i + 1, train_loss, test_loss, test_err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MNIST\n",
    "\n",
    "Vous allez maintenant utiliser les fonctions haut niveau de pytorch: torch.nn, torch.optim etc.\n",
    "\n",
    "On commence par charger les données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_folder = '!/MNIST_data/'\n",
    "\n",
    "train_data = datasets.MNIST(root=mnist_folder, download=True, transform=transforms.ToTensor(), train=True)\n",
    "test_data = datasets.MNIST(root=mnist_folder, download=True, transform=transforms.ToTensor(), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images dans le train set: 60000\n",
      "Nombre d'images dans le train set: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre d'images dans le train set:\", len(train_data))\n",
    "print(\"Nombre d'images dans le train set:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afficher quelques images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAADyCAYAAAB+iq2yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XecFEX+//FX7S45gyRJCyygYM45\nnJ6ihzkHDhXjieGMeJ7n6fk7Uc8czsMzZwQ9s98TDGcWTCBBQLISBIkSd7d+f/RsVcvOxpnpnp19\nPx+PefCZmp6Zms82U9PV1VXGWouIiIjEJy/uCoiIiNR3aoxFRERipsZYREQkZmqMRUREYqbGWERE\nJGZqjEVERGKmxlhERCRmaoyrYIxpa4z5yRjzYdx1yXXGmMeMMRuNMWtCt/y465WrEvv288aYpYnb\n08aYlnHXK1cp39EzxjQyxjxijFlljFlkjLks7jpVRI1x1W4BpsZdiXrkVmtt89CtJO4K5bCbgDZA\nL6A30BH4a5wVynHKd/T+CvQBegAHAlcZYwbGWqMK5GRjbIy50hgzZrOye40xd9XwdfYEtgEeTWf9\nclG6ci7Vk6Z89wT+Y61dZa1dCbwEDEhnPXOF8h29NOX898DfrLXLrbVTgYeAM9JYzfSx1ubcDegM\n/AK0TtwvAJYAOwMPACsquE0MvUY+8GXiOWcAH8b9ubL5lqacPwb8nLh9ARwX9+fK1lua8j0IeIPg\naK0N8A5wadyfLRtvynfdy3kixxboGHrN44FJcX+2pJ837gpk8A/5JnBOIh4ETKnh8/8I/DMRqzGO\nJuc7Ae0S/+kOB1YDe8f9ubL1loZ8bwmMBUoTt7eBhnF/rmy9Kd91K+dAt0Rj3DhU9ltgTtyfK9kt\nJ7upEx4HTk/EpwNPVveJxpgtgYuBazNQr1xW65wDWGu/tNYus9YWW2vfAJ4Gjk1zHXNJSvkGXgCm\nAy2AlsD3wFNpq13uUb6jl0rO1yT+DQ+Sa0nwIz/7xP1rIIO/qBoDywnO+a4BuifKH0zcT3abnNjm\naGA9sChxWwlsTMT5cX+2bL2lkvMKXu+fwB1xf65svaWa78T97UP3dwDWxP25svWmfNfJnP8I/DZ0\n/0bgubg/V7KbSVQwJxljHgJ2B5Zaa39Tg+c1IjjfUOYk4FTgKGvtovTWMrfUNueJ5x4PvAWsBQ4G\nxgBHWGvfS3c9c0WK+X4X+Ba4KlF0O0FjsXd6a5k7lO/opZjzEcCeBAdYHYF3gTOttW+lvaIpyuVu\nagi6OLal5t2lG6y1i8puBEfGm9QQV0utcp5wCfADwSCM2wjOFb2XvqrlpFTyfRZQCCwgyHsvsnWk\nafZQvqOXSs6vJzgdMBd4H7gtGxtiIOePjLsD04BO1tpVcdenPlDOo6V8R0v5jl59yXnOHhkbY/KA\nywjOD+TsHzCbKOfRUr6jpXxHrz7lvCDuCmSCMaYZsJigayIrZ1vJNcp5tJTvaCnf0atvOc/pbmoR\nEZG6IKVuamPMQGPMd8aYmcaY4emqlFRMOY+W8h0t5Tt6ynl2qPWRcWI1nekEM5osAMYDp1hrp1T0\nnIamkW1Ms1q9X321muVLrbXtoeY5V75rLpV8g3JeG2U5V76joe+UaIXzXZlUzhnvBsy01s4CMMY8\nBxwFVPgfpzHN2N0clMJb1j9j7ei5obs1yrnyXXOp5BuU89oI5Vz5joC+U6K1Wb4rlEo3dRdgfuj+\ngkTZrxhjzjXGTDDGTNjEhhTeTqhGzpXvtNI+Hi3lO3r6TskSqTTGJklZuT5va+1Ia+0u1tpdGtAo\nhbcTqpFz5TuttI9HS/mOnr5TskQqjfECglUxynQlmAdUMkc5j5byHS3lO3rKeZZIpTEeD/QxxvQ0\nxjQETgZeSU+1pALKebSU72gp39FTzrNErQdwWWuLjTHDgP8D8oFHrLWT01YzKUc5j5byHS3lO3rK\nefZIaQYuG6w5+0aa6iLVoJxHS/mOlvIdPeU8O+TkdJgiIlJ/zPl/e7p4n4Mmufh/72/r4j43B1dr\nlaxYGV3FaiBnF4oQERGpK9QYi4iIxEzd1CIiUqcVXvuJix8+82sXl5z+PxdPP2k9AOcPu9SVNX7t\n8whqVz06MhYREYmZGmMREZGYqZtaRAAoKOwOgF233he2bpl021XbtAPgh4Glrqz9R/7rZIsX/aWq\nJatWpbOaWSG/pc/L2n37uXjewOD45ouj73RlbfKbuniTLan2e+z42e/9e/zQHICt7lvmyux8P1FW\n6dq11X7dXLfdP/7g4q2O/c7Fz/Z8G4C7773XlV21/DwXm49893YcdGQsIiISszp7ZDx7hL+ubPrv\n/+nipSW/AHD8uf4kfaM3x0dXMYmc2XEAAGt6N3dlP+7vHx9+8KsuPrdVcDSxz0X+F3GzMZ9luIbR\nMjsPcPH6DsFR2ZKdGriy5nv9lPR59/V/BoAv1xW6sqGt5rm4lNLNn/IreYf73/b9tx7m4uL2m8pt\n2/esCZW+VjYq6LKli/d7a4aLL207LsnWPt/ho+Gqchj2xe6PlS881ocjlm7v4k/3bO3fI0eOkvO3\naOdi28kvB1z67bRKn9f5jo9dvHj6bi5+4JaZAPyh9WxX9tNVvheo8xltXFyyfHktapwaHRmLiIjE\nTI2xiIhIzOpsN/XeB3zr4nA3UKu8xgD8cKD/aL3ejK5e9VV+G9/Fs/wwP6Cl1XerXbyqqAUAJY38\nEqptJicf3PPjAa0AWFPo/7aD9/vQxbs1+97FWzUIygsL/ECZsI82+N+cRc+cD0Cft/yUedXvOMxe\nCy/fy8X/Hna3i7dvWH7bvNBv8GTdpts3nPOrrWvj29PvcfFpsw4DYO15bV1Z9Ycxxa+s2//KUc+6\nsj0bb0i67fOrOwOw3vrE54dyXFKDfHZp8LOLD26yutzjw7f4xsXHNDzYP5AbvdQsP6SPi2/+20gX\nn/nfs1281R8nAlC6PjToMCR8HfHrP+wDwB9e893UE3Z5xsV97vKv22eIuqlFRETqHTXGIiIiMauz\n3dRhC0vWufjM6acC0GJW6q9buv+OLj7ygXcAuOv/DnNlRZd9mvqb5Ihlg7Zy8ccj7s/4+22wxS7+\nOdELuNuXJ7sy84ofidnx7R9c3HtO8DfLha7psC8u89dOJvtsf1myq4tHjfdxw8X+K6D3k0uq/X6r\nt9kCgB5X+Os4H+3hRxXvfM8lLu7x1BwASn6YXu3Xj1v4OuIFiVMm4a7pqRt9lk8e77s3e54ZfPGU\n/vJLynVYdeqRLj74tnsr2TK3bDp4ZwDanzfHle3b2P9/v++3T7j4gdbBZROli5J3U4eZmcGVAUPm\n/saVPd7jHRefsN2XLp6UGMldstRf151pOjIWERGJmRpjERGRmOVEN/WkjVu4uHGix6j9nE8q2Lpy\neY0bu/jnK31X0/mtg+6nfkc+7MruemCQi0tm+hF69dEWHy108T4TT3DxSd2/cPFFrat/7uDmZf0B\nePSdA1xZ6yl+FHbzH/143LIRk1uQvBu0OGlp3Tf3Rj/xTQPjp/JbWuK77A6850oAtrzNT4TQl+ST\n4CQb4Wwa+FHB86/YxcX3nP0vAAoL/ELtAwf7ruku7/j3q4v5nzrCn3aZdtTd5R4/5bE/urjHDf6z\npnr6Y9Wpe7h4nysqn4zmt9+e6OKmv/xQyZZ1S/Prgs/yUtEbSR+/7LkzXVy4qPrf86WrgxHpH4/3\nOSbUTf33Dr6beuCAoQDkvR9dN3WVjbEx5hFgELDEWrtNoqwt8DxQCMwBTrTWRj8WPEdNthNYykIa\n0siVKeeZo3xHK5zvPc0hgPKdadrHs191jowfA+4DngiVDQfGWWtHGGOGJ+5fnf7qVc8hTfwR7KXn\ndwGg1/B5FW1eKdO9i4s/3vHZco8f2MQfddzZtFG5x9NhS3rQjd5M/vURTFblfHPFs+a4uMXf/DR9\nfZ5YVG7bU2b/1sU/3lXk4lYfzXVx6crg+uOitZkfJFcX8w2A9T0F4WvtRy7fycXdHgmmDqzJdb35\nRT1dXPIvP5Xll1v5I8T9vzkFgBY3t3BlBR/4XpDK1IV8m1Buk/n3kPtcfM3X57u4ycs1Xx+35AD/\n9wofDd/UsfxrDZrm58NsdqX//indtLHS98j6nO+xnQsf6PlAIko+b0Cv0b43pjY9Eb1eCuXq+OTb\nzD7PAtD7/Vq8QS1Vec7YWvs/4OfNio8CHk/EjwNHp7le9Vob054GlJutQTnPEOU7Wsp39JTz7Ffb\nAVwdrbULARL/dqhoQ2PMucaYCcaYCZtIPmuNVEu1cq58p4328Wgp39HTd0oWyfgALmvtSGAkQEvT\n1mb6/T4/7XYADpt0mStr9XT1uzpnn9wx7XWKUtT5xgTdeaX77OCKLn3Ud++Hp/G7bklw/eCqg9a4\nsmYbfLdcXRzoAzHkvAqXt/NTxb69634ANHxr886t8n45fncALv77c67smGb+ef2fvNjFfW4Lri8u\nWTYztcrWQhT53uqaqS7e77Pgc9/xV3/9/C6NfMf/P+7y5VeWXAj8ehrGsLwWvlt//h+2BeCZC+5w\nZf0a5Cd93gkzjwiC6/3186UTo1l/N4p8lzT2TVHn/PLd0/2e9WsUF03+stzj6da2VerXiddUbY+M\nFxtjOgMk/q3+bAFSW8p5tJTvaCnf0VPOs0htG+NXgCGJeAjwcnqqI5VQzqOlfEdL+Y6ecp5FqnNp\n07PAAcAWxpgFwPXACGCUMWYoMA84oeJXyIwP39/G3zn9PRc2zwtGGBZd6BegXvq8/5i2uPLO0MY7\nV92dl2mT7Gcs5ycS52e2S+Q59pwns2JwcM3exzcnnwJzn4l+isqWh5WttJRd553qUr7Det0TWmT9\n7Iq3q8yPV/nVnh6+IBgtPWaFny7zsUF+NaCihb77u2R1+VWEqiuc7w/s6wBbkGX5LlnlVxNr/URw\nLes1K/2o6XDXdHhlrHvvC1aruqT4IleWF5o6c/Xl/nW/2KFsdHryruk31/qV0IrPD7q386bWrms6\n2/fxZX+sfKmpRj/740ZbxcjxVN8rLlU2xtbaUyp46KA010UStjW7u3isHT3RWls204hyngHKd7TC\n+QYYa0cvtdYuQ/nOGO3j2U/TYYqIiMSszk6H2esaP1pxm43DXPztWcHF+OEVZNbM9t2iuz7vR1n3\nu3tBudc9rPuUSt936/eHurj3pG8q2TJ3hUeEHnHFu+Uef3J1Jxe3vrKBi3NtpaS4lSzzp1QWFPuV\ny7oWNHHxmmHBBAlt3/LPm/2sn5Rl8n5+NaDFJcH/k/dv99MFtpqulcnKhCf0KBs1Db5rGvxo6H//\n605XFj7i2bKg8omCtvqv7wrvf43/fipZNKPG9c16eb57vlVoMqV8E2Rs0HS/Ql7Xv/spR2uroGsw\nodN5fT4o916ba3Vr85Tfr6Z0ZCwiIhKzOntkTKm/zq/njX4avm1tcJQ8aaifrq5sUBfA1FP8wIvP\njy0/5d1ujZJfRnfHz8HE8f3+5I9Gim3sl5TGIq+VX+t1l6blr6cc3MJPgbnTa4+5ePy6QgBufsNP\n9NN35FIXl3wX/TWruWLwZZe7eNw9ft/v2TqY6H7iqG1d2eS9H3HxkDl+gNbCvwVTk7Z6S0fDVQlf\nR3zqAN/b9sXFwaCsrqEj4LzQMU9pqH/o243B98dVQy9wZf0+mOTi4hQHKmU7s71fjGPcgCddXJL4\nWi2tYkrSmtpQFMwhcU6r+eXeC+DeFb1c3HDWT0C0cx/oyFhERCRmaoxFRERiVne7qUPC150V3his\nSjKggR/U1X+v5Ovo9m8ZrMF7Q4evqnyPkeOCKwCK5qgLr3iBXzv1mjuDAW2XHbgq6ba/6zXZxSM6\nBqcTzjj5AVc25gh/LeXIc49zcf57mZ/yLpe0eNN3bw6ePdDFT/ZMjNzyCzHxhwUHuHjliX6wV8Mf\nkq9zLOXNv85fn/3cUD+dZR4Nym3bwPiBSuPW+YuSb+0dnDoowJ9mq58nvjInbxvfFX7Kg69Vuu1D\nTx/u4q7zUx8wVlM6MhYREYmZGmMREZGY5UQ3dVjZdJc9r/nEla2rYNtvunQFYMfB+7iyry66t4Kt\nJZkO9ye6c5LPhsnEUHzEgGAyt62f8NdM3tppgouvGeo76YreS1cN6wfTpLGLB7RYWOm2PxzuR/qW\nLPsxY3XKFXmNg9zOum5HV/bIKX7EenilpdIkV9NvCvU9l9jy3diSXqbAN2tLbvZ/j/BVHmUeXNnD\nxYVPzHVxHCvI6chYREQkZmqMRUREYpZz3dQ1UfxD0EXX6VM/fSN+sRXWWj9Ku9doP12b1E7J5GBB\n+in7+sXDX/jKL5Y+/TcPu/jQA4NliPLf1ajqzeW3DCZdWXrsAFf2yf/z5wlKfzUmt/zv7fA0mpJc\nQa9CF0+5LthHpx1yT9JtZ27ynZqnfn0WAE0abnJlH2z/vIu3arjcxesH7Qb8egIRSd2Mf+zi4uk7\nPVDJlvDAU0e4uOuC6EdQh+nIWEREJGb1+si4KhusP/mf92Ht1hGV8krX+vVEH17gB8+dsJVf2/yn\n7YNBM53Kr0NR782+NFjL++vz7nZlpaHf1ePW+Z6HA5usia5idVx+/74ubvSgP4Kd1vuFcttODa1R\nfOHVf3Rxp1HBPARmVz/9KP/xYcf80DSZlywOgsovf5VK5A/oB8C081q7slnHP+jikiQXbh8143cu\nLnzkexfHMWgrTEfGIiIiMVNjLCIiEjN1U0us5nzR1d/xM9exYa/VQXBXtPXJVsuG7unil4feloj8\n1Io73O9HHraY57tQD7xF181XpnRff+3whY/4gVaHNl1ZbtuyVZYALhp+iYtbjCo/Ra4dP6lc2eZO\n6RpMPzqGDtWrbI7JX/mLi98KnVoZ2CQ4jTVjvL8GuBf+eviVp/n1tlceHbzGjL3+GXplf4y5rNTP\nMvHbf1wJQJfn/OpwJYuX1Lb6aacjYxERkZhVeWRsjOkGPAF0AkqBkdbau40xbYHngUJgDnCitXZ5\nRa8j1bPermUy49nAegwGCH42K9+ZE845MMAYc4n28czRPh4t5btuqE43dTFwubX2S2NMC+ALY8zb\nwBnAOGvtCGPMcGA4cHXmqlo/GAx92I6Wpg3FdhPv8XIHY0x/cjTfxa2Tj2HcsKxJ0vJMCOd8rB09\nFbgwG/bxFYN91/SL19/m4rIRuQPeO9eV9f67v0Zyw2G7RlC72sumfXzmWb5zMFnXNMCIpdsD8NH5\nPq8tPql89baZd+4RuudXZfq5ZIOL73voaAA6k9nrW7Mp32HFs+a4+Oarh7h44D1Bl/O7J/t9fmDR\neS7+aLc7Xdzc+NHpyZw761gXd7o7yHNJ7aqbcVV2U1trF1prv0zEq4GpQBfgKODxxGaPA0dnqpL1\nSSPThJYmWFawwDSAYGpt5TuDwjkn6P3RPp5B2sejpXzXDTU6Z2yMKQR2BD4DOlprF0LQYEPyUQjG\nmHONMROMMRM2sSHZJlKBdfYXgKYo31FqiPbxyGgfj5bynb2qPZraGNMcGANcaq1dZYyp1vOstSOB\nkQAtTVutnV1NxbaYiXwCMD/X8j3jbt+FN/6w2128PLTgTc8x0XcmFdtigN7A4GzI+ccjwlNc+m77\nvb4KVr/qfdpXriy/X5GLG13hV23KS/zenldc0dpl8YlzHy+bUvSp/R+qctsXHzkAgE6fJO9ODi9g\nP+3C4HUnHRG+DMCv1DRpo+uBofMd0U6/mM3fKc1f85MqFf32fABmHuEn7/hm9ydDW1feNX3mvH1d\nvPGI7NvvK1KtI2NjTAOChvhpa+2LieLFxpjOicc7A9kzRryOK7WlTOQTOtEdYEWiWPnOoLKcAz9r\nH8887ePRUr6zX3VGUxvgYWCqtfaO0EOvAEOAEYl/X07y9DqhYKXvevl8g/+12CeGpUettUxhAs1o\nQQ/TlxnWrQiclflecM1eAKxv7w9riy7zg1vymvrrB2c8FExd9+3+fsL9RsYf8e18yzAXdxwb3VFD\nOOc/s3hx6KFYcx5e8CG8Tu61/d4A4O+vH+bKPtrhuaTbfrEh+L09/CI/ZWMjxqe/sjWQDft4yZrg\n+tRzvvy9K/tqz0eTbnvLRcECJj+c3ybp470b+lW792xc9l3i1zj+85KdXTzuAT8orx1+zfVMyoZ8\nV1nHDf47uN+wYHGYgU+d5co2XOcH1727zRgX/2nJTgC88NHu/vlXfOPi0vV1Z4Gf6nRT7w0MBiYZ\nY8r6Ev5E8AccZYwZCswDTshMFeuXlSxjEfNoTis+tW8D9DfGHI7ynTHhnBPk+2u0j2eM9vFoKd91\nQ5WNsbX2Q6CikwsHpbc60tpswcEc7+6PtaOnWGvfSNxVvjMgnPNEvncJPaycp5n28Wgp33WDpsME\n7FeTXTxs0qku/mjnJ1w8769Bd2z3t5KvgpM3ebaLS1evTncVY5ffvr2L277s12p9sltwLeD+/77S\nla083Q/QGjDsWxe/1q1svWK/2/V9Z6iL+zzg13XNypFnWeKwpsG8DIft8Eyo1A//+GqDj898Ipgm\ns/vr8a7VmnVKgwGCPW4KjRp8PfmmbuWrGqyAtfU4f13sVhf7lYHarYima7ous8XB3APhlfKaHOof\nP5ydyj2nD5+5uLTco3WDpsMUERGJmRpjERGRmKmbejOr1/jRvT+XbnTxxHMSq9+c47ddXupH6p36\ne79qTv67X2augjGZfWEfF7/a4z4XFydWDnrtrFtdWWGBH0E9p3iti89fEPQ1TbxvO1fW9wV/rWxp\ncdzLe2eXvq+f7+8k6bfv92+//+Wt9Hk2G/x+232uuqcrUzrxOxfv+beLXbyiv+/s/MshLwFwSosf\nXNk/V/j/D/eM832oW98erC7UZ57fr0usTrpI1XRkLCIiEjM1xiIiIjFTN/VmwlMMnnjSFS5+/45g\nasL+T/uJKdpM8c9r825uj5JsN8lPT/lDie8S7ZIfdElP3uintT34bT8ivd/9fjq6slHrrUOTHdTV\nkY9R6Htu5ZNzhDs/s3UlmqxX6jPX/kG/X7YPbfIsW/7q382FR/LqRIvUlo6MRUREYqYj40q0eN5P\n6zjo+WBKu14RTWGXbZqN8b/+zxmzT6Xb9mWCizV0RUSkajoyFhERiZkaYxERkZipMRYREYmZGmMR\nEZGYqTEWERGJmbERTtVmjPkJ+AVYGtmbRmsL0v/Zelhr21e9WXmJfM8lM/XKFun+bLXON2gfr6VU\n93Hlu2b0nVK5WL5TIm2MAYwxEzZbLzZnZOtny9Z6pUM2frZsrFO6ZONny8Y6pUu2frZsrVc6xPXZ\n1E0tIiISMzXGIiIiMYujMR4Zw3tGJVs/W7bWKx2y8bNlY53SJRs/WzbWKV2y9bNla73SIZbPFvk5\nYxEREfk1dVOLiIjETI2xiIhIzCJtjI0xA40x3xljZhpjhkf53ulmjOlmjHnXGDPVGDPZGHNJoryt\nMeZtY8yMxL9tYqyj8h1tHZXv6OupnEdbR+U7U6y1kdyAfOB7oBfQEPgG6B/V+2fg83QGdkrELYDp\nQH/gVmB4onw4cEtM9VO+le+czbdyrnznWr6jPDLeDZhprZ1lrd0IPAccFeH7p5W1dqG19stEvBqY\nCnQh+EyPJzZ7HDg6nhoq3xFTvqOnnEdL+c6gKBvjLsD80P0FibI6zxhTCOwIfAZ0tNYuhOCPDXSI\nqVrKd7SU7+gp59FSvjMoysbYJCmr89dVGWOaA2OAS621q+KuT4jyHS3lO3rKebSU7wyKsjFeAHQL\n3e8K/Bjh+6edMaYBwR/xaWvti4nixcaYzonHOwNLYqqe8h0t5Tt6ynm0lO8MirIxHg/0Mcb0NMY0\nBE4GXonw/dPKGGOAh4Gp1to7Qg+9AgxJxEOAl6OuW4LyHS3lO3rKebSU70yKePTa4QQj1r4Hro3y\nvTPwWfYh6KKZCHyduB0OtAPGATMS/7aNsY7Kt/Kds/lWzpXvXMq3psMUERGJmWbgEhERiZkaYxER\nkZipMRYREYmZGmMREZGYqTEWERGJmRpjERGRmKkxFhERiZkaYxERkZipMRYREYmZGmMREZGYqTEW\nERGJmRrjChhjuhhjXjbG/GyMWWCMOT/uOuU6Y8yJxpiPjTFrjTHvxV2fXKd9PFrGmMnGmDWhW7Ex\n5tW465XLjDG3GmPmG2NWGWPmGmOujbtOFVFjXLGngNlAR+B3wN+NMQfGW6Wc9zNwFzAi7orUE9rH\nI2StHWCtbW6tbQ60AOYBL8RcrVz3MLCVtbYlsBdwqjHm2JjrlFRONsbGmCuNMWM2K7vXGHNXNZ/f\nHDgA+H/W2k3W2m+A0cBZaa9sjkg15wDW2rHW2lHU8QXLo6B9PFrp2L83sx/QgWBhe0kiTd8p31lr\nfwkVlQJF6apjOuVkY0zwi3+gMaY1gDGmADgJeNIY84AxZkUFt4mJ55vN/i2Lt4nsE9Q9qeZcakb7\neLTSvX8PAUZv1lDIr6Ul58aY4caYNcACoBnwTNQfpFriXuA5gwtHvwmck4gHAVNq+PwPgXuBxsBO\nBF2o38X9ubL5lmrOQ69zNvBe3J8n22/ax+tWvkOv0xRYBRwQ92fK9lsac26AHYEbgBZxf65kt1w9\nMgZ4HDg9EZ8OPFnD558G9ATmA/8Enib4ZSUVSzXnUjPax6OVrv37WIIfPu+no1I5Li05t4GvgHUE\nDXLWyeXG+D/AdsaYbQh+UT0NYIx5cLMRjeHb5LInW2vnWmsHWWvbW2t3B9oBn8fySeqOlHIuNaZ9\nPFrp2r+HAE/YxCGbVCrd3ykFQO8I6l1jJpf3B2PMQ8DuwFJr7W9q+NytCY4SNgAnEozy3dpa+1Pa\nK5pDUsx5PtAAOAM4FTgEKLHWbkp3PXOF9vFopZLvxPO7AnOAftba79NcvZxU25wbY/KAc4BRwApg\nV+Bl4GZr7T2ZqGsqcvnIGIIujm2pXdfGocAsYDlwPjBQX1LVkkrOBxN0I/0T2DcRP5S+quUk7ePR\nSiXfEOzjn6ghrpFUcn4M8D2wmmBA2L2JW9bJ9SPj7sA0oJO1dlXc9akPlPNoKd/RUr6jV19ynrNH\nxokuisuA53L5D5hNlPNoKd/RUr6jV59yXhB3BTLBGNMMWAzMBQbGXJ16QTmPlvIdLeU7evUt5ykd\nGRtjBhpjvjPGzDTGDE9XpVLRG+miAAAXLklEQVRlrf3FBtPODbDWzo+7PumknEdL+Y6W8h095Tw7\n1PqccWLk63TgtwQjMscDp1hrp6SvehKmnEdL+Y6W8h095Tx7pNJNvRsw01o7C8AY8xxwFFDhH7Gh\naWQb0yyFt6x/VrN8qbW2feJujXKufNdcKvkG5bw2QjlXviOg75RobZbvCqXSGHchmLmnzAKCa8F+\nxRhzLnAuQGOasrs5KIW3rH/G2tFzQ3erzLnynZqa5huU81SFcq58R0DfKdHaLN8VSuWcsUlSVq7P\n21o70lq7i7V2lwY0SuHthGrkXPlOK+3j0VK+o6fvlCyRSmO8AOgWut8VLX2Xacp5tJTvaCnf0VPO\ns0QqjfF4oI8xpqcxpiFwMvBKeqolFVDOo6V8R0v5jp5yniVqfc7YWltsjBkG/B+QDzxirdWk/xmk\nnEdL+Y6W8h095Tx7pDTph7X2DeCNNNVFqkE5j5byHS3lO3rKeXbI2ekwRURE6go1xiIiIjFTYywi\nIhIzNcYiIiIxy8lVmyT3FfQqdHH+o+sBuLqbH4NyY6+doq6SiEit6chYREQkZmqMRUREYqZuaqmT\nNnVs5eIXi14AYHXpRle27ujdXNzkP59HVzERiUzeDv0BKGnSIOnjM85o6OJuhUsBGLfNaP/80NTc\npaEpuZeWrANgv2evdGVFN3zjt127NpVqJ6UjYxERkZjpyHhzu23rwkV/Knbxl7s+DUC+8b9flpb8\n4uIjr7zcxS2e+zSTNaxX8ho3dvGcq/ygrOfPuiO0VT4Apx9znitpNuVbF5dmrnpZb+OhuwAw5xi/\n39584AsuPqH5Mhf3HfUHAPrdMNWVlaxYmekqiiSV36/IxT8M7ODibU/ySy3/rctIALoWNHFlpVX8\nj//1o/7/xROrurj49JbBqpLfnn6PK9t+/SUu7nH9x5VXvhZ0ZCwiIhIzNcYiIiIxq9/d1HtsB8BP\nf9rgij7Z+REXFyS6PwHOnHcAAJ/O6enKpu73qIsXD/Kv0eK5dFe0/inrnp4z3HdNf33O3S5eXOJP\nIezwr8sAKJzytSvLxACLumL2zXu6+OvBQc6a5vmBLCU2eTfe9BMfAGCXmcNcWYf7098dV2eFTmGZ\nr75zsd20MdnWKZs7yr9fk0abAOhw1LSMvFc2Wrx/exd/ftXdFWzVqNLX+GqDP958c3Xwff/ZWTu4\nsvwl/jSMXeNPO950x+8AmHbIg65s7Jm3unjo9ftU+r61oSNjERGRmKkxFhERiVm966aee8NeLh4z\n5HYAGpsSV7bVq5e5uP8ti11cPHcBAK3OaOpfbL9M1VLKRk6Hu6bDjv+Lv/6v+2NBV2p9HjU9e4Tv\nmh5/uh9p3sgE3Xg9/3OuK2s63/+3L95hjYs/2uufAKzp4a+37Lx1H/8mS/zI65JlP6eh1nXDmhP3\nAOCp2/7hyi7c5RgXl/z0U0qvn9eihYtnX+G7pr/c6y4X7/rZmSm9R64auy7I3bNL9nBlX7zV38WF\n/0h26mqyK7Ot/XwF888e4OLPDr4tEfnTO8f92X/ntOaTlOqdjI6MRUREYqbGWEREJGb1opt65l2+\nC2PKCb7b88+Lgy7rL0KTSfQd66dO9ON1veKjlrt4Vel6Fxc+ot81qVpzwu4uHnR00A2UF/q9uNUL\nF7q46LH0dxPVNUuG+VMun53mu1C/2tDcxTeeF3RvhvfrihwwPOiG6zjTn7a58NVXXXzR62e4uM8l\n9Wdim22uCKZB7F7QNOnjxb/Z2cVzDw+mZWzRZ0W1X//VHf/t4s7577v4pqV+1G/h5auD96r2q9Z9\nHV+c7uIjJw5Nuk3B4mA0dPHsua6sO/4KgPCpq/w+vQDo8pQ//ThjZRsXTxgQPiUWdE9fvcif/mk7\nOjQdZjXqX1NVNsbGmEeAQcASa+02ibK2wPNAITAHONFau7yi15CamWwnsJSFNAwN21fOM0f5jlY4\n33uaQwDlO9O0j2e/6hwZPwbcBzwRKhsOjLPWjjDGDE/cvzr91au9ny7wv2jePfY2F/958b4unnLk\nlgA0WPBFla9X9uv3g53vd2U7vO+P1Hq/U/VrVNeW9KAbvZnM+HBx1uc8VT3/6K/dvKljcCT3yQY/\nAXy/B/xAGX/slrq6lu+8psER2uDz33JlLfP8tKFX/N1PC9pubPV7EHqM+hHw60MDDGzir9e2jdOT\n9bqQ75Wn+d60O7csmxLRf10WjPZzEDzRy0+ZuNYGg98WlVR+/WtY+/zk2751ix8h2nJOaj0RdSHn\nmytZ6gcMEo5DkvUU5A/o5+K5R7Zz8dfD7i23bYNu/u84deMmFw/6IPhuLxr8VRXvlj5V9q1aa/8H\nbD508ijg8UT8OHB0mutVr7Ux7WkQGsWXoJxniPIdLeU7esp59qvtic6O1tqFAIl/O1S0oTHmXGPM\nBGPMhE1sqGgzqVq1cq58p4328Wgp39HTd0oWyfgALmvtSGAkQEvT1laxedrscZbvXlhv/ZqVk0/z\nK4GULJhR+YuEpr/rd0twbVoT439ddnqp3C/N2MWV75qwe/uBKVvc6gde3NXtNRd/tSHodr3hbD9w\no2B6+k4FpFPkOe9bCMAlbT50RdM3+a7lDi/6KROr6lheeq4/nXPjVcH0ruGu6TXWf/l2f9X/P4pT\npvJt99rexSNuHOniRqbyr8kD7vfXn3Z7LehELP226mkrSw4IBo4++YTv5p5R7Afftfmv/35K52mZ\nmorrOyW8alNx22YuNp/4gVSrTw5OJxRd4ldyuqLz4y7u18B3QycbdPXnJf67aMx//CnMor9GPw1s\nbY+MFxtjOgMk/l2SvipJBZTzaCnf0VK+o6ecZ5HaNsavAEMS8RDg5fRURyqhnEdL+Y6W8h095TyL\nVOfSpmeBA4AtjDELgOuBEcAoY8xQYB5wQiYrWRNmx2BKs+s6/suV7feM70bqNbXy0aUz7vXXur59\n5O0uLkxcY1i2ehNAy28yM7p3kv2M5fxE4vzMdok8Z23Oa2rRHv56zdcLx7r4kw2+K+qie4KF7ju9\nk/nuolzId4s83wm3ftfeLl7VIxiNvrq737bVTktd/P72d7o4fAqmzA6vX+zivq9Vfa1ydYTz/YF9\nHWALsiDfq6/zU4Pu29iPnC07BTBs6EWurOBdP81il9JFLq7q+tO8Zn4f3/WuYGRzh3z//+GIv13g\n4nZL03ctfV3cx8OrNo2+1l8R82OJz9c2DYMcNQ3tu6Wh1fZKrO9Vv2XZjgC8fo8fpd5+1Lcu7r46\n3hXKqmyMrbWnVPDQQWmuiyRsa/wPgrF29ERr7cOJu8p5Bijf0QrnG2CsHb3UWrsM5TtjtI9nP00b\nJSIiErOcmw5zU9tgFG7TPN9Vce3RY1x8Q+vyl9IN2Gq+i78q8iulNDe+O+R33x0BQP6pvvuqZNGs\nNNS4/th0yC4AjL30tlCpn6zirDG+i673XVrUvkLfB/vrLcu2dkVXt5vq4rcfHVnuKRUr3zV93MzD\nXLz11X5KwjhH9GbKsqF+NPmrA/x++d56v5rPddcGp0xajEt9CtBNu/oJKW5oH0yDuax0nStrPVOX\nDiWzZUGjUBzeEytvws6Y4/fllfsEE4e0C624lE0rvenIWEREJGY5d2RcMC64FnWvz852ZR/v7idi\nH3zEg+WeM3nTRhc3N/4X2PLQL9alzwQjYNot0gIFNZHfv6+L110e/DJtE5q68f4VfrBR35F+Avdc\nPApLl9LVwaIBH57ir5F8aNj+Lm7Ubl255zSY4NfM7f277108puhNF1+1KOi5+OXazq4sb4UfqJSL\nSo70UzGHB1LtO+ocF/d+LrUj4vyWLV288dry0zr+7i9XuLjtu/p+KdNmhu8l2HrseZVsCeft9IGL\nL23rrzl+qNDPXXDm/44EYMNJvte0eKEffBc3HRmLiIjETI2xiIhIzHKum7pM1+Mmu/jk7c9ysQ1N\nj1Zm/iG+G2nihfe5+Pipp7m43b/VfVRda4/xl1GceJNfWejc1jOBXw+a+O/Rfi3pkhkaEFcTJZP9\nKld9L6hkQyC/rz8dcPLQ5NcLv/9g8Hdr92H92debP+4Hag34epiL+42c4+JU1+r5Zf+tXPxOf3+a\nbNy64JRYh//6KWHr03rFVcl/90sX93m38m3fwV+/PfpMf238tX960sXP9w6+i/pf6v/Ova5WN7WI\niIgkqDEWERGJWc52U4eVfjM1afmys4NrDB8+O7zotF+Z5scv/ajSnszJRNVyRun+O7r4pXvucHGL\nvPLXsV69yF/bWdzBnyIwVSyiJbXX7akfXXxCcz+it+jl813c96H60z1dpumLn7m4x4u+PJ3dxQv3\nDo3eDV0n8NdrgxXJWvyQ+vXL4rV91O/H98/yM3we9kxw/f23p/tVsvaZdnHS58VBR8YiIiIxU2Ms\nIiISs3rRTV2Rn3cIxvXu2sh3TR8143cu7jNyoYs1yjG5/D69AJhxrJ8sJVnXNMA9y4NRpf/3ym6u\nrPtHmvYyk6b/a1cA3ujiVzE74ftDXbz18Gku1kQr6VO6j5+QZdRJfordWZt8lls8r+7pTGs4Z2ml\njzf5OXv2eh0Zi4iIxKxeHxlvWfRTubKN13RwsZn1TZTVqZO+uz64TvO7A+93ZeHriL/d6NcTffeA\nQgC6L9XRcCaFFz/48vBgTe6vN/r/6muu3tLFZpX28UyYdbyf8nXbhg1c3O99P61jb3J7qtHvb9/D\nxR0T4+Saj8p8b0BBj24u/m5Y10q3XdfWD65rkrEaVY+OjEVERGKmxlhERCRm9a6bevkZvgvvtQH/\nAOCoGce7soLJs12cPaf242ca+EFZDce2dfG0omBFrAbGd/dM3ehXW/nLnse4uGSpX5VJ0iu8MtA1\nVz/t4paJFbIuuOFCV9bmk/p3PXFUTEHwlTr0N37+xut/2t7Ffc7260Nn01q6mTD1ZH/qauZxwXfC\noCP8flg0+Ku0vde6o/yg0J3+4qfRfLHTi+W2vX3ZNi6O+9risCobY2NMN+AJoBPB/jPSWnu3MaYt\n8DxQCMwBTrTWLq/odaR61tu1TGY8G1iPCSYg6QCgfGdOOOfAAGPMJdrHM0f7eLSU77qhOt3UxcDl\n1tqtgT2AC40x/YHhwDhrbR9gXOK+pMhg6MN27GUOZVcOBOigfGdWOOfAVLSPZ5T28Wgp33VDlUfG\n1tqFwMJEvNoYMxXoAhwFHJDY7HHgPeDqjNQyRaZR6BrY039wcbu8YPzc9I8LXVnPVfF2WzQyTWiU\nGNdXYBqAZR1ZkO/1B/uutpeLHnBxWVfbqDW+6/rh3//eP3HRxExXLWXhnBN8pDq3jy99tqOLj262\nwsV9XgyWc+rzWPZ0x2XrPp4Os24Mrut+vZ3vou076g8uLlob/bXFceU7LzS1cFGD4Dt42m/+7cqO\ne9/P6VByph99XjxrTqWvm9/ar7Q17YatAbjgoLdd2aVtpoe29sebC0vWAfDB4J1CjyefKjkONRrA\nZYwpBHYEPgM6Jhrqsga7QwXPOdcYM8EYM2ETG5JtIhVYZ38BaIryHaWGaB+PjPbxaCnf2avajbEx\npjkwBrjUWruqus+z1o601u5ird2lAY2qfoIAUGyLmcgnAPOV72gU22KA3mgfj4T28Wgp39mtWqOp\njTENCBrip621ZcPTFhtjOltrFxpjOgNLMlXJVH1/g++WmLa17z46ZubhABSNmOzKsmEEdaktZSKf\n0InurGZFWZ9j5PnOa+YX7L7y3ieTbvNTSfBL+b4rT3JlTT5Nvnh9NivLOfBzXdnHV/zeXxkwetvb\nXDx5k/9v3efJtZHWqbqyZR9Phw2H7eriN08L/g7DF+/ryvrd4LtC4/p+iSPfB357nIvf3mZUucdf\nKHrVxdvdPNTFhYmvkrXH7O7KFhzqJw86Y88PXfzSFmMByAsdV5aGxqmXTcEL8PydhwDQ7pvsOWUT\nVuWRsTHGAA8DU621d4QeegUYkoiHAC+nv3r1j7WWKUygGS3oYfqGH1K+MySccyB8/ZVyngHax6Ol\nfNcN1Tky3hsYDEwyxpTN3/YnYAQwyhgzFJgHnFDB82NR0LOHiy8/8hUXb7B+yYfVNwfTpjVcNT66\nilVhJctYxDya04pP7dsA/Y0xhxNDvr9/uLeLD27yXtJtjvvzlQC0fjk7f21WRzjnBPn+mizex0v3\nDdaOfuEmfzTcMd93Hx7319AarZ9n398lm/bx2spv5wcsnnD7Wy4uLGgKwMtv+akge66I928QV77n\nf9/exav7bwQqXkRm4j4Pu/irWcExYlGDj1xZRc8r8/kGP1jsrGf9/t/7tikubhfz36Eq1RlN/SGE\nhsX92kHprY60NltwMH4SkrF29BRr7RuJu8p3BoRznsj3LqGHlfM00z4eLeW7btB0mCIiIjHL2ekw\nvxvW2cWvtJrv4qJXh7m471t1b6BRlIrXN0havu0HfrBF79HBqj+5PrVf3Ap6Fbr4kkefAqBLflNX\n1uelC3z8SHZ3x+WCpv/xxzEXtvbfL33/dwYAva7/wpX5oUf1S98/+O/X32x5NgDjd32iyuftnDjj\nUorvml5dutHFF88b5OJJLwfXGW95q18JrhC//2fDgNzq0pGxiIhIzNQYi4iIxCznuqnLrr389MR/\nuLLjZh7r4q2u9Nf8qWu1cn3O8F1tR+KvpeyJn+JSOcyc8BUBe//H77cHNQmu7f7jQn8d5tY3zXGx\nv15A0im/v78s6N4ej7i4xPrTBe1fDGK7yXerCnQ9O7iEebfTL3Flq3dcX+lzGs32U2T2eHWli+0X\nfl6ILfmYXKEjYxERkZipMRYREYlZznVTLzs06Ppok+dW4WHV37q6uMHqL8o9RyQb9R8zz8VXt/Pd\n1HOKgykuZ5zlJ2UpXTQtuorVMwWdOwEw+CW/MlCH0Ej27e73V2h0fUEj2ZMpWboMgE53+W7lTjV4\nfn0Yka4jYxERkZjl3JFx79O+AuBw/OIQDdDRsNQ9E3fyxwPh/dnT0XAk8oJjltb5ftGN6Zv84KPu\nb/j1o0ttfTiGk0zQkbGIiEjM1BiLiIjELOe6qUVE0qn4hx8BuLNo6wq2mFJBuUj16chYREQkZmqM\nRUREYmZshKP/jDE/Ab8ASyN702htQfo/Ww9rbfuqNysvke+5ZKZe2SLdn63W+Qbt47WU6j6ufNeM\nvlMqF8t3SqSNMYAxZsJmi7fnjGz9bNlar3TIxs+WjXVKl2z8bNlYp3TJ1s+WrfVKh7g+m7qpRURE\nYqbGWEREJGZxNMYjY3jPqGTrZ8vWeqVDNn62bKxTumTjZ8vGOqVLtn62bK1XOsTy2SI/ZywiIiK/\npm5qERGRmKkxFhERiVmkjbExZqAx5jtjzExjzPAo3zvdjDHdjDHvGmOmGmMmG2MuSZS3Nca8bYyZ\nkfi3TYx1VL6jraPyHX09lfNo66h8Z4q1NpIbkA98D/QCGgLfAP2jev8MfJ7OwE6JuAUwHegP3AoM\nT5QPB26JqX7Kt/Kds/lWzpXvXMt3lEfGuwEzrbWzrLUbgeeAoyJ8/7Sy1i601n6ZiFcDU4EuBJ/p\n8cRmjwNHx1ND5Ttiynf0lPNoKd8ZFGVj3AWYH7q/IFFW5xljCoEdgc+AjtbahRD8sYEOMVVL+Y6W\n8h095TxayncGRdkYmyRldf66KmNMc2AMcKm1dlXc9QlRvqOlfEdPOY+W8p1BUTbGC4BuoftdgR8j\nfP+0M8Y0IPgjPm2tfTFRvNgY0znxeGdgSUzVU76jpXxHTzmPlvKdQVE2xuOBPsaYnsaYhsDJwCsR\nvn9aGWMM8DAw1Vp7R+ihV4AhiXgI8HLUdUtQvqOlfEdPOY+W8p1JEY9eO5xgxNr3wLVRvncGPss+\nBF00E4GvE7fDgXbAOGBG4t+2MdZR+Va+czbfyrnynUv51nSYIiIiMdMMXCIiIjFTYywiIhIzNcYi\nIiIxU2MsIiISMzXGIiIiMVNjLCIiEjM1xiIiIjH7/6fc7msyAnODAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e5a0dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(8, 4), squeeze=False)\n",
    "seed = 123 # changer la seed pour afficher d'autres images\n",
    "\n",
    "for i in range(10):\n",
    "    r = i // 5\n",
    "    c = i % 5\n",
    "    np.random.seed(seed+i)\n",
    "    idx = np.random.choice(len(train_data), 1)[0]\n",
    "    x = train_data[idx][0].numpy()\n",
    "    y = train_data[idx][1]\n",
    "    axes[r, c].imshow(x[0, :, :])\n",
    "    axes[r, c].set_title('y={}'.format(y))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train negative log-likelihood: 0.368019\n",
      "Test  negative log-likelihood: 0.294447 0/1 error: 0.083300\n",
      "Epoch 2...\n",
      "Train negative log-likelihood: 0.301837\n",
      "Test  negative log-likelihood: 0.286049 0/1 error: 0.081200\n",
      "Epoch 3...\n",
      "Train negative log-likelihood: 0.289908\n",
      "Test  negative log-likelihood: 0.282798 0/1 error: 0.078600\n",
      "Epoch 4...\n",
      "Train negative log-likelihood: 0.283505\n",
      "Test  negative log-likelihood: 0.290526 0/1 error: 0.080500\n",
      "Epoch 5...\n",
      "Train negative log-likelihood: 0.278865\n",
      "Test  negative log-likelihood: 0.274886 0/1 error: 0.075400\n",
      "Epoch 6...\n",
      "Train negative log-likelihood: 0.276089\n",
      "Test  negative log-likelihood: 0.284389 0/1 error: 0.082400\n",
      "Epoch 7...\n",
      "Train negative log-likelihood: 0.272958\n",
      "Test  negative log-likelihood: 0.285296 0/1 error: 0.081000\n",
      "Epoch 8...\n",
      "Train negative log-likelihood: 0.269966\n",
      "Test  negative log-likelihood: 0.272259 0/1 error: 0.075700\n",
      "Epoch 9...\n",
      "Train negative log-likelihood: 0.268882\n",
      "Test  negative log-likelihood: 0.283950 0/1 error: 0.076400\n",
      "Epoch 10...\n",
      "Train negative log-likelihood: 0.267367\n",
      "Test  negative log-likelihood: 0.282141 0/1 error: 0.078500\n",
      "Epoch 11...\n",
      "Train negative log-likelihood: 0.265564\n",
      "Test  negative log-likelihood: 0.278789 0/1 error: 0.077000\n",
      "Epoch 12...\n",
      "Train negative log-likelihood: 0.264023\n",
      "Test  negative log-likelihood: 0.278803 0/1 error: 0.075800\n",
      "Epoch 13...\n",
      "Train negative log-likelihood: 0.262911\n",
      "Test  negative log-likelihood: 0.274599 0/1 error: 0.076500\n",
      "Epoch 14...\n",
      "Train negative log-likelihood: 0.262123\n",
      "Test  negative log-likelihood: 0.278249 0/1 error: 0.075000\n",
      "Epoch 15...\n",
      "Train negative log-likelihood: 0.261244\n",
      "Test  negative log-likelihood: 0.276109 0/1 error: 0.075200\n",
      "Epoch 16...\n",
      "Train negative log-likelihood: 0.260619\n",
      "Test  negative log-likelihood: 0.273745 0/1 error: 0.077900\n",
      "Epoch 17...\n",
      "Train negative log-likelihood: 0.259354\n",
      "Test  negative log-likelihood: 0.281995 0/1 error: 0.077000\n",
      "Epoch 18...\n",
      "Train negative log-likelihood: 0.258855\n",
      "Test  negative log-likelihood: 0.284478 0/1 error: 0.078600\n",
      "Epoch 19...\n",
      "Train negative log-likelihood: 0.258018\n",
      "Test  negative log-likelihood: 0.283081 0/1 error: 0.078600\n",
      "Epoch 20...\n",
      "Train negative log-likelihood: 0.257712\n",
      "Test  negative log-likelihood: 0.283459 0/1 error: 0.077400\n",
      "Epoch 21...\n",
      "Train negative log-likelihood: 0.256462\n",
      "Test  negative log-likelihood: 0.278956 0/1 error: 0.075200\n",
      "Epoch 22...\n",
      "Train negative log-likelihood: 0.256435\n",
      "Test  negative log-likelihood: 0.280318 0/1 error: 0.075000\n",
      "Epoch 23...\n",
      "Train negative log-likelihood: 0.256266\n",
      "Test  negative log-likelihood: 0.278721 0/1 error: 0.076800\n",
      "Epoch 24...\n",
      "Train negative log-likelihood: 0.255725\n",
      "Test  negative log-likelihood: 0.312082 0/1 error: 0.085300\n",
      "Epoch 25...\n",
      "Train negative log-likelihood: 0.254750\n",
      "Test  negative log-likelihood: 0.279933 0/1 error: 0.078100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Training settings\n",
    "seed = 1337\n",
    "lr = 0.2\n",
    "epochs = 25\n",
    "train_batch_size = 25\n",
    "test_batch_size = 100\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, 28*28)  # flatten images\n",
    "        X = self.fc1(X)\n",
    "        return F.log_softmax(X)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "    exp_loss = 0.\n",
    "    n_processed = 0\n",
    "\n",
    "    model.train()\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = Variable(X), Variable(Y)\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_pred_prob = model(X)\n",
    "\n",
    "        # Compute expected loss\n",
    "        loss = F.nll_loss(Y_pred_prob, Y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Parameter update (gradient descent)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # exp_loss.data[0] += loss * X.data.shape[0]\n",
    "        exp_loss += loss * X.data.shape[0]\n",
    "        n_processed += X.data.shape[0]\n",
    "    \n",
    "    exp_loss /= n_processed\n",
    "    return exp_loss\n",
    "\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    test_error = 0\n",
    "    model.eval()\n",
    "    for X, Y in test_loader:\n",
    "        X, Y = Variable(X, volatile=True), Variable(Y)\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_pred_prob = model(X)\n",
    "        \n",
    "        # Compute the expected negative log-likelihood\n",
    "        test_loss += F.nll_loss(Y_pred_prob, Y, size_average=False).data[0]\n",
    "        \n",
    "        # Get the mode of p(y|x) (most probable digit)\n",
    "        Y_pred = Y_pred_prob.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # Compute the expected 0/1 error\n",
    "        test_error += (1 - Y_pred.eq(Y.data.view_as(Y_pred))).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_error /= len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, test_error\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    print('Epoch {}...'.format(epoch))\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "    print('Train negative log-likelihood: {:.6f}'.format(train_loss.data[0]))\n",
    "    \n",
    "    test_loss, test_error = test()\n",
    "    print('Test  negative log-likelihood: {:.6f} 0/1 error: {:.6f}'.format(test_loss, test_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jouez avec les paramètres suivants:\n",
    "- lr\n",
    "- epochs\n",
    "- train_batch_size\n",
    "\n",
    "Quelle est la meilleure performance (0/1 error) que vous arrivez à atteindre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur score que j'obtient est 0.0751 avec lr=0.2, epochs=25, train_batch_size=50\n",
    "J'ai monté epochs jusqu'à 100 mais le résultat ne s'améliore pas. Il faut donc changer la méthode pour espérér un meilleur résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Améliorez votre modèle\n",
    "\n",
    "Améliorez votre modèle afin de diminuer l'erreur sur le jeu de test. Essayez différentes architectures / hyperparamètres et à chaque fois reportez vos résultats.\n",
    "\n",
    "Objectif: passer sous les 1% d'erreur: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Pistes à essayer:\n",
    "- plus de couches cachées\n",
    "- convolutions + max pooling\n",
    "- dropout\n",
    "- couches résiduelles\n",
    "\n",
    "Astuces:\n",
    "- changer l'algorithme de descente de gradient (Adam)\n",
    "- implémentez une stratégie d'early stopping: $n$ epochs sans amélioration -> arret\n",
    "- implémentez une stratégie de diminution du learning rate: $n/2$ epochs sans amélioration -> $\\alpha = \\alpha / 2$ (torch.optim.lr_scheduler.ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train negative log-likelihood: nan\n",
      "Test  negative log-likelihood: nan 0/1 error: 0.902000\n",
      "Epoch 2...\n",
      "Train negative log-likelihood: nan\n",
      "Test  negative log-likelihood: nan 0/1 error: 0.902000\n",
      "Epoch 3...\n",
      "Train negative log-likelihood: nan\n",
      "Test  negative log-likelihood: nan 0/1 error: 0.902000\n",
      "Epoch 4...\n",
      "Train negative log-likelihood: nan\n",
      "Test  negative log-likelihood: nan 0/1 error: 0.902000\n",
      "Epoch 5...\n",
      "Train negative log-likelihood: nan\n",
      "Test  negative log-likelihood: nan 0/1 error: 0.902000\n",
      "Time 49.08213496208191\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "t_s=time.time()\n",
    "# Training settings\n",
    "seed = 1337\n",
    "lr = 1\n",
    "epochs = 5\n",
    "train_batch_size = 25\n",
    "test_batch_size = 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 120)# On utilise ici un NN avec 3 couche, donc, 2 couches cachées de dimension \n",
    "        self.fc2 = nn.Linear(120, 80)# correspondance de (28*28, 120) et (120,84)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, 28*28)\n",
    "        X = self.fc1(X)\n",
    "        X= F.log_softmax(X)\n",
    "        X = self.fc2(X)\n",
    "        X = F.log_softmax(X)\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X)\n",
    "        \n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "    exp_loss = 0.\n",
    "    n_processed = 0\n",
    "\n",
    "    model.train()\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = Variable(X), Variable(Y)\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_pred_prob = model(X)\n",
    "\n",
    "        # Compute expected loss\n",
    "        loss = F.nll_loss(Y_pred_prob, Y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Parameter update (gradient descent)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # exp_loss.data[0] += loss * X.data.shape[0]\n",
    "        exp_loss += loss * X.data.shape[0]\n",
    "        n_processed += X.data.shape[0]\n",
    "    \n",
    "    exp_loss /= n_processed\n",
    "    return exp_loss\n",
    "\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    test_error = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for X, Y in test_loader:\n",
    "        X, Y = Variable(X, volatile=True), Variable(Y)\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_pred_prob = model(X)\n",
    "        \n",
    "        # Compute the expected negative log-likelihood\n",
    "        test_loss += F.nll_loss(Y_pred_prob, Y, size_average=False).data[0]\n",
    "        \n",
    "        # Get the mode of p(y|x) (most probable digit)\n",
    "        Y_pred = Y_pred_prob.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # Compute the expected 0/1 error\n",
    "        test_error += (1 - Y_pred.eq(Y.data.view_as(Y_pred))).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_error /= len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, test_error\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    print('Epoch {}...'.format(epoch))\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "    print('Train negative log-likelihood: {:.6f}'.format(train_loss.data[0]))\n",
    "    \n",
    "    test_loss, test_error = test()\n",
    "    print('Test  negative log-likelihood: {:.6f} 0/1 error: {:.6f}'.format(test_loss, test_error))\n",
    "\n",
    "t_end=time.time()\n",
    "print(\"Time\", t_end-t_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1...\n",
      "Train negative log-likelihood: 0.506679\n",
      "Test  negative log-likelihood: 0.082159 0/1 error: 0.025100\n",
      "Epoch 2...\n",
      "Train negative log-likelihood: 0.248509\n",
      "Test  negative log-likelihood: 0.060899 0/1 error: 0.020800\n",
      "Epoch 3...\n",
      "Train negative log-likelihood: 0.206382\n",
      "Test  negative log-likelihood: 0.057975 0/1 error: 0.018100\n",
      "Epoch 4...\n",
      "Train negative log-likelihood: 0.191437\n",
      "Test  negative log-likelihood: 0.051360 0/1 error: 0.016700\n",
      "Epoch 5...\n",
      "Train negative log-likelihood: 0.176884\n",
      "Test  negative log-likelihood: 0.045304 0/1 error: 0.014300\n",
      "Epoch 6...\n",
      "Train negative log-likelihood: 0.172587\n",
      "Test  negative log-likelihood: 0.062649 0/1 error: 0.018000\n",
      "Epoch 7...\n",
      "Train negative log-likelihood: 0.165201\n",
      "Test  negative log-likelihood: 0.063225 0/1 error: 0.017300\n",
      "Epoch 8...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "t_s=time.time()\n",
    "# Training settings\n",
    "seed = 1337\n",
    "lr = 0.1\n",
    "epochs = 10\n",
    "train_batch_size = 25\n",
    "test_batch_size = 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "    exp_loss = 0.\n",
    "    n_processed = 0\n",
    "\n",
    "    model.train()\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = Variable(X), Variable(Y)\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_pred_prob = model(X)\n",
    "\n",
    "        # Compute expected loss\n",
    "        loss = F.nll_loss(Y_pred_prob, Y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Parameter update (gradient descent)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # exp_loss.data[0] += loss * X.data.shape[0]\n",
    "        exp_loss += loss * X.data.shape[0]\n",
    "        n_processed += X.data.shape[0]\n",
    "    \n",
    "    exp_loss /= n_processed\n",
    "    return exp_loss\n",
    "\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    test_error = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for X, Y in test_loader:\n",
    "        X, Y = Variable(X, volatile=True), Variable(Y)\n",
    "        \n",
    "        # Forward pass\n",
    "        Y_pred_prob = model(X)\n",
    "        \n",
    "        # Compute the expected negative log-likelihood\n",
    "        test_loss += F.nll_loss(Y_pred_prob, Y, size_average=False).data[0]\n",
    "        \n",
    "        # Get the mode of p(y|x) (most probable digit)\n",
    "        Y_pred = Y_pred_prob.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # Compute the expected 0/1 error\n",
    "        test_error += (1 - Y_pred.eq(Y.data.view_as(Y_pred))).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_error /= len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, test_error\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    print('Epoch {}...'.format(epoch))\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "    print('Train negative log-likelihood: {:.6f}'.format(train_loss.data[0]))\n",
    "    \n",
    "    test_loss, test_error = test()\n",
    "    print('Test  negative log-likelihood: {:.6f} 0/1 error: {:.6f}'.format(test_loss, test_error))\n",
    "\n",
    "t_end=time.time()\n",
    "print(\"Time\", t_end-t_s)#cette méthode tourne bien, nous avons donc une erreur de moins de 2% avec 10 epochs, \n",
    "#si on utilise 25 epochs, je pense qu'on peut arriver à un résultat de 1% un peu près."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dans le résultat précédent on peut espérer à avoir une erreur de 1% environs en augementant la taille de epoch(50, par exemple)  et la taille de training_batch_size(=50, par exemple. Là, je suis sur mon PC personnel et cela tournera mal avec les paramètres unpeu plus élévé)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NLP: N-Gram Language Modeling\n",
    "\n",
    "Modèle NGram: sachant les mots $n$ précédents on veut prédire le prochain mot:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i | w_{i-1}, w_{i-2}, \\dots, w_{i-n+1})\n",
    "\\end{equation*}\n",
    "\n",
    "Où $w_i$ est le ième mot d'une phrase.\n",
    "\n",
    "Veuillez considérer de modèle de prédiction de trigram suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " 525.0787\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 501.3724\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 478.8521\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 456.7795\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 434.5869\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 411.8039\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 388.1391\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 363.4603\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 337.8178\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 311.3845\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 284.3995\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 257.2635\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 230.3702\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 204.2893\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 179.5183\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 156.5714\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 135.7663\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 117.3949\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 101.3916\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 87.6958\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 76.1037\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 66.3585\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 58.2123\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 51.4513\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 45.8166\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 41.1220\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 37.2157\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 33.9302\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 31.1569\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 28.8026\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 26.7793\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 25.0402\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 23.5327\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 22.2125\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 21.0564\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 20.0319\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 19.1219\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 18.3110\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 17.5789\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 16.9242\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 16.3280\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 15.7890\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 15.2957\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 14.8442\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 14.4298\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 14.0479\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 13.6941\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 13.3669\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 13.0619\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 12.7776\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 12.5137\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 12.2644\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 12.0310\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 11.8120\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 11.6052\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 11.4099\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 11.2242\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 11.0486\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 10.8814\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 10.7237\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 10.5725\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 10.4295\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 10.2919\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 10.1611\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 10.0352\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.9157\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.8005\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.6892\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.5831\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.4802\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.3836\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.2873\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.1964\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.1067\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.0207\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.9377\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.8569\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.7792\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.7036\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.6303\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.5587\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.4900\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.4222\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.3583\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.2940\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.2323\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.1713\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.1131\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.0551\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.9996\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.9444\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.8915\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.8388\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.7888\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.7377\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.6903\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.6414\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.5950\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.5491\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.5047\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.4606\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.4181\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.3758\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.3349\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.2942\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.2548\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.2156\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.1777\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.1414\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.1035\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.0674\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.0323\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.9983\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.9631\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.9305\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.8968\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.8641\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.8330\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.8010\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.7708\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.7394\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.7097\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.6823\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.6516\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.6239\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.5949\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.5672\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.5401\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.5131\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.4870\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.4609\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.4350\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.4096\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.3851\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.3607\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.3364\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.3127\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.2890\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.2658\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.2429\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.2204\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.1980\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.1762\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.1542\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.1335\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.1119\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.0905\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.0712\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.0497\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.0299\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.0106\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.9905\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.9707\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.9525\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.9331\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.9150\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.8968\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.8776\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.8597\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.8426\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.8245\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.8069\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.7898\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.7727\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.7558\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.7397\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.7229\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.7070\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.6907\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.6753\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.6593\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.6441\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.6285\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.6137\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.5995\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.5835\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.5692\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.5545\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.5406\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.5260\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.5121\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.4980\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.4845\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.4706\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.4571\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.4434\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.4301\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.4173\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.4052\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3917\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3787\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3664\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3537\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3414\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3296\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3171\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3055\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2934\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2817\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2704\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2586\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2475\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2359\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2250\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2137\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.2027\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1921\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1812\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1706\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1598\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1496\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1389\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1286\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1187\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.1085\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0985\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0884\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0786\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0692\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0593\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0502\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0411\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0310\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0218\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0124\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.0043\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9942\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9851\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9764\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9681\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9588\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9498\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9411\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9338\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9241\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9159\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9073\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8989\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8909\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8826\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8755\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8664\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8584\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8515\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8425\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8350\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8279\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8197\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8126\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.8041\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7969\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7900\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7819\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7748\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7681\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7603\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7528\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7461\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7388\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7319\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7250\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7179\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7111\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.7045\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6975\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6909\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6842\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6775\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6712\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6644\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6582\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6516\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6452\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6391\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6325\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6263\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6204\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6140\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6078\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6019\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5957\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5899\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5869\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5776\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5721\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5668\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5629\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5544\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5489\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5434\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5399\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5318\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5265\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5209\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5178\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5098\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.5044\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4990\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4961\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4882\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4832\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4778\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4748\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4676\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4622\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4571\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4523\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4471\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4421\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4370\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4324\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4272\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4224\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4177\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4128\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4093\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.4034\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3984\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3946\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3889\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3851\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3807\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3752\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3706\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3663\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3624\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3572\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3531\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3483\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3440\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3404\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3354\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3310\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3269\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3224\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3189\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3142\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3099\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3056\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3017\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2981\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2934\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2895\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2853\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2812\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2774\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2732\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2693\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2655\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2615\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2576\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2537\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2501\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2461\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2423\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2389\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2355\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2310\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2274\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2243\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2198\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2164\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2126\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2090\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2056\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.2019\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1983\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1950\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1912\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1878\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1843\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1810\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1773\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1740\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1707\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1672\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1638\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1606\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1571\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1538\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1506\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1472\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1440\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1407\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1375\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1342\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1310\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1280\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1246\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1214\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1185\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1152\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1128\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1090\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1061\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1026\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0998\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0973\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0943\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0905\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0875\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0854\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0816\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0795\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0759\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0729\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0699\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0672\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0642\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0620\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0587\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0557\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0549\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0501\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0472\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0454\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0417\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0391\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0383\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0334\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0330\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0281\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0268\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0226\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0222\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0175\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0154\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0124\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0097\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0089\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0045\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.0020\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9993\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9968\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9944\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9938\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9891\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9869\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9843\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9817\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9793\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9788\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9744\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9719\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9696\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9692\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9647\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9622\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9599\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9575\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9549\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9527\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9505\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9479\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9460\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9433\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9414\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9387\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9364\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9348\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9319\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9299\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9274\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9256\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9230\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9207\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9189\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9164\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9144\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9120\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9102\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9077\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9055\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9038\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9013\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8994\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8971\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8951\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8931\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8908\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8890\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8868\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8846\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8833\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8811\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8789\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8771\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8745\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8735\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8705\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8687\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8678\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8653\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8627\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8606\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8601\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8569\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8548\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8529\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8511\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8491\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8471\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8454\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8434\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8414\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8396\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8378\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8359\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8340\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8322\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8305\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8286\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8267\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8248\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8233\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8213\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8195\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8181\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8160\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8142\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8123\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8106\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8090\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8072\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8054\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8037\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8019\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.8002\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7984\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7969\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7950\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7934\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7919\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7901\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7886\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7866\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7853\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7837\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7817\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7803\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7786\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7770\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7754\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7735\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7720\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7706\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7687\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7673\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7659\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7639\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7623\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7614\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7596\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7577\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7561\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7548\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7531\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7520\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7500\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7486\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7470\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7454\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7439\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7426\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7415\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7394\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7382\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7364\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7350\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7335\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7322\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7313\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7292\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7277\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7264\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7247\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7234\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7233\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7209\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7190\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7189\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7161\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7147\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7147\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7121\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7111\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7104\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7078\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7066\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7063\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7043\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7023\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7027\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6997\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6988\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6982\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6955\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6945\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6935\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6933\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6902\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6890\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6889\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6863\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6850\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6854\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6825\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6828\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6810\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6785\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6772\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6761\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6758\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6739\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6722\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6721\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6713\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6683\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6683\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6659\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6664\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6636\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6624\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6622\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6616\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6585\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6584\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6569\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6550\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6549\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6544\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6512\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6513\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6493\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6483\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6477\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6454\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6455\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6447\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6418\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6419\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6396\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6389\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6384\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6361\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6351\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6351\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6328\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6333\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6315\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6298\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6283\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6281\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6260\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6255\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6265\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6226\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6220\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6216\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6194\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6183\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6182\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6161\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6170\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6154\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6128\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6118\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6120\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6098\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6086\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6092\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6075\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6061\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6044\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6044\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6023\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6013\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6006\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.6023\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5981\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5974\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5961\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5962\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5943\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5931\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5931\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5918\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5917\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5900\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5882\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5871\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5872\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5852\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5842\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5846\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5823\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5812\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5828\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5791\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5782\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5782\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5763\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5759\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5754\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5734\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5724\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5726\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5721\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5695\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5697\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5683\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5668\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5658\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5659\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5639\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5637\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5636\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5627\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5602\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5603\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5585\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5575\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5567\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5567\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5553\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5555\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5539\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5520\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5513\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5513\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5495\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5485\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5481\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5484\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5459\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5460\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5442\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5433\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5434\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5422\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5408\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5400\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5391\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5407\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5374\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5364\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5365\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5354\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5338\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5339\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5322\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5315\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5305\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5322\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5291\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5284\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5281\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5265\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5255\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5257\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5242\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5230\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5232\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5216\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5227\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5200\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5190\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5191\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5177\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5167\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5167\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5157\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5157\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5134\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5136\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5119\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5110\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5112\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5095\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5091\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5090\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5087\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5064\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5065\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5048\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5042\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5047\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5026\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5018\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5011\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5013\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5010\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4988\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4989\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4977\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4966\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4958\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4960\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4943\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4936\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4929\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4921\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4918\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4930\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4899\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4893\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4885\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4886\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4870\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4863\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4869\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4849\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4841\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4834\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4836\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4820\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4814\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4815\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4803\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4806\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4793\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4777\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4772\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4764\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4765\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4754\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4743\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4745\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4729\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4722\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4724\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4709\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4702\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4697\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4692\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4690\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4674\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4670\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4663\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4663\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4648\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4641\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4639\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4653\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4621\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4614\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4614\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4621\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4595\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4588\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4586\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4582\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4569\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4571\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4567\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4549\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4548\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4544\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4535\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4538\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4517\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4525\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4516\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4497\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4500\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4485\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4479\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4485\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4478\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4461\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4454\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4448\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4450\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4437\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4448\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4423\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4436\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4410\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4404\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4398\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4401\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4386\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4380\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4378\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4388\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4363\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4358\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4358\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4344\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4340\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4332\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4331\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4344\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4314\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4308\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4302\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4305\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4291\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4285\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4279\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4277\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4269\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4262\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4264\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4250\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4244\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4241\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4234\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4249\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4221\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4218\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4211\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4213\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4203\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4193\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4196\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4184\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4177\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4173\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4173\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4162\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4154\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4149\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4152\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4138\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4133\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4134\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4121\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4117\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4111\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4112\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4099\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4099\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4088\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4092\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4077\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4086\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4067\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4061\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4057\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4059\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4045\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4042\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4035\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4030\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4033\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4019\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4014\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4009\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.4011\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3998\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3994\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3988\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3983\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3985\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3972\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3968\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3977\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3964\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3951\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3946\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3941\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3937\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3931\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3934\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3921\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3916\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3912\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3915\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3901\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3896\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3893\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3888\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3889\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3879\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3871\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3868\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3864\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3857\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3852\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3850\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3855\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3837\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3834\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3829\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3823\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3817\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3813\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3810\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3803\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3799\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3794\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3789\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3784\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3779\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3774\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3770\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3765\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3760\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3756\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "t_s=time.time()\n",
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "# we should tokenize the input, but we will ignore that for now\n",
    "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in variables)\n",
    "        context_idxs = [word_to_ix[w] for w in context]\n",
    "        context_var = Variable(torch.LongTensor(context_idxs))\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_var)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a variable)\n",
    "        loss = loss_function(log_probs, Variable(\n",
    "            torch.LongTensor([word_to_ix[target]])))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisez vos propres valeurs pour context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'be'] new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "context = ['to', 'be']\n",
    "context_idxs = [word_to_ix[w] for w in context]\n",
    "context_var = Variable(torch.LongTensor(context_idxs))\n",
    "log_probs = model(context_var)\n",
    "print(context, list(vocab)[torch.max(log_probs, 1)[1].data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'much'] more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "context = ['How', 'much']\n",
    "context_idxs = [word_to_ix[w] for w in context]\n",
    "context_var = Variable(torch.LongTensor(context_idxs))\n",
    "log_probs = model(context_var)\n",
    "print(context, list(vocab)[torch.max(log_probs, 1)[1].data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'child'] of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "context = ['This', 'child']\n",
    "context_idxs = [word_to_ix[w] for w in context]\n",
    "context_var = Variable(torch.LongTensor(context_idxs))\n",
    "log_probs = model(context_var)\n",
    "print(context, list(vocab)[torch.max(log_probs, 1)[1].data[0]])# il peut trouver la meilleure solution \n",
    "# meme quand ces 2 mots là ne sont pas consécutifs dans le texte original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW: Continuous Bag-of-Words\n",
    "CBOW = Prédire un mot sachant les mots d'avant et les mots d'après.\n",
    "\n",
    "Exercice : en utilisant l'exemple précédent, codez un modèle CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " 228.5765\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 214.6649\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 201.2470\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 187.9053\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 174.3643\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 160.5009\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 146.3137\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 131.9731\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 117.6527\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 103.7487\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 90.3668\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 77.8214\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 66.2478\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 55.8415\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 46.7199\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 38.9198\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 32.3991\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 27.0613\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 22.7481\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 19.2720\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 16.5084\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 14.2815\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 12.4933\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 11.0366\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 9.8383\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.8444\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 8.0111\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 7.3040\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.6991\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 6.1774\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.7230\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 5.3250\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.9748\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.6629\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.3842\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 4.1355\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.9103\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.7065\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.5215\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.3519\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.1975\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 3.0553\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.9245\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.8029\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.6907\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.5869\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.4892\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.3989\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.3141\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.2347\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.1605\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.0903\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 2.0242\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.9621\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.9033\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.8477\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.7951\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.7452\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.6977\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.6525\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.6098\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.5687\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.5298\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.4925\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.4569\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.4228\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.3903\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.3590\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.3290\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.3003\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.2727\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.2460\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.2206\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.1960\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.1723\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.1495\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.1274\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.1062\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.0858\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.0659\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.0468\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.0283\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 1.0103\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.9931\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.9762\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.9599\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.9442\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.9289\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.9140\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.8997\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.8856\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.8720\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.8589\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.8460\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.8335\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.8214\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.8096\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7981\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7869\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7760\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7654\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7550\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7449\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7351\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7255\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7161\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.7070\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6980\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6893\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6808\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6724\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6643\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6563\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6485\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6409\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6335\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6262\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6190\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6121\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.6052\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5985\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5920\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5855\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5793\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5731\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5670\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5611\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5553\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5496\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5440\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5385\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5331\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5279\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5227\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5176\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5126\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5077\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.5028\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4981\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4934\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4889\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4844\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4800\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4756\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4713\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4671\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4630\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4590\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4550\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4511\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4472\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4434\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4396\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4359\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4323\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4287\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4252\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4218\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4183\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4150\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4117\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4084\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4052\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.4020\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3989\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3958\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3928\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3898\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3869\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3840\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3811\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3783\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3755\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3728\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3701\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3674\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3648\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3621\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3596\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3571\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3546\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3521\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3497\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3473\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3449\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3425\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3402\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3379\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3357\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3335\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3313\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3291\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3270\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3248\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3227\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3207\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3186\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3166\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3146\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3127\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3107\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3088\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3069\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3050\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3031\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.3013\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2995\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2977\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2959\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2941\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2924\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2907\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2890\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2873\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2856\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2840\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2824\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2808\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2792\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2776\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2760\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2745\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2730\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2715\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2700\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2685\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2670\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2656\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2641\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2627\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2613\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2599\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2585\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2572\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2558\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2545\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2532\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2518\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2505\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2493\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2480\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2467\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2455\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2442\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2430\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2418\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2406\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2394\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2382\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2370\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2359\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2347\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2336\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2325\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2313\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2302\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2291\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2281\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2270\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2259\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2248\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2238\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2228\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2217\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2207\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2197\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2187\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2177\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2167\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2157\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2147\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2138\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2128\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2119\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2109\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2100\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2091\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2082\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2073\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2064\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2055\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2046\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2037\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2028\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2020\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2011\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.2003\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1994\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1986\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1977\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1969\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1961\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1953\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1945\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1937\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1929\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1921\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1913\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1905\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1898\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1890\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1883\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1875\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1868\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1860\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1853\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1845\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1838\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1831\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1824\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1817\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1810\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1803\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1796\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1789\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1782\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1775\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1769\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1762\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1755\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1749\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1742\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1736\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1729\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1723\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1716\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1710\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1704\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1698\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1691\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1685\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1679\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1673\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1667\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1661\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1655\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1649\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1643\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1638\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1632\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1626\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1620\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1615\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1609\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1603\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1598\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1592\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1587\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1581\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1576\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1571\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1565\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1560\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1555\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1549\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1544\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1539\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1534\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1529\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1524\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1519\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1514\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1509\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1504\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1499\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1494\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1489\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1484\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1479\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1475\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1470\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1465\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1460\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1456\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1451\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1446\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1442\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1437\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1433\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1428\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1424\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1419\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1415\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1411\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1406\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1402\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1397\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1393\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1389\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1385\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1380\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1376\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1372\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1368\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1364\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1360\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1356\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1352\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1348\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1344\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1340\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1336\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1332\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1328\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1324\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1320\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1316\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1312\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1308\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1305\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1301\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1297\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1293\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1290\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1286\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1282\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1279\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1275\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1271\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1268\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1264\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1261\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1257\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1254\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1250\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1247\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1243\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1240\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1236\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1233\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1230\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1226\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1223\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1219\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1216\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1213\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1210\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1206\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1203\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1200\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1197\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1193\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1190\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1187\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1184\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1181\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1178\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1174\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1171\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1168\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1165\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1162\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1159\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1156\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1153\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1150\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1147\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1144\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1141\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1138\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1135\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1132\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1130\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1127\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1124\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1121\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1118\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1115\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1113\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1110\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1107\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1104\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1101\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1099\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1096\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1093\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1091\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1088\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1085\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1082\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1080\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1077\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1075\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1072\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1069\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1067\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1064\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1062\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1059\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1056\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1054\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1051\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1049\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1046\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1044\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1041\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1039\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1036\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1034\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1032\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1029\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1027\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1024\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1022\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1020\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1017\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1015\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1013\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1010\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1008\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1006\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1003\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      " 0.1001\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.9862\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.9633\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.9406\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.9181\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.8956\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.8730\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.8508\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.8286\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.8064\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.7843\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.7624\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.7406\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.7188\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.6971\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.6755\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.6542\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.6326\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.6113\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.5901\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.5690\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.5479\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.5271\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.5061\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.4854\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.4646\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.4440\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.4235\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.4031\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.3827\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.3624\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.3423\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.3220\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.3021\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.2822\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.2622\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.2424\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.2228\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.2031\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.1835\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.1641\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.1447\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.1254\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.1061\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.0869\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.0679\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.0489\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.0299\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  9.0110\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.9923\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.9735\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.9549\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.9363\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.9179\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.8994\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.8810\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.8628\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.8445\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.8265\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.8083\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.7903\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.7724\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.7546\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.7368\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.7190\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.7013\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.6838\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.6662\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.6488\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.6313\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.6141\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.5968\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.5795\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.5625\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.5454\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.5284\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.5114\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.4946\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.4778\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.4610\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.4443\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.4277\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.4112\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.3946\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.3782\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.3618\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.3455\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.3292\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.3131\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.2969\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.2808\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.2648\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.2488\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.2329\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.2171\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.2013\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.1855\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.1699\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.1542\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.1387\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.1232\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.1077\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.0923\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.0770\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.0617\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.0465\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.0313\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.0162\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  8.0011\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.9862\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.9711\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.9563\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.9413\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.9266\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.9118\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.8971\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.8825\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.8679\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.8533\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.8388\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.8244\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.8100\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.7956\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.7813\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.7671\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.7529\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.7388\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.7246\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.7106\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.6967\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.6826\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.6688\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.6549\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.6411\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.6274\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.6136\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.5999\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.5863\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.5728\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.5592\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.5457\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.5323\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.5189\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.5056\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.4922\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.4790\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.4658\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.4526\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.4394\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.4264\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.4134\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.4003\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.3873\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.3744\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.3616\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.3487\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.3360\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.3232\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.3105\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.2978\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.2852\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.2726\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.2601\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.2476\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.2352\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.2227\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.2103\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1980\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1857\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1734\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1612\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1490\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1369\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1248\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1127\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.1007\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.0887\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.0768\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.0648\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.0530\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.0412\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.0293\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.0176\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  7.0058\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9942\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9826\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9709\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9593\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9478\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9363\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9248\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9134\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.9020\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8906\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8793\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8680\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8568\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8455\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8343\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8232\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8120\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.8010\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7899\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7789\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7679\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7570\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7461\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7352\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7244\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7136\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.7027\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6920\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6813\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6706\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6599\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6493\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6388\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6282\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6177\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.6072\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5967\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5863\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5759\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5655\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5552\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5449\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5346\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5244\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5141\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.5039\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4938\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4837\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4735\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4635\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4535\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4434\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4335\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4236\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4136\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.4037\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3939\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3840\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3742\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3644\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3547\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3450\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3353\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3256\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3160\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.3063\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2968\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2872\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2777\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2681\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2587\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2492\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2398\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2304\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2211\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2117\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.2024\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1931\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1839\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1746\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1654\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1562\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1471\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1380\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1288\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1198\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1107\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.1017\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0927\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0837\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0747\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0658\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0569\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0480\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0392\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0303\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0215\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0127\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  6.0040\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9952\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9866\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9779\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9692\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9606\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9520\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9433\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9348\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9262\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9177\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9092\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.9008\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8923\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8839\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8755\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8671\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8587\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8504\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8420\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8338\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8255\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8172\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8090\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.8008\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7926\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7845\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7763\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7682\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7601\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7520\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7440\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7359\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7279\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7199\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7120\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.7040\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6961\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6882\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6803\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6724\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6646\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6568\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6489\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6412\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6334\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6256\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6180\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6102\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.6026\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5949\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5872\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5796\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5720\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5644\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5569\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5494\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5418\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5343\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5268\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5194\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5119\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.5045\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4971\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4897\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4823\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4749\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4676\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4603\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4530\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4457\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4384\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4312\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4240\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4168\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4096\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.4024\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3953\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3881\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3810\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3739\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3668\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3598\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3527\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3457\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3387\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3317\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3247\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3177\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3108\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.3039\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2970\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2901\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2832\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2764\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2695\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2627\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2559\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2491\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2423\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2356\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2288\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2221\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2154\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2087\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.2020\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1954\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1887\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1821\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1755\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1689\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1623\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1558\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1492\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1427\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1362\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1297\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1232\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1167\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1103\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.1038\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0974\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0910\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0846\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0782\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0719\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0655\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0592\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0529\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0466\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0403\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0340\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0277\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0215\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0153\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0090\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  5.0028\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9967\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9905\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9843\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9782\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9721\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9659\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9599\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9538\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9477\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9417\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9356\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9296\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9236\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9175\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9116\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.9056\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8996\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8937\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8878\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8818\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8759\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8700\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8641\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8583\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8525\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8466\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8408\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8350\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8292\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8234\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8176\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8118\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8061\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.8004\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7947\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7889\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7833\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7776\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7719\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7663\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7606\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7550\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7494\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7437\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7382\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7326\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7270\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7215\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7159\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7104\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.7049\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6994\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6939\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6884\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6829\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6774\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6720\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6666\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6611\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6557\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6503\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6449\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6396\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6342\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6289\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6235\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6182\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6129\n",
      "[torch.FloatTensor of size 1]\n",
      ", \n",
      "1.00000e-02 *\n",
      "  4.6076\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return Variable(tensor)\n",
    "\n",
    "CONTEXT_SIZE = 4  # 2 words to the left, 2 to the right\n",
    "EMBEDDING_DIM = 10\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])\n",
    "\n",
    "#class CBOW(nn.Module):\n",
    "\n",
    " #   def __init__(self):\n",
    " #       pass\n",
    "\n",
    "  #  def forward(self, inputs):\n",
    "  #      pass\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range((300):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    for context, target in data:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in variables)\n",
    "        context_var = make_context_vector(context, word_to_ix)\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_var)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a variable)\n",
    "        loss = loss_function(log_probs, Variable(\n",
    "            torch.LongTensor([word_to_ix[target]])))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!\n",
    "#là, nous avons une erreur très très petite..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processes', 'manipulate', 'abstract', 'things'] other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "context = ['processes', 'manipulate', 'abstract', 'things']# We expect to see 'other'\n",
    "context_var = make_context_vector(context, word_to_ix)\n",
    "log_probs = model(context_var)\n",
    "print(context, list(vocab)[torch.max(log_probs, 1)[1].data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['People', 'create', 'to', 'direct'] programs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "context = ['People', 'create',  'to', 'direct']# We expect to see 'programs'\n",
    "context_var = make_context_vector(context, word_to_ix)\n",
    "log_probs = model(context_var)\n",
    "print(context, list(vocab)[torch.max(log_probs, 1)[1].data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computational', 'processes', 'beings', 'that'] abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NhatMinh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "context = ['Computational', 'processes',  'beings', 'that']# there are 'are' and 'abstract' between these words.\n",
    "context_var = make_context_vector(context, word_to_ix)\n",
    "log_probs = model(context_var)\n",
    "print(context, list(vocab)[torch.max(log_probs, 1)[1].data[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
